{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from SVERL_icml_2023.portfolio_DRL.data_function import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SVERL_icml_2023.portfolio_DRL.create_model import *\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from SVERL_icml_2023.shapley import Shapley\n",
    "import shap\n",
    "sys.path.append(\"E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023\")\n",
    "# from portfolio_DRL.create_model import StockPredictWrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data (as before)\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Select relevant SHAP features for regime clustering\n",
    "shap_features = shap_metrics[[\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA'\n",
    "]]\n",
    "\n",
    "# Normalize SHAP metrics using StandardScaler (mean=0, std=1)\n",
    "scaler_shap = StandardScaler()\n",
    "shap_features_normalized = scaler_shap.fit_transform(shap_features)\n",
    "\n",
    "# Save normalized SHAP metrics back to a DataFrame\n",
    "shap_features_norm_df = pd.DataFrame(\n",
    "    shap_features_normalized,\n",
    "    columns=shap_features.columns,\n",
    "    index=shap_metrics.index\n",
    ")\n",
    "\n",
    "# Include 'End_Date' and 'Stock' columns for reference\n",
    "shap_features_norm_df['End_Date'] = shap_metrics['End_Date']\n",
    "shap_features_norm_df['Stock'] = shap_metrics['Stock']\n",
    "\n",
    "# Drop non-numeric columns explicitly before aggregation\n",
    "numeric_columns = shap_features_norm_df.columns.drop(['End_Date', 'Stock'])\n",
    "\n",
    "# Aggregated SHAP regime-level features (average over DJ30 stocks per date)\n",
    "regime_features_norm = shap_features_norm_df.groupby('End_Date')[numeric_columns].mean().dropna()\n",
    "\n",
    "# Inspect aggregated and normalized regime-level SHAP features\n",
    "print(regime_features_norm.head())\n",
    "\n",
    "# Normalize factor returns similarly for PPO input\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize stock returns for PPO environment\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Inspect normalized data\n",
    "print(\"Normalized SHAP features:\", regime_features_norm.head())\n",
    "print(\"Normalized factor returns:\", factor_returns_norm.head())\n",
    "print(\"Normalized stock returns:\", stock_returns_norm.head())\n",
    "regime_features_norm.to_csv(\"regime_features_norm.csv\")\n",
    "factor_returns_norm.to_csv(\"factor_returns_norm.csv\")\n",
    "stock_returns_norm.to_csv(\"stock_returns_norm.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c807fd6acd5211a2"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Implement t-SNE and clustering to detect market regimes:\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# t-SNE Dimension reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(regime_features_norm)\n",
    "\n",
    "# Gaussian Mixture clustering (or KMeans as simpler alternative)\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "clusters = gmm.fit_predict(tsne_result)\n",
    "\n",
    "regime_features_norm['Regime'] = clusters\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(tsne_result[:,0], tsne_result[:,1], c=clusters, cmap='viridis')\n",
    "plt.title(\"t-SNE SHAP Regime Clustering\")\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.colorbar(label='Regime')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acee54455ebb1102"
  },
  {
   "cell_type": "raw",
   "source": [
    "1. Single-Step PPO: \"SinglePPOEnv\"\n",
    "\n",
    "Environment definition (rename explicitly):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81abba305046567"
  },
  {
   "cell_type": "raw",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "class SinglePPOEnv(gym.Env):\n",
    "    def __init__(self, stock_returns_norm, regime_features_norm):\n",
    "        super().__init__()\n",
    "        self.stock_returns = stock_returns_norm.values\n",
    "        self.regime_features = regime_features_norm['Regime'].values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets + 1,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = self.regime_features[self.current_step]\n",
    "        obs = np.concatenate([returns, [regime]])\n",
    "        obs = np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        if action_sum == 0:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "        else:\n",
    "            action /= action_sum\n",
    "\n",
    "        reward = np.dot(action, self.stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Explicit fix to ensure exactly 63 observations\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        # Adjust observation to always return valid step explicitly\n",
    "        if not done:\n",
    "            obs = self._get_obs()\n",
    "        else:\n",
    "            obs = np.zeros(self.observation_space.shape)\n",
    "\n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = 0.0\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b684f58e04c996c2"
  },
  {
   "cell_type": "raw",
   "source": [
    "Rolling Training and Out-of-Sample Testing (Single-Step PPO):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88d84e25cf2eeea"
  },
  {
   "cell_type": "raw",
   "source": [
    "single_step_records = []\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "total_windows = len(range(0, len(stock_returns_norm) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(stock_returns_norm) - train_window - test_window, test_window)):\n",
    "    \n",
    "    print(f\"\\nStarting training window {i+1}/{total_windows}...\")\n",
    "    \n",
    "    train_returns_df = stock_returns_norm.iloc[start : start + train_window].ffill()\n",
    "    test_returns_df = stock_returns_norm.iloc[start + train_window : start + train_window + test_window + 1].ffill()\n",
    "\n",
    "    train_regimes_df = regime_features_norm.iloc[start : start + train_window].ffill()\n",
    "    test_regimes_df = regime_features_norm.iloc[start + train_window : start + train_window + test_window + 1].ffill()\n",
    "\n",
    "    env = DummyVecEnv([lambda: SinglePPOEnv(train_returns_df, train_regimes_df)])\n",
    "    model = PPO('MlpPolicy', env, verbose=0)\n",
    "\n",
    "    print(\"Training PPO model...\")\n",
    "    model.learn(total_timesteps=10000)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    env_test = SinglePPOEnv(test_returns_df, test_regimes_df)\n",
    "    obs = env_test.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "\n",
    "    test_dates = test_returns_df.index[:-1].tolist()  # explicitly matching 63 steps\n",
    "\n",
    "    print(\"Starting out-of-sample evaluation...\")\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env_test.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        single_step_records.append({\n",
    "            'Date': test_dates[step_idx],\n",
    "            'Window': i,\n",
    "            'Step': step_idx,\n",
    "            'Reward': reward,\n",
    "            **{ticker: weight for ticker, weight in zip(tickers, action)}\n",
    "        })\n",
    "\n",
    "        step_idx += 1\n",
    "\n",
    "    print(f\"Window {i+1}/{total_windows} completed. Total Steps: {step_idx}, Total Out-of-Sample Reward: {total_reward:.4f}\")\n",
    "\n",
    "single_df = pd.DataFrame(single_step_records)\n",
    "single_df['Cumulative_Return'] = single_df['Reward'].cumsum()\n",
    "\n",
    "single_df.to_csv('single_step_allocations_with_dates.csv', index=False)\n",
    "\n",
    "single_pnl_df = single_df[['Date', 'Cumulative_Return']]\n",
    "single_pnl_df.to_csv('single_step_pnl_with_dates.csv', index=False)\n",
    "\n",
    "print(\"\\nAll training windows completed successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e6c5c167b729846"
  },
  {
   "cell_type": "raw",
   "source": [
    "New: 1. Single-Step PPO: \"SinglePPOEnv\"\n",
    "\n",
    "Environment definition (rename explicitly):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6597bad74c5aa6c5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SHAP records (Test Phase): 12964\n",
      "Scaled SHAP metrics (Test phase):   Start_Date   End_Date  mean_abs_shap_Mkt-RF  mean_abs_shap_SMB  \\\n",
      "0 2006-06-09 2006-06-22              0.746145           0.844451   \n",
      "1 2006-06-23 2006-07-07              0.591442           1.321563   \n",
      "2 2006-07-10 2006-07-21              0.701747           1.144933   \n",
      "3 2006-07-24 2006-08-04              0.235944           0.440245   \n",
      "4 2006-08-07 2006-08-18              0.154516           0.162799   \n",
      "\n",
      "   mean_abs_shap_HML  mean_abs_shap_RMW  mean_abs_shap_CMA  shap_std_Mkt-RF  \\\n",
      "0          -0.052021           0.381862           0.096910         0.011057   \n",
      "1           0.365858          -0.052443           0.296386         0.154940   \n",
      "2           0.386793           0.880681           0.881446         0.060338   \n",
      "3           0.654832          -0.166087           0.466175        -0.063344   \n",
      "4           0.291578           0.199758           0.683642        -0.078770   \n",
      "\n",
      "   shap_std_SMB  shap_std_HML  shap_std_RMW  shap_std_CMA  \\\n",
      "0      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "1      0.234299     -0.015797     -0.176936     -0.097054   \n",
      "2      0.231865     -0.042080      0.119016      0.183408   \n",
      "3     -0.035748     -0.005399     -0.152201     -0.022909   \n",
      "4     -0.076416     -0.051296     -0.101779      0.214690   \n",
      "\n",
      "   mean_abs_over_std_Mkt-RF  mean_abs_over_std_SMB  mean_abs_over_std_HML  \\\n",
      "0                 -0.194962               0.223477              -0.325955   \n",
      "1                 -1.320173              -0.899827              -0.939413   \n",
      "2                 -0.896670              -1.127286              -0.119374   \n",
      "3                 -0.873857              -0.283181               0.435469   \n",
      "4                 -0.139662              -0.179884              -0.054696   \n",
      "\n",
      "   mean_abs_over_std_RMW  mean_abs_over_std_CMA  \n",
      "0              -0.676347              -1.377567  \n",
      "1               0.648182              -0.200381  \n",
      "2               0.319011              -0.088274  \n",
      "3              -0.831263              -0.322296  \n",
      "4               0.211424              -1.114314  \n",
      "Daily regimes (aligned):             mean_abs_shap_Mkt-RF  mean_abs_shap_SMB  mean_abs_shap_HML  \\\n",
      "Date                                                                     \n",
      "2006-06-09              0.746145           0.844451          -0.052021   \n",
      "2006-06-12              0.746145           0.844451          -0.052021   \n",
      "2006-06-13              0.746145           0.844451          -0.052021   \n",
      "2006-06-14              0.746145           0.844451          -0.052021   \n",
      "2006-06-15              0.746145           0.844451          -0.052021   \n",
      "\n",
      "            mean_abs_shap_RMW  mean_abs_shap_CMA  shap_std_Mkt-RF  \\\n",
      "Date                                                                \n",
      "2006-06-09           0.381862            0.09691         0.011057   \n",
      "2006-06-12           0.381862            0.09691         0.011057   \n",
      "2006-06-13           0.381862            0.09691         0.011057   \n",
      "2006-06-14           0.381862            0.09691         0.011057   \n",
      "2006-06-15           0.381862            0.09691         0.011057   \n",
      "\n",
      "            shap_std_SMB  shap_std_HML  shap_std_RMW  shap_std_CMA  \\\n",
      "Date                                                                 \n",
      "2006-06-09      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "2006-06-12      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "2006-06-13      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "2006-06-14      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "2006-06-15      0.052918     -0.134875     -0.053576     -0.067324   \n",
      "\n",
      "            mean_abs_over_std_Mkt-RF  mean_abs_over_std_SMB  \\\n",
      "Date                                                          \n",
      "2006-06-09                 -0.194962               0.223477   \n",
      "2006-06-12                 -0.194962               0.223477   \n",
      "2006-06-13                 -0.194962               0.223477   \n",
      "2006-06-14                 -0.194962               0.223477   \n",
      "2006-06-15                 -0.194962               0.223477   \n",
      "\n",
      "            mean_abs_over_std_HML  mean_abs_over_std_RMW  \\\n",
      "Date                                                       \n",
      "2006-06-09              -0.325955              -0.676347   \n",
      "2006-06-12              -0.325955              -0.676347   \n",
      "2006-06-13              -0.325955              -0.676347   \n",
      "2006-06-14              -0.325955              -0.676347   \n",
      "2006-06-15              -0.325955              -0.676347   \n",
      "\n",
      "            mean_abs_over_std_CMA  \n",
      "Date                               \n",
      "2006-06-09              -1.377567  \n",
      "2006-06-12              -1.377567  \n",
      "2006-06-13              -1.377567  \n",
      "2006-06-14              -1.377567  \n",
      "2006-06-15              -1.377567  \n",
      "Merged normalized data preview:                   BA      AMGN       DIS       NKE       HON       MMM  \\\n",
      "Date                                                                     \n",
      "2006-06-09 -0.410708 -0.719982 -1.062918  0.296119 -1.334177 -0.986970   \n",
      "2006-06-12 -1.500823 -0.709680 -0.867092 -0.032437 -0.500863 -0.363230   \n",
      "2006-06-13 -0.549310  0.016436 -1.256317  0.130897 -0.370934 -0.190166   \n",
      "2006-06-14  2.936579  0.346382  0.803866  0.449253  0.632941 -0.073700   \n",
      "2006-06-15  1.522270  0.052613  0.971762  0.956243  1.471639  0.811592   \n",
      "\n",
      "                 CAT        KO        PG       AXP  ...  \\\n",
      "Date                                                ...   \n",
      "2006-06-09  0.438097  0.287575 -0.500826  0.029074  ...   \n",
      "2006-06-12 -0.928663 -0.517800 -0.260928 -0.559349  ...   \n",
      "2006-06-13 -0.027736 -0.218557 -0.326322 -0.548646  ...   \n",
      "2006-06-14  0.836117 -0.239334  1.102934  0.417602  ...   \n",
      "2006-06-15  2.474911  0.435180  0.045444  0.677312  ...   \n",
      "\n",
      "            mean_abs_over_std_SMB  mean_abs_over_std_HML  \\\n",
      "Date                                                       \n",
      "2006-06-09               0.223477              -0.325955   \n",
      "2006-06-12               0.223477              -0.325955   \n",
      "2006-06-13               0.223477              -0.325955   \n",
      "2006-06-14               0.223477              -0.325955   \n",
      "2006-06-15               0.223477              -0.325955   \n",
      "\n",
      "            mean_abs_over_std_RMW  mean_abs_over_std_CMA    Mkt-RF       SMB  \\\n",
      "Date                                                                           \n",
      "2006-06-09              -0.676347              -1.377567 -0.393593 -0.374663   \n",
      "2006-06-12              -0.676347              -1.377567 -1.243634 -1.953367   \n",
      "2006-06-13              -0.676347              -1.377567 -0.973910 -0.734170   \n",
      "2006-06-14              -0.676347              -1.377567  0.342021  0.188043   \n",
      "2006-06-15              -0.676347              -1.377567  1.870462  1.766746   \n",
      "\n",
      "                 HML       RMW       CMA        RF  \n",
      "Date                                                \n",
      "2006-06-09  0.015913  0.365865  0.285723  1.598139  \n",
      "2006-06-12  0.351442  0.654112 -0.133271  1.598139  \n",
      "2006-06-13 -0.481167  0.388038 -0.028523  1.598139  \n",
      "2006-06-14 -0.294762  0.277174  0.678529  1.598139  \n",
      "2006-06-15  0.214745 -0.764949  0.128600  1.598139  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data explicitly\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Explicitly filter only 'Test' phase SHAP metrics\n",
    "shap_metrics_test = shap_metrics[shap_metrics['Phase'] == 'Test'].copy()\n",
    "\n",
    "# Verify explicitly\n",
    "print(f\"Total SHAP records (Test Phase): {len(shap_metrics_test)}\")\n",
    "\n",
    "# Select SHAP metrics explicitly\n",
    "selected_columns = [\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA',\n",
    "    'mean_abs_over_std_Mkt-RF', 'mean_abs_over_std_SMB', 'mean_abs_over_std_HML',\n",
    "    'mean_abs_over_std_RMW', 'mean_abs_over_std_CMA'\n",
    "]\n",
    "\n",
    "# Aggregate SHAP metrics explicitly by Start_Date and End_Date across stocks\n",
    "shap_agg = shap_metrics_test.groupby(['Start_Date', 'End_Date'])[selected_columns].mean().reset_index()\n",
    "\n",
    "# Explicitly scale SHAP metrics\n",
    "scaler_shap = StandardScaler()\n",
    "shap_agg[selected_columns] = scaler_shap.fit_transform(shap_agg[selected_columns])\n",
    "\n",
    "# Verify explicitly scaled SHAP metrics\n",
    "print(\"Scaled SHAP metrics (Test phase):\", shap_agg.head())\n",
    "\n",
    "# Explicitly map SHAP intervals to daily returns\n",
    "daily_regimes = pd.DataFrame(index=stock_returns.index)\n",
    "\n",
    "for _, row in shap_agg.iterrows():\n",
    "    mask = (daily_regimes.index >= row['Start_Date']) & (daily_regimes.index <= row['End_Date'])\n",
    "    daily_regimes.loc[mask, selected_columns] = row[selected_columns].values\n",
    "\n",
    "# Explicit forward-fill for continuity\n",
    "daily_regimes.ffill(inplace=True)\n",
    "daily_regimes.dropna(inplace=True)\n",
    "\n",
    "# Verify explicitly aligned daily regimes\n",
    "print(\"Daily regimes (aligned):\", daily_regimes.head())\n",
    "\n",
    "# Normalize explicitly factor returns\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize explicitly stock returns\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Merge explicitly into final dataset\n",
    "merged_data = stock_returns_norm.join(daily_regimes, how='inner').join(factor_returns_norm, rsuffix='_factor').dropna()\n",
    "\n",
    "# Explicit final dataset verification\n",
    "print(\"Merged normalized data preview:\", merged_data.head())\n",
    "\n",
    "# Save explicitly final aligned dataset\n",
    "merged_data.to_csv(\"final_merged_data.csv\")\n",
    "\n",
    "start_date = merged_data.index.min()\n",
    "end_date = merged_data.index.max()\n",
    "\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "raw_stock_returns = stock_returns.loc[start_date:end_date].copy()\n",
    "raw_stock_returns.to_csv(\"aligned_raw_stock_returns.csv\")\n",
    "\n",
    "stock_returns_norm_filter = stock_returns_norm.loc[start_date:end_date].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T23:32:24.119627Z",
     "start_time": "2025-04-12T23:32:22.031085Z"
    }
   },
   "id": "50052cf6eee1b086",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class SinglePPOEnv(gym.Env):\n",
    "    def __init__(self, returns_df, regime_df, raw_returns_df):\n",
    "        super().__init__()\n",
    "        self.stock_returns = returns_df.values\n",
    "        self.regime_features = regime_df.values\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "\n",
    "        # Adjust observation space shape accordingly\n",
    "        obs_dim = self.n_assets + self.regime_features.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_dim,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        stock_returns = self.stock_returns[self.current_step]\n",
    "        regime = self.regime_features[self.current_step]\n",
    "\n",
    "        obs = np.concatenate([stock_returns, regime])\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        action = action / action_sum if action_sum != 0 else np.ones_like(action) / len(action)\n",
    "\n",
    "        # Reward calculated explicitly using raw returns\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T23:32:27.081272Z",
     "start_time": "2025-04-12T23:32:27.063811Z"
    }
   },
   "id": "16986ba29a0650f7",
   "execution_count": 8
  },
  {
   "cell_type": "raw",
   "source": [
    "# reb every day\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "records = []\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\nStarting Window {i+1}/{total_windows}\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start+train_window]\n",
    "    test_df = merged_data.iloc[start+train_window:start+train_window+test_window+1]\n",
    "\n",
    "    env = DummyVecEnv([\n",
    "        lambda: SinglePPOEnv(train_df[tickers], train_df[selected_columns])\n",
    "    ])\n",
    "\n",
    "    model = PPO('MlpPolicy', env, verbose=0)\n",
    "    print(\"Training PPO model...\")\n",
    "    model.learn(total_timesteps=10000)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    print(\"Starting out-of-sample evaluation...\")\n",
    "    env_test = SinglePPOEnv(test_df[tickers], test_df[selected_columns])\n",
    "    obs = env_test.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    test_dates = test_df.index[:-1]\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env_test.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        records.append({\n",
    "            'Date': test_dates[step_idx],\n",
    "            'Window': i,\n",
    "            'Step': step_idx,\n",
    "            'Reward': reward,\n",
    "            **{ticker: weight for ticker, weight in zip(tickers, action)}\n",
    "        })\n",
    "\n",
    "        step_idx += 1\n",
    "\n",
    "    # print(f\"Window {i+1} completed, Steps: {step_idx}\")\n",
    "    print(f\"Window {i+1}/{total_windows} completed. Total Steps: {step_idx}, Total Out-of-Sample Reward: {total_reward:.4f}\")\n",
    "\n",
    "# Save explicitly final results\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"All windows completed successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "456e4f509a40f0be"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Starting Training Window 1/69\n",
      "Training Period: 2006-06-09 to 2007-06-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_0.zip\n",
      "\n",
      "Testing Period: 2007-06-12 to 2007-09-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2007-06-12\n",
      "Holding period: 2007-06-12 to 2007-07-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1129), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0149), 'NKE': np.float32(0.0161), 'HON': np.float32(0.0), 'MMM': np.float32(0.0021), 'CAT': np.float32(0.0541), 'KO': np.float32(0.018), 'PG': np.float32(0.0), 'AXP': np.float32(0.0709), 'GS': np.float32(0.0581), 'JPM': np.float32(0.1283), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0167), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0395), 'IBM': np.float32(0.05), 'MSFT': np.float32(0.0222), 'TRV': np.float32(0.0005), 'UNH': np.float32(0.0379), 'CVX': np.float32(0.0656), 'JNJ': np.float32(0.0146), 'MRK': np.float32(0.0759), 'AMZN': np.float32(0.0601), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0133), 'VZ': np.float32(0.1284)}\n",
      "Cumulative reward for holding period: -0.9916\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2007-07-12\n",
      "Holding period: 2007-07-12 to 2007-08-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0756), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1864), 'GS': np.float32(0.0578), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0426), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1157), 'IBM': np.float32(0.0551), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0763), 'CVX': np.float32(0.0306), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0955), 'AMZN': np.float32(0.1406), 'WMT': np.float32(0.1036), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0202)}\n",
      "Cumulative reward for holding period: -0.9910\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2007-08-10\n",
      "Holding period: 2007-08-10 to 2007-09-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1698), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1001), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1587), 'PG': np.float32(0.0), 'AXP': np.float32(0.0342), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.2002), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0036), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0067), 'TRV': np.float32(0.1374), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0138), 'JNJ': np.float32(0.0179), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0151), 'WMT': np.float32(0.1426), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9992\n",
      "\n",
      "==============================\n",
      "Starting Training Window 2/69\n",
      "Training Period: 2006-09-08 to 2007-09-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_1.zip\n",
      "\n",
      "Testing Period: 2007-09-11 to 2007-12-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2007-09-11\n",
      "Holding period: 2007-09-11 to 2007-10-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0457), 'HON': np.float32(0.0161), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0017), 'KO': np.float32(0.1126), 'PG': np.float32(0.0678), 'AXP': np.float32(0.0), 'GS': np.float32(0.0658), 'JPM': np.float32(0.1007), 'MCD': np.float32(0.015), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0068), 'CRM': np.float32(0.0644), 'CSCO': np.float32(0.0222), 'IBM': np.float32(0.0201), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0926), 'UNH': np.float32(0.1426), 'CVX': np.float32(0.0065), 'JNJ': np.float32(0.0503), 'MRK': np.float32(0.0052), 'AMZN': np.float32(0.0856), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0164), 'VZ': np.float32(0.0618)}\n",
      "Cumulative reward for holding period: 9.6846\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2007-10-10\n",
      "Holding period: 2007-10-10 to 2007-11-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0095), 'DIS': np.float32(0.0062), 'NKE': np.float32(0.0443), 'HON': np.float32(0.1854), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0393), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0225), 'MCD': np.float32(0.0), 'HD': np.float32(0.091), 'AAPL': np.float32(0.0095), 'CRM': np.float32(0.0179), 'CSCO': np.float32(0.0373), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1245), 'TRV': np.float32(0.0447), 'UNH': np.float32(0.1145), 'CVX': np.float32(0.0513), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0709), 'AMZN': np.float32(0.0369), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0052), 'VZ': np.float32(0.0892)}\n",
      "Cumulative reward for holding period: -1.1113\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2007-11-08\n",
      "Holding period: 2007-11-08 to 2007-12-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0406), 'DIS': np.float32(0.1681), 'NKE': np.float32(0.0711), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0586), 'KO': np.float32(0.0), 'PG': np.float32(0.065), 'AXP': np.float32(0.03), 'GS': np.float32(0.0), 'JPM': np.float32(0.0308), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0122), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.2486), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0434), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1117), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0608), 'VZ': np.float32(0.059)}\n",
      "Cumulative reward for holding period: -1.0001\n",
      "\n",
      "==============================\n",
      "Starting Training Window 3/69\n",
      "Training Period: 2006-12-07 to 2007-12-07\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_2.zip\n",
      "\n",
      "Testing Period: 2007-12-10 to 2008-03-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2007-12-10\n",
      "Holding period: 2007-12-10 to 2008-01-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.2062), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.01), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0405), 'AAPL': np.float32(0.0032), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.09), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.4079), 'UNH': np.float32(0.0529), 'CVX': np.float32(0.0082), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.181), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9949\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2008-01-10\n",
      "Holding period: 2008-01-10 to 2008-02-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1359), 'NKE': np.float32(0.0), 'HON': np.float32(0.0756), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1311), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0409), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0248), 'AAPL': np.float32(0.0352), 'CRM': np.float32(0.1336), 'CSCO': np.float32(0.0492), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0466), 'TRV': np.float32(0.1199), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0655), 'JNJ': np.float32(0.0146), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0308), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0963), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2008-02-11\n",
      "Holding period: 2008-02-11 to 2008-03-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0883), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0631), 'NKE': np.float32(0.0067), 'HON': np.float32(0.0), 'MMM': np.float32(0.0357), 'CAT': np.float32(0.0281), 'KO': np.float32(0.0139), 'PG': np.float32(0.0), 'AXP': np.float32(0.0246), 'GS': np.float32(0.0), 'JPM': np.float32(0.0443), 'MCD': np.float32(0.0), 'HD': np.float32(0.0453), 'AAPL': np.float32(0.0685), 'CRM': np.float32(0.0308), 'CSCO': np.float32(0.0208), 'IBM': np.float32(0.0139), 'MSFT': np.float32(0.1033), 'TRV': np.float32(0.1111), 'UNH': np.float32(0.0181), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0628), 'WMT': np.float32(0.0973), 'INTC': np.float32(0.0537), 'VZ': np.float32(0.0696)}\n",
      "Cumulative reward for holding period: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Training Window 4/69\n",
      "Training Period: 2007-03-13 to 2008-03-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_3.zip\n",
      "\n",
      "Testing Period: 2008-03-12 to 2008-06-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2008-03-12\n",
      "Holding period: 2008-03-12 to 2008-04-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1087), 'NKE': np.float32(0.0), 'HON': np.float32(0.0613), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0448), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1038), 'GS': np.float32(0.0533), 'JPM': np.float32(0.0526), 'MCD': np.float32(0.0), 'HD': np.float32(0.009), 'AAPL': np.float32(0.0956), 'CRM': np.float32(0.0958), 'CSCO': np.float32(0.1811), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0028), 'UNH': np.float32(0.0824), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0323), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.057), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0194), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9977\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2008-04-11\n",
      "Holding period: 2008-04-11 to 2008-05-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.126), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1023), 'NKE': np.float32(0.0), 'HON': np.float32(0.043), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0806), 'PG': np.float32(0.0), 'AXP': np.float32(0.0484), 'GS': np.float32(0.0785), 'JPM': np.float32(0.0179), 'MCD': np.float32(0.0), 'HD': np.float32(0.0461), 'AAPL': np.float32(0.1202), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0345), 'TRV': np.float32(0.0772), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0913), 'WMT': np.float32(0.0795), 'INTC': np.float32(0.0547), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.4644\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2008-05-12\n",
      "Holding period: 2008-05-12 to 2008-06-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0507), 'PG': np.float32(0.0009), 'AXP': np.float32(0.0), 'GS': np.float32(0.0562), 'JPM': np.float32(0.1136), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0771), 'CRM': np.float32(0.046), 'CSCO': np.float32(0.0877), 'IBM': np.float32(0.001), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1713), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.179), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.2166)}\n",
      "Cumulative reward for holding period: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Training Window 5/69\n",
      "Training Period: 2007-06-12 to 2008-06-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_4.zip\n",
      "\n",
      "Testing Period: 2008-06-11 to 2008-09-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2008-06-11\n",
      "Holding period: 2008-06-11 to 2008-07-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0094), 'DIS': np.float32(0.1045), 'NKE': np.float32(0.1489), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0904), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1083), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1287), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1948), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0112), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1272), 'INTC': np.float32(0.0766), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9941\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2008-07-11\n",
      "Holding period: 2008-07-11 to 2008-08-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1547), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0003), 'KO': np.float32(0.004), 'PG': np.float32(0.0097), 'AXP': np.float32(0.0992), 'GS': np.float32(0.0807), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0539), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1089), 'CSCO': np.float32(0.0835), 'IBM': np.float32(0.0396), 'MSFT': np.float32(0.1165), 'TRV': np.float32(0.039), 'UNH': np.float32(0.0922), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1177), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.9101\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2008-08-11\n",
      "Holding period: 2008-08-11 to 2008-09-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.059), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1517), 'KO': np.float32(0.0492), 'PG': np.float32(0.0882), 'AXP': np.float32(0.0144), 'GS': np.float32(0.0), 'JPM': np.float32(0.0132), 'MCD': np.float32(0.0272), 'HD': np.float32(0.057), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0239), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0098), 'TRV': np.float32(0.1421), 'UNH': np.float32(0.1279), 'CVX': np.float32(0.0864), 'JNJ': np.float32(0.0186), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0631), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0682), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9964\n",
      "\n",
      "==============================\n",
      "Starting Training Window 6/69\n",
      "Training Period: 2007-09-11 to 2008-09-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_5.zip\n",
      "\n",
      "Testing Period: 2008-09-10 to 2008-12-09 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2008-09-10\n",
      "Holding period: 2008-09-10 to 2008-10-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0591), 'DIS': np.float32(0.1616), 'NKE': np.float32(0.0), 'HON': np.float32(0.1222), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1635), 'KO': np.float32(0.0), 'PG': np.float32(0.0345), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0338), 'MCD': np.float32(0.0), 'HD': np.float32(0.056), 'AAPL': np.float32(0.0673), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0052), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0935), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0701), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1331)}\n",
      "Cumulative reward for holding period: -0.6312\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2008-10-09\n",
      "Holding period: 2008-10-09 to 2008-11-06\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1711), 'DIS': np.float32(0.0242), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0983), 'KO': np.float32(0.0), 'PG': np.float32(0.043), 'AXP': np.float32(0.0), 'GS': np.float32(0.0352), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.137), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0166), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0267), 'CVX': np.float32(0.0691), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1027), 'AMZN': np.float32(0.0545), 'WMT': np.float32(0.0342), 'INTC': np.float32(0.1872), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -427.4065\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2008-11-07\n",
      "Holding period: 2008-11-07 to 2008-12-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0096), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0263), 'HON': np.float32(0.0167), 'MMM': np.float32(0.0), 'CAT': np.float32(0.19), 'KO': np.float32(0.0932), 'PG': np.float32(0.0306), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0085), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0866), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0293), 'TRV': np.float32(0.0555), 'UNH': np.float32(0.2166), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1648), 'WMT': np.float32(0.0012), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0713)}\n",
      "Cumulative reward for holding period: -4764.2487\n",
      "\n",
      "==============================\n",
      "Starting Training Window 7/69\n",
      "Training Period: 2007-12-10 to 2008-12-08\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_6.zip\n",
      "\n",
      "Testing Period: 2008-12-09 to 2009-03-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2008-12-09\n",
      "Holding period: 2008-12-09 to 2009-01-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1177), 'AMGN': np.float32(0.0907), 'DIS': np.float32(0.058), 'NKE': np.float32(0.0452), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0084), 'AXP': np.float32(0.0), 'GS': np.float32(0.1384), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0105), 'AAPL': np.float32(0.0021), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0665), 'IBM': np.float32(0.0891), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1888), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1558), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0028), 'VZ': np.float32(0.0261)}\n",
      "Cumulative reward for holding period: -0.9929\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2009-01-09\n",
      "Holding period: 2009-01-09 to 2009-02-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0783), 'AMGN': np.float32(0.1823), 'DIS': np.float32(0.0474), 'NKE': np.float32(0.0578), 'HON': np.float32(0.0), 'MMM': np.float32(0.0225), 'CAT': np.float32(0.0258), 'KO': np.float32(0.0881), 'PG': np.float32(0.0), 'AXP': np.float32(0.0176), 'GS': np.float32(0.0), 'JPM': np.float32(0.1209), 'MCD': np.float32(0.0), 'HD': np.float32(0.0358), 'AAPL': np.float32(0.1021), 'CRM': np.float32(0.0036), 'CSCO': np.float32(0.0291), 'IBM': np.float32(0.0151), 'MSFT': np.float32(0.0438), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0253), 'AMZN': np.float32(0.1045), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 9.6861\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2009-02-10\n",
      "Holding period: 2009-02-10 to 2009-03-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0608), 'AMGN': np.float32(0.06), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1164), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0372), 'KO': np.float32(0.0305), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.1132), 'JPM': np.float32(0.0314), 'MCD': np.float32(0.0), 'HD': np.float32(0.0314), 'AAPL': np.float32(0.0509), 'CRM': np.float32(0.0378), 'CSCO': np.float32(0.0197), 'IBM': np.float32(0.0197), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1502), 'MRK': np.float32(0.0413), 'AMZN': np.float32(0.0409), 'WMT': np.float32(0.0573), 'INTC': np.float32(0.1012), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9969\n",
      "\n",
      "==============================\n",
      "Starting Training Window 8/69\n",
      "Training Period: 2008-03-12 to 2009-03-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_7.zip\n",
      "\n",
      "Testing Period: 2009-03-12 to 2009-06-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2009-03-12\n",
      "Holding period: 2009-03-12 to 2009-04-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0498), 'AMGN': np.float32(0.0591), 'DIS': np.float32(0.1243), 'NKE': np.float32(0.0878), 'HON': np.float32(0.0), 'MMM': np.float32(0.0501), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1246), 'GS': np.float32(0.0624), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0389), 'HD': np.float32(0.014), 'AAPL': np.float32(0.097), 'CRM': np.float32(0.129), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0375), 'MSFT': np.float32(0.0511), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0091), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.041), 'INTC': np.float32(0.0243), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8331\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2009-04-13\n",
      "Holding period: 2009-04-13 to 2009-05-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1019), 'DIS': np.float32(0.1814), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.1646), 'AXP': np.float32(0.0), 'GS': np.float32(0.0069), 'JPM': np.float32(0.0), 'MCD': np.float32(0.2082), 'HD': np.float32(0.0716), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0193), 'MSFT': np.float32(0.0232), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1022), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1208)}\n",
      "Cumulative reward for holding period: -0.9889\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2009-05-12\n",
      "Holding period: 2009-05-12 to 2009-06-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0323), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0748), 'HON': np.float32(0.0284), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.027), 'AXP': np.float32(0.0), 'GS': np.float32(0.1197), 'JPM': np.float32(0.119), 'MCD': np.float32(0.0892), 'HD': np.float32(0.1275), 'AAPL': np.float32(0.0877), 'CRM': np.float32(0.0676), 'CSCO': np.float32(0.0137), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0599), 'TRV': np.float32(0.0274), 'UNH': np.float32(0.0), 'CVX': np.float32(0.076), 'JNJ': np.float32(0.0497), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9881\n",
      "\n",
      "==============================\n",
      "Starting Training Window 9/69\n",
      "Training Period: 2008-06-11 to 2009-06-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_8.zip\n",
      "\n",
      "Testing Period: 2009-06-11 to 2009-09-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2009-06-11\n",
      "Holding period: 2009-06-11 to 2009-07-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0727), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.002), 'MMM': np.float32(0.1232), 'CAT': np.float32(0.0012), 'KO': np.float32(0.0976), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0761), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1287), 'HD': np.float32(0.091), 'AAPL': np.float32(0.1097), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0563), 'IBM': np.float32(0.0811), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.102), 'MRK': np.float32(0.0011), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0573), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9896\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2009-07-13\n",
      "Holding period: 2009-07-13 to 2009-08-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0152), 'NKE': np.float32(0.0195), 'HON': np.float32(0.1027), 'MMM': np.float32(0.1723), 'CAT': np.float32(0.0954), 'KO': np.float32(0.0), 'PG': np.float32(0.1252), 'AXP': np.float32(0.077), 'GS': np.float32(0.0394), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0633), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.2198), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0399), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0293), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0011)}\n",
      "Cumulative reward for holding period: 60.7271\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2009-08-11\n",
      "Holding period: 2009-08-11 to 2009-09-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1093), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1002), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0133), 'PG': np.float32(0.0), 'AXP': np.float32(0.0286), 'GS': np.float32(0.0235), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0423), 'HD': np.float32(0.0), 'AAPL': np.float32(0.029), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1033), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.2784), 'UNH': np.float32(0.0725), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1145), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0756), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0094)}\n",
      "Cumulative reward for holding period: -1.4380\n",
      "\n",
      "==============================\n",
      "Starting Training Window 10/69\n",
      "Training Period: 2008-09-10 to 2009-09-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_9.zip\n",
      "\n",
      "Testing Period: 2009-09-10 to 2009-12-09 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2009-09-10\n",
      "Holding period: 2009-09-10 to 2009-10-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0885), 'NKE': np.float32(0.0), 'HON': np.float32(0.0495), 'MMM': np.float32(0.0294), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0494), 'AXP': np.float32(0.0822), 'GS': np.float32(0.0117), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0859), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0335), 'IBM': np.float32(0.0286), 'MSFT': np.float32(0.0626), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0244), 'JNJ': np.float32(0.0579), 'MRK': np.float32(0.2146), 'AMZN': np.float32(0.1317), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0503)}\n",
      "Cumulative reward for holding period: -1.2423\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2009-10-09\n",
      "Holding period: 2009-10-09 to 2009-11-06\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1024), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0019), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0348), 'AXP': np.float32(0.0), 'GS': np.float32(0.1314), 'JPM': np.float32(0.0983), 'MCD': np.float32(0.1264), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0596), 'IBM': np.float32(0.0402), 'MSFT': np.float32(0.1981), 'TRV': np.float32(0.0891), 'UNH': np.float32(0.0977), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.02)}\n",
      "Cumulative reward for holding period: -1.2040\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2009-11-09\n",
      "Holding period: 2009-11-09 to 2009-12-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0947), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1277), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0267), 'PG': np.float32(0.0344), 'AXP': np.float32(0.0), 'GS': np.float32(0.0458), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0696), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0862), 'IBM': np.float32(0.0143), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1711), 'UNH': np.float32(0.0985), 'CVX': np.float32(0.1258), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0669), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0383), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9905\n",
      "\n",
      "==============================\n",
      "Starting Training Window 11/69\n",
      "Training Period: 2008-12-09 to 2009-12-08\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_10.zip\n",
      "\n",
      "Testing Period: 2009-12-09 to 2010-03-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2009-12-09\n",
      "Holding period: 2009-12-09 to 2010-01-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0547), 'AMGN': np.float32(0.0442), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0422), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1064), 'AAPL': np.float32(0.0204), 'CRM': np.float32(0.0305), 'CSCO': np.float32(0.0925), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0358), 'UNH': np.float32(0.1106), 'CVX': np.float32(0.0625), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1464), 'WMT': np.float32(0.0823), 'INTC': np.float32(0.1715), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.3000\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2010-01-11\n",
      "Holding period: 2010-01-11 to 2010-02-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0517), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0022), 'MMM': np.float32(0.1088), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0727), 'AXP': np.float32(0.0901), 'GS': np.float32(0.0257), 'JPM': np.float32(0.0225), 'MCD': np.float32(0.0258), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0376), 'CRM': np.float32(0.1526), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1279), 'MSFT': np.float32(0.0825), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1057), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0395), 'AMZN': np.float32(0.055), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0010\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2010-02-10\n",
      "Holding period: 2010-02-10 to 2010-03-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1526), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0372), 'HON': np.float32(0.0093), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0164), 'AXP': np.float32(0.0497), 'GS': np.float32(0.0), 'JPM': np.float32(0.0395), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0512), 'CRM': np.float32(0.0807), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0047), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.2296), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0078), 'JNJ': np.float32(0.0033), 'MRK': np.float32(0.0548), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1066), 'INTC': np.float32(0.1567), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 6.9437\n",
      "\n",
      "==============================\n",
      "Starting Training Window 12/69\n",
      "Training Period: 2009-03-12 to 2010-03-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_11.zip\n",
      "\n",
      "Testing Period: 2010-03-12 to 2010-06-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2010-03-12\n",
      "Holding period: 2010-03-12 to 2010-04-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0384), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0517), 'HON': np.float32(0.0478), 'MMM': np.float32(0.0419), 'CAT': np.float32(0.0628), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0933), 'GS': np.float32(0.0055), 'JPM': np.float32(0.0171), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1115), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0295), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.059), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1454), 'CVX': np.float32(0.0803), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0979), 'AMZN': np.float32(0.0002), 'WMT': np.float32(0.0), 'INTC': np.float32(0.118), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 1.5629\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2010-04-13\n",
      "Holding period: 2010-04-13 to 2010-05-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0178), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0585), 'MMM': np.float32(0.0309), 'CAT': np.float32(0.1186), 'KO': np.float32(0.0259), 'PG': np.float32(0.1267), 'AXP': np.float32(0.0466), 'GS': np.float32(0.0092), 'JPM': np.float32(0.0033), 'MCD': np.float32(0.0394), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0251), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1763), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0261), 'MRK': np.float32(0.1341), 'AMZN': np.float32(0.0239), 'WMT': np.float32(0.1013), 'INTC': np.float32(0.0362), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2010-05-12\n",
      "Holding period: 2010-05-12 to 2010-06-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0367), 'AMGN': np.float32(0.1513), 'DIS': np.float32(0.0443), 'NKE': np.float32(0.1693), 'HON': np.float32(0.0), 'MMM': np.float32(0.0962), 'CAT': np.float32(0.0118), 'KO': np.float32(0.0951), 'PG': np.float32(0.0), 'AXP': np.float32(0.0914), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0045), 'HD': np.float32(0.0317), 'AAPL': np.float32(0.061), 'CRM': np.float32(0.0156), 'CSCO': np.float32(0.0207), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0604), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1099)}\n",
      "Cumulative reward for holding period: -1.0001\n",
      "\n",
      "==============================\n",
      "Starting Training Window 13/69\n",
      "Training Period: 2009-06-11 to 2010-06-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_12.zip\n",
      "\n",
      "Testing Period: 2010-06-11 to 2010-09-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2010-06-11\n",
      "Holding period: 2010-06-11 to 2010-07-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0457), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0918), 'NKE': np.float32(0.0638), 'HON': np.float32(0.0), 'MMM': np.float32(0.1992), 'CAT': np.float32(0.0333), 'KO': np.float32(0.1083), 'PG': np.float32(0.0682), 'AXP': np.float32(0.067), 'GS': np.float32(0.0529), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0261), 'HD': np.float32(0.0241), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0623), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0211), 'JNJ': np.float32(0.0028), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0126), 'WMT': np.float32(0.1064), 'INTC': np.float32(0.0143), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9862\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2010-07-13\n",
      "Holding period: 2010-07-13 to 2010-08-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0075), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0891), 'NKE': np.float32(0.0), 'HON': np.float32(0.0216), 'MMM': np.float32(0.1073), 'CAT': np.float32(0.0743), 'KO': np.float32(0.11), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0078), 'MCD': np.float32(0.0), 'HD': np.float32(0.0033), 'AAPL': np.float32(0.0748), 'CRM': np.float32(0.0965), 'CSCO': np.float32(0.0899), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0419), 'UNH': np.float32(0.1136), 'CVX': np.float32(0.1213), 'JNJ': np.float32(0.0204), 'MRK': np.float32(0.0029), 'AMZN': np.float32(0.0052), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0127)}\n",
      "Cumulative reward for holding period: -5.2999\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2010-08-11\n",
      "Holding period: 2010-08-11 to 2010-09-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0603), 'AMGN': np.float32(0.1326), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0417), 'HON': np.float32(0.0), 'MMM': np.float32(0.0905), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0432), 'AXP': np.float32(0.1472), 'GS': np.float32(0.0928), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0434), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0626), 'MSFT': np.float32(0.1129), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0435), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1293), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0011\n",
      "\n",
      "==============================\n",
      "Starting Training Window 14/69\n",
      "Training Period: 2009-09-10 to 2010-09-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_13.zip\n",
      "\n",
      "Testing Period: 2010-09-10 to 2010-12-09 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2010-09-10\n",
      "Holding period: 2010-09-10 to 2010-10-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1818), 'AMGN': np.float32(0.0469), 'DIS': np.float32(0.0596), 'NKE': np.float32(0.0), 'HON': np.float32(0.1833), 'MMM': np.float32(0.0056), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0583), 'AXP': np.float32(0.1452), 'GS': np.float32(0.1138), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1481), 'IBM': np.float32(0.0409), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0158), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0005)}\n",
      "Cumulative reward for holding period: -0.6784\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2010-10-11\n",
      "Holding period: 2010-10-11 to 2010-11-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0297), 'AMGN': np.float32(0.0314), 'DIS': np.float32(0.0056), 'NKE': np.float32(0.0), 'HON': np.float32(0.0517), 'MMM': np.float32(0.0871), 'CAT': np.float32(0.0996), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0165), 'JPM': np.float32(0.1023), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0206), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1808), 'TRV': np.float32(0.0479), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0087), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0236), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1228), 'INTC': np.float32(0.0218), 'VZ': np.float32(0.15)}\n",
      "Cumulative reward for holding period: -0.9221\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2010-11-09\n",
      "Holding period: 2010-11-09 to 2010-12-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1073), 'KO': np.float32(0.0), 'PG': np.float32(0.1925), 'AXP': np.float32(0.0144), 'GS': np.float32(0.157), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0314), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1283), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0179), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0431), 'CVX': np.float32(0.0928), 'JNJ': np.float32(0.0928), 'MRK': np.float32(0.0339), 'AMZN': np.float32(0.0114), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0217), 'VZ': np.float32(0.0553)}\n",
      "Cumulative reward for holding period: -1.0044\n",
      "\n",
      "==============================\n",
      "Starting Training Window 15/69\n",
      "Training Period: 2009-12-09 to 2010-12-08\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_14.zip\n",
      "\n",
      "Testing Period: 2010-12-09 to 2011-03-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2010-12-09\n",
      "Holding period: 2010-12-09 to 2011-01-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0442), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1527), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0653), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0362), 'MCD': np.float32(0.0), 'HD': np.float32(0.0277), 'AAPL': np.float32(0.0496), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1756), 'IBM': np.float32(0.1091), 'MSFT': np.float32(0.004), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.2196), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1045), 'VZ': np.float32(0.0115)}\n",
      "Cumulative reward for holding period: 0.4236\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2011-01-10\n",
      "Holding period: 2011-01-10 to 2011-02-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0406), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0457), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0786), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0009), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1525), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0699), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1894), 'TRV': np.float32(0.145), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0884), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1288), 'AMZN': np.float32(0.0283), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0318)}\n",
      "Cumulative reward for holding period: -1.2179\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2011-02-09\n",
      "Holding period: 2011-02-09 to 2011-03-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0391), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0495), 'CAT': np.float32(0.0), 'KO': np.float32(0.0055), 'PG': np.float32(0.2075), 'AXP': np.float32(0.0547), 'GS': np.float32(0.0), 'JPM': np.float32(0.1302), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1932), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1672), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0365), 'UNH': np.float32(0.0), 'CVX': np.float32(0.039), 'JNJ': np.float32(0.0553), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0183), 'VZ': np.float32(0.0041)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Training Window 16/69\n",
      "Training Period: 2010-03-12 to 2011-03-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_15.zip\n",
      "\n",
      "Testing Period: 2011-03-11 to 2011-06-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2011-03-11\n",
      "Holding period: 2011-03-11 to 2011-04-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0432), 'AMGN': np.float32(0.0162), 'DIS': np.float32(0.0532), 'NKE': np.float32(0.0641), 'HON': np.float32(0.0448), 'MMM': np.float32(0.0186), 'CAT': np.float32(0.0483), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0979), 'GS': np.float32(0.0813), 'JPM': np.float32(0.0009), 'MCD': np.float32(0.045), 'HD': np.float32(0.0456), 'AAPL': np.float32(0.0292), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0462), 'IBM': np.float32(0.0652), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0507), 'JNJ': np.float32(0.0581), 'MRK': np.float32(0.0036), 'AMZN': np.float32(0.0583), 'WMT': np.float32(0.1297), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1577\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2011-04-11\n",
      "Holding period: 2011-04-11 to 2011-05-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.3041), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0547), 'KO': np.float32(0.0), 'PG': np.float32(0.0401), 'AXP': np.float32(0.0), 'GS': np.float32(0.0313), 'JPM': np.float32(0.1561), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.178), 'CVX': np.float32(0.0762), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0296), 'AMZN': np.float32(0.1299), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.7833\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2011-05-11\n",
      "Holding period: 2011-05-11 to 2011-06-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0257), 'AMGN': np.float32(0.0725), 'DIS': np.float32(0.0178), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0218), 'CAT': np.float32(0.2339), 'KO': np.float32(0.0277), 'PG': np.float32(0.1528), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0088), 'CRM': np.float32(0.0432), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0563), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0653), 'UNH': np.float32(0.0173), 'CVX': np.float32(0.0131), 'JNJ': np.float32(0.0081), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.2357), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0207\n",
      "\n",
      "==============================\n",
      "Starting Training Window 17/69\n",
      "Training Period: 2010-06-11 to 2011-06-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_16.zip\n",
      "\n",
      "Testing Period: 2011-06-10 to 2011-09-09 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2011-06-10\n",
      "Holding period: 2011-06-10 to 2011-07-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1529), 'AMGN': np.float32(0.0768), 'DIS': np.float32(0.0658), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0743), 'CAT': np.float32(0.0), 'KO': np.float32(0.0769), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0942), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0328), 'CRM': np.float32(0.0141), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0272), 'TRV': np.float32(0.0936), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0016), 'JNJ': np.float32(0.1187), 'MRK': np.float32(0.0399), 'AMZN': np.float32(0.067), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0641), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9417\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2011-07-12\n",
      "Holding period: 2011-07-12 to 2011-08-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.121), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1094), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.103), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0286), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0235), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.2132), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0689), 'TRV': np.float32(0.0152), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0315), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1079), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0832), 'VZ': np.float32(0.0946)}\n",
      "Cumulative reward for holding period: -0.8479\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2011-08-10\n",
      "Holding period: 2011-08-10 to 2011-09-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1121), 'AMGN': np.float32(0.3482), 'DIS': np.float32(0.0378), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0674), 'PG': np.float32(0.0177), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0548), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.013), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0073), 'MRK': np.float32(0.0754), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.2663), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.6873\n",
      "\n",
      "==============================\n",
      "Starting Training Window 18/69\n",
      "Training Period: 2010-09-10 to 2011-09-08\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_17.zip\n",
      "\n",
      "Testing Period: 2011-09-09 to 2011-12-08 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2011-09-09\n",
      "Holding period: 2011-09-09 to 2011-10-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1346), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0856), 'CAT': np.float32(0.0503), 'KO': np.float32(0.0), 'PG': np.float32(0.0044), 'AXP': np.float32(0.0547), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0314), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1778), 'IBM': np.float32(0.1181), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0649), 'UNH': np.float32(0.1119), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1475), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0188), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -4.0726\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2011-10-10\n",
      "Holding period: 2011-10-10 to 2011-11-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0094), 'AXP': np.float32(0.1616), 'GS': np.float32(0.0), 'JPM': np.float32(0.032), 'MCD': np.float32(0.0361), 'HD': np.float32(0.1898), 'AAPL': np.float32(0.0918), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0548), 'TRV': np.float32(0.0682), 'UNH': np.float32(0.1197), 'CVX': np.float32(0.0158), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1898), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0309)}\n",
      "Cumulative reward for holding period: -1.0012\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2011-11-08\n",
      "Holding period: 2011-11-08 to 2011-12-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0031), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.05), 'AXP': np.float32(0.0218), 'GS': np.float32(0.0604), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1907), 'AAPL': np.float32(0.1406), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0177), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.128), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0374), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0338), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1561), 'INTC': np.float32(0.1604), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9989\n",
      "\n",
      "==============================\n",
      "Starting Training Window 19/69\n",
      "Training Period: 2010-12-09 to 2011-12-07\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_18.zip\n",
      "\n",
      "Testing Period: 2011-12-08 to 2012-03-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2011-12-08\n",
      "Holding period: 2011-12-08 to 2012-01-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0332), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0119), 'HON': np.float32(0.0405), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1754), 'PG': np.float32(0.0077), 'AXP': np.float32(0.1549), 'GS': np.float32(0.0539), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1254), 'AAPL': np.float32(0.0167), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.032), 'IBM': np.float32(0.1239), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0107), 'MRK': np.float32(0.0555), 'AMZN': np.float32(0.0306), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0162), 'VZ': np.float32(0.1115)}\n",
      "Cumulative reward for holding period: -0.8952\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2012-01-10\n",
      "Holding period: 2012-01-10 to 2012-02-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.1205), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.2105), 'MCD': np.float32(0.0075), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0587), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0632), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0909), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1994), 'MRK': np.float32(0.0327), 'AMZN': np.float32(0.0599), 'WMT': np.float32(0.1193), 'INTC': np.float32(0.0051), 'VZ': np.float32(0.0324)}\n",
      "Cumulative reward for holding period: 2.6046\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2012-02-09\n",
      "Holding period: 2012-02-09 to 2012-03-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0065), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0723), 'MMM': np.float32(0.0334), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0988), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0411), 'CRM': np.float32(0.1092), 'CSCO': np.float32(0.147), 'IBM': np.float32(0.0882), 'MSFT': np.float32(0.0952), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0256), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.076), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1178), 'INTC': np.float32(0.0889), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.7093\n",
      "\n",
      "==============================\n",
      "Starting Training Window 20/69\n",
      "Training Period: 2011-03-11 to 2012-03-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_19.zip\n",
      "\n",
      "Testing Period: 2012-03-12 to 2012-06-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2012-03-12\n",
      "Holding period: 2012-03-12 to 2012-04-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0126), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0474), 'NKE': np.float32(0.0334), 'HON': np.float32(0.0316), 'MMM': np.float32(0.1554), 'CAT': np.float32(0.0503), 'KO': np.float32(0.0), 'PG': np.float32(0.0745), 'AXP': np.float32(0.0262), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0653), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0719), 'CSCO': np.float32(0.0563), 'IBM': np.float32(0.0398), 'MSFT': np.float32(0.0776), 'TRV': np.float32(0.0005), 'UNH': np.float32(0.0166), 'CVX': np.float32(0.0133), 'JNJ': np.float32(0.0323), 'MRK': np.float32(0.0136), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0532), 'INTC': np.float32(0.1282), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0076\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2012-04-11\n",
      "Holding period: 2012-04-11 to 2012-05-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.165), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0704), 'MMM': np.float32(0.0812), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1573), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1551), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1009), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0041), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0585), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0533), 'VZ': np.float32(0.1544)}\n",
      "Cumulative reward for holding period: -0.9822\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2012-05-10\n",
      "Holding period: 2012-05-10 to 2012-06-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0355), 'AMGN': np.float32(0.0068), 'DIS': np.float32(0.0), 'NKE': np.float32(0.2307), 'HON': np.float32(0.0), 'MMM': np.float32(0.0341), 'CAT': np.float32(0.0444), 'KO': np.float32(0.0106), 'PG': np.float32(0.0), 'AXP': np.float32(0.0097), 'GS': np.float32(0.0993), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0179), 'HD': np.float32(0.0601), 'AAPL': np.float32(0.0465), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0785), 'IBM': np.float32(0.057), 'MSFT': np.float32(0.0927), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0163), 'JNJ': np.float32(0.0881), 'MRK': np.float32(0.0521), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0197), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Training Window 21/69\n",
      "Training Period: 2011-06-10 to 2012-06-08\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_20.zip\n",
      "\n",
      "Testing Period: 2012-06-11 to 2012-09-10 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2012-06-11\n",
      "Holding period: 2012-06-11 to 2012-07-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1464), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1263), 'NKE': np.float32(0.0158), 'HON': np.float32(0.0354), 'MMM': np.float32(0.1042), 'CAT': np.float32(0.0), 'KO': np.float32(0.094), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1272), 'MCD': np.float32(0.0), 'HD': np.float32(0.0319), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0676), 'TRV': np.float32(0.0), 'UNH': np.float32(0.06), 'CVX': np.float32(0.0154), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0185), 'WMT': np.float32(0.0967), 'INTC': np.float32(0.0534), 'VZ': np.float32(0.0072)}\n",
      "Cumulative reward for holding period: -1.0581\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2012-07-11\n",
      "Holding period: 2012-07-11 to 2012-08-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0373), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0634), 'NKE': np.float32(0.0786), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0692), 'AXP': np.float32(0.0), 'GS': np.float32(0.0158), 'JPM': np.float32(0.125), 'MCD': np.float32(0.0651), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0791), 'CRM': np.float32(0.1106), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1394), 'TRV': np.float32(0.0326), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0668), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0705), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0467)}\n",
      "Cumulative reward for holding period: -0.7504\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2012-08-09\n",
      "Holding period: 2012-08-09 to 2012-09-07\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1261), 'AMGN': np.float32(0.0253), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0504), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0957), 'GS': np.float32(0.0), 'JPM': np.float32(0.2043), 'MCD': np.float32(0.0), 'HD': np.float32(0.0019), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1763), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0832), 'TRV': np.float32(0.055), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0567), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0405), 'WMT': np.float32(0.0845), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.1842\n",
      "\n",
      "==============================\n",
      "Starting Training Window 22/69\n",
      "Training Period: 2011-09-09 to 2012-09-07\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_21.zip\n",
      "\n",
      "Testing Period: 2012-09-10 to 2012-12-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2012-09-10\n",
      "Holding period: 2012-09-10 to 2012-10-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0149), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.002), 'NKE': np.float32(0.0424), 'HON': np.float32(0.0), 'MMM': np.float32(0.0763), 'CAT': np.float32(0.0397), 'KO': np.float32(0.0), 'PG': np.float32(0.0104), 'AXP': np.float32(0.1435), 'GS': np.float32(0.1282), 'JPM': np.float32(0.171), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0129), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0486), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.2228), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0874)}\n",
      "Cumulative reward for holding period: 1.1975\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2012-10-09\n",
      "Holding period: 2012-10-09 to 2012-11-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.06), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0658), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0136), 'KO': np.float32(0.0), 'PG': np.float32(0.0369), 'AXP': np.float32(0.2041), 'GS': np.float32(0.1888), 'JPM': np.float32(0.016), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0027), 'IBM': np.float32(0.0999), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1228), 'CVX': np.float32(0.0971), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0361), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0562), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9983\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2012-11-09\n",
      "Holding period: 2012-11-09 to 2012-12-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1269), 'AMGN': np.float32(0.0311), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.2242), 'GS': np.float32(0.1113), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1808), 'HD': np.float32(0.0063), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0424), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0124), 'JNJ': np.float32(0.1074), 'MRK': np.float32(0.119), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0019), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0364)}\n",
      "Cumulative reward for holding period: 0.2568\n",
      "\n",
      "==============================\n",
      "Starting Training Window 23/69\n",
      "Training Period: 2011-12-08 to 2012-12-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_22.zip\n",
      "\n",
      "Testing Period: 2012-12-11 to 2013-03-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2012-12-11\n",
      "Holding period: 2012-12-11 to 2013-01-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1021), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0111), 'CAT': np.float32(0.0049), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.1153), 'JPM': np.float32(0.029), 'MCD': np.float32(0.1549), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1161), 'CRM': np.float32(0.0319), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1336), 'MSFT': np.float32(0.0494), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0742), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.027), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0758), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0748)}\n",
      "Cumulative reward for holding period: -0.9131\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2013-01-11\n",
      "Holding period: 2013-01-11 to 2013-02-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0695), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0615), 'GS': np.float32(0.1159), 'JPM': np.float32(0.0162), 'MCD': np.float32(0.0651), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1815), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1144), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1023), 'CVX': np.float32(0.1039), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0136), 'WMT': np.float32(0.0563), 'INTC': np.float32(0.0998), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1578\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2013-02-12\n",
      "Holding period: 2013-02-12 to 2013-03-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0861), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0013), 'NKE': np.float32(0.0857), 'HON': np.float32(0.0389), 'MMM': np.float32(0.0017), 'CAT': np.float32(0.0), 'KO': np.float32(0.07), 'PG': np.float32(0.0), 'AXP': np.float32(0.0091), 'GS': np.float32(0.0986), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0534), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0436), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1009), 'JNJ': np.float32(0.1096), 'MRK': np.float32(0.1545), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0935), 'VZ': np.float32(0.053)}\n",
      "Cumulative reward for holding period: -0.4028\n",
      "\n",
      "==============================\n",
      "Starting Training Window 24/69\n",
      "Training Period: 2012-03-12 to 2013-03-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_23.zip\n",
      "\n",
      "Testing Period: 2013-03-14 to 2013-06-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2013-03-14\n",
      "Holding period: 2013-03-14 to 2013-04-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0551), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0387), 'HON': np.float32(0.0798), 'MMM': np.float32(0.0025), 'CAT': np.float32(0.0004), 'KO': np.float32(0.0678), 'PG': np.float32(0.0), 'AXP': np.float32(0.0466), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1631), 'HD': np.float32(0.0156), 'AAPL': np.float32(0.0877), 'CRM': np.float32(0.1231), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1057), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0615), 'CVX': np.float32(0.1026), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0326), 'AMZN': np.float32(0.0172), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.2022\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2013-04-15\n",
      "Holding period: 2013-04-15 to 2013-05-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1123), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0987), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0913), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0802), 'AXP': np.float32(0.0968), 'GS': np.float32(0.1028), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1275), 'HD': np.float32(0.0461), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1651), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0115), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0608), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0071), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 1.4945\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2013-05-14\n",
      "Holding period: 2013-05-14 to 2013-06-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0645), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0887), 'NKE': np.float32(0.0264), 'HON': np.float32(0.0749), 'MMM': np.float32(0.1349), 'CAT': np.float32(0.1138), 'KO': np.float32(0.0), 'PG': np.float32(0.0668), 'AXP': np.float32(0.0), 'GS': np.float32(0.1826), 'JPM': np.float32(0.0), 'MCD': np.float32(0.032), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0535), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0153), 'MSFT': np.float32(0.0383), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1083), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9962\n",
      "\n",
      "==============================\n",
      "Starting Training Window 25/69\n",
      "Training Period: 2012-06-11 to 2013-06-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_24.zip\n",
      "\n",
      "Testing Period: 2013-06-13 to 2013-09-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2013-06-13\n",
      "Holding period: 2013-06-13 to 2013-07-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0667), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0278), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0195), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1365), 'CRM': np.float32(0.2081), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1693), 'UNH': np.float32(0.091), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.152), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0774), 'INTC': np.float32(0.0517), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.5738\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2013-07-15\n",
      "Holding period: 2013-07-15 to 2013-08-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0207), 'AMGN': np.float32(0.0289), 'DIS': np.float32(0.0709), 'NKE': np.float32(0.1762), 'HON': np.float32(0.0441), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0158), 'GS': np.float32(0.0069), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0263), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0097), 'IBM': np.float32(0.2644), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0139), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1152), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0483), 'AMZN': np.float32(0.0002), 'WMT': np.float32(0.1586), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.7699\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2013-08-13\n",
      "Holding period: 2013-08-13 to 2013-09-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1403), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0258), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0025), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0141), 'AAPL': np.float32(0.1005), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0975), 'UNH': np.float32(0.0201), 'CVX': np.float32(0.0259), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0184), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.4114), 'INTC': np.float32(0.1436), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1109\n",
      "\n",
      "==============================\n",
      "Starting Training Window 26/69\n",
      "Training Period: 2012-09-10 to 2013-09-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_25.zip\n",
      "\n",
      "Testing Period: 2013-09-12 to 2013-12-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2013-09-12\n",
      "Holding period: 2013-09-12 to 2013-10-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0221), 'NKE': np.float32(0.0), 'HON': np.float32(0.0822), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1294), 'KO': np.float32(0.0651), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.075), 'JPM': np.float32(0.0871), 'MCD': np.float32(0.1031), 'HD': np.float32(0.0102), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0675), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0464), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0652), 'JNJ': np.float32(0.1459), 'MRK': np.float32(0.0334), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0518), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0155)}\n",
      "Cumulative reward for holding period: -0.9769\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2013-10-11\n",
      "Holding period: 2013-10-11 to 2013-11-08\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0862), 'CAT': np.float32(0.0), 'KO': np.float32(0.0615), 'PG': np.float32(0.0291), 'AXP': np.float32(0.0671), 'GS': np.float32(0.1754), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0913), 'HD': np.float32(0.1336), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0388), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1231), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0157), 'JNJ': np.float32(0.0489), 'MRK': np.float32(0.0234), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1059)}\n",
      "Cumulative reward for holding period: 0.4019\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2013-11-11\n",
      "Holding period: 2013-11-11 to 2013-12-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0514), 'AMGN': np.float32(0.0548), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1293), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.015), 'AXP': np.float32(0.0611), 'GS': np.float32(0.1023), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1681), 'CSCO': np.float32(0.0558), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1433), 'UNH': np.float32(0.1675), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0417), 'VZ': np.float32(0.0097)}\n",
      "Cumulative reward for holding period: -0.6149\n",
      "\n",
      "==============================\n",
      "Starting Training Window 27/69\n",
      "Training Period: 2012-12-11 to 2013-12-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_26.zip\n",
      "\n",
      "Testing Period: 2013-12-11 to 2014-03-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2013-12-11\n",
      "Holding period: 2013-12-11 to 2014-01-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1718), 'DIS': np.float32(0.0763), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.2033), 'CAT': np.float32(0.0), 'KO': np.float32(0.0069), 'PG': np.float32(0.0422), 'AXP': np.float32(0.0), 'GS': np.float32(0.0544), 'JPM': np.float32(0.0934), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0382), 'CRM': np.float32(0.0227), 'CSCO': np.float32(0.1722), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0234), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0786), 'JNJ': np.float32(0.0089), 'MRK': np.float32(0.0055), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0022)}\n",
      "Cumulative reward for holding period: 1.5978\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2014-01-13\n",
      "Holding period: 2014-01-13 to 2014-02-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0845), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0947), 'HON': np.float32(0.0), 'MMM': np.float32(0.0663), 'CAT': np.float32(0.0), 'KO': np.float32(0.0983), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0553), 'AAPL': np.float32(0.031), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0815), 'IBM': np.float32(0.0123), 'MSFT': np.float32(0.0221), 'TRV': np.float32(0.034), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0701), 'MRK': np.float32(0.0946), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0711), 'INTC': np.float32(0.1841), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0029\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2014-02-12\n",
      "Holding period: 2014-02-12 to 2014-03-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0048), 'DIS': np.float32(0.1062), 'NKE': np.float32(0.0), 'HON': np.float32(0.0236), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0758), 'PG': np.float32(0.0958), 'AXP': np.float32(0.0652), 'GS': np.float32(0.0771), 'JPM': np.float32(0.0793), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1219), 'MSFT': np.float32(0.0484), 'TRV': np.float32(0.064), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0112), 'AMZN': np.float32(0.0087), 'WMT': np.float32(0.0646), 'INTC': np.float32(0.0864), 'VZ': np.float32(0.0671)}\n",
      "Cumulative reward for holding period: -0.7971\n",
      "\n",
      "==============================\n",
      "Starting Training Window 28/69\n",
      "Training Period: 2013-03-14 to 2014-03-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_27.zip\n",
      "\n",
      "Testing Period: 2014-03-14 to 2014-06-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2014-03-14\n",
      "Holding period: 2014-03-14 to 2014-04-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1121), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0637), 'HON': np.float32(0.008), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0187), 'KO': np.float32(0.0993), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0463), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0339), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0978), 'CSCO': np.float32(0.2202), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0222), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0821), 'CVX': np.float32(0.004), 'JNJ': np.float32(0.0814), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0261), 'WMT': np.float32(0.0676), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0165)}\n",
      "Cumulative reward for holding period: -1.0549\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2014-04-14\n",
      "Holding period: 2014-04-14 to 2014-05-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0438), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1309), 'NKE': np.float32(0.0768), 'HON': np.float32(0.0556), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0157), 'KO': np.float32(0.0), 'PG': np.float32(0.0947), 'AXP': np.float32(0.0), 'GS': np.float32(0.06), 'JPM': np.float32(0.0409), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1234), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0668), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1053), 'MRK': np.float32(0.1051), 'AMZN': np.float32(0.0185), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0229), 'VZ': np.float32(0.0395)}\n",
      "Cumulative reward for holding period: 0.2518\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2014-05-14\n",
      "Holding period: 2014-05-14 to 2014-06-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1152), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1105), 'NKE': np.float32(1e-04), 'HON': np.float32(0.0137), 'MMM': np.float32(0.0871), 'CAT': np.float32(0.0312), 'KO': np.float32(0.0548), 'PG': np.float32(0.0707), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0574), 'MCD': np.float32(0.0334), 'HD': np.float32(0.041), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1487), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.082), 'TRV': np.float32(0.111), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0109), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0324), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.5454\n",
      "\n",
      "==============================\n",
      "Starting Training Window 29/69\n",
      "Training Period: 2013-06-13 to 2014-06-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_28.zip\n",
      "\n",
      "Testing Period: 2014-06-13 to 2014-09-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2014-06-13\n",
      "Holding period: 2014-06-13 to 2014-07-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0978), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0879), 'HON': np.float32(0.1167), 'MMM': np.float32(0.0029), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.2548), 'AXP': np.float32(0.0), 'GS': np.float32(0.0765), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1947), 'TRV': np.float32(0.0838), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0452), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0193), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0204), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.0300\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2014-07-15\n",
      "Holding period: 2014-07-15 to 2014-08-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0722), 'AMGN': np.float32(0.0633), 'DIS': np.float32(0.0364), 'NKE': np.float32(0.1227), 'HON': np.float32(0.1335), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0359), 'KO': np.float32(0.024), 'PG': np.float32(0.1047), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0372), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0388), 'CVX': np.float32(0.041), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0206), 'AMZN': np.float32(0.0327), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1832), 'VZ': np.float32(0.0537)}\n",
      "Cumulative reward for holding period: -1.0498\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2014-08-13\n",
      "Holding period: 2014-08-13 to 2014-09-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1048), 'MMM': np.float32(0.044), 'CAT': np.float32(0.0418), 'KO': np.float32(0.0), 'PG': np.float32(0.0256), 'AXP': np.float32(0.0), 'GS': np.float32(0.0782), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0208), 'CSCO': np.float32(0.1641), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1201), 'TRV': np.float32(0.0009), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0928), 'JNJ': np.float32(0.1965), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0476), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.063)}\n",
      "Cumulative reward for holding period: 0.4401\n",
      "\n",
      "==============================\n",
      "Starting Training Window 30/69\n",
      "Training Period: 2013-09-12 to 2014-09-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_29.zip\n",
      "\n",
      "Testing Period: 2014-09-12 to 2014-12-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2014-09-12\n",
      "Holding period: 2014-09-12 to 2014-10-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0515), 'HON': np.float32(0.0), 'MMM': np.float32(0.2007), 'CAT': np.float32(0.1488), 'KO': np.float32(0.0397), 'PG': np.float32(0.0), 'AXP': np.float32(0.0074), 'GS': np.float32(0.0765), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1175), 'CSCO': np.float32(0.0248), 'IBM': np.float32(0.0542), 'MSFT': np.float32(0.1285), 'TRV': np.float32(0.0812), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0254), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0438), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2014-10-13\n",
      "Holding period: 2014-10-13 to 2014-11-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0095), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0988), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1262), 'PG': np.float32(0.0), 'AXP': np.float32(0.0344), 'GS': np.float32(0.0), 'JPM': np.float32(0.0371), 'MCD': np.float32(0.0815), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0157), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0401), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1219), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0078), 'MRK': np.float32(0.0667), 'AMZN': np.float32(0.1252), 'WMT': np.float32(0.0798), 'INTC': np.float32(0.1056), 'VZ': np.float32(0.0497)}\n",
      "Cumulative reward for holding period: -0.9965\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2014-11-11\n",
      "Holding period: 2014-11-11 to 2014-12-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0971), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0739), 'NKE': np.float32(0.0557), 'HON': np.float32(0.0), 'MMM': np.float32(0.0854), 'CAT': np.float32(0.2037), 'KO': np.float32(0.0027), 'PG': np.float32(0.0511), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1236), 'AAPL': np.float32(0.0848), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1278), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0822), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0121), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0004\n",
      "\n",
      "==============================\n",
      "Starting Training Window 31/69\n",
      "Training Period: 2013-12-11 to 2014-12-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_30.zip\n",
      "\n",
      "Testing Period: 2014-12-11 to 2015-03-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2014-12-11\n",
      "Holding period: 2014-12-11 to 2015-01-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0435), 'DIS': np.float32(0.0581), 'NKE': np.float32(0.0), 'HON': np.float32(0.1802), 'MMM': np.float32(0.0013), 'CAT': np.float32(0.0), 'KO': np.float32(0.1797), 'PG': np.float32(0.0), 'AXP': np.float32(0.1026), 'GS': np.float32(0.0), 'JPM': np.float32(0.0649), 'MCD': np.float32(0.0), 'HD': np.float32(0.0456), 'AAPL': np.float32(0.0556), 'CRM': np.float32(0.0256), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1318), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.111), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0029\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2015-01-13\n",
      "Holding period: 2015-01-13 to 2015-02-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.1132), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0164), 'MCD': np.float32(0.0), 'HD': np.float32(0.2182), 'AAPL': np.float32(0.0626), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.2028), 'MSFT': np.float32(0.069), 'TRV': np.float32(0.0925), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1859), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0394), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.5673\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2015-02-12\n",
      "Holding period: 2015-02-12 to 2015-03-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0584), 'HON': np.float32(0.0107), 'MMM': np.float32(0.0989), 'CAT': np.float32(0.1479), 'KO': np.float32(0.011), 'PG': np.float32(0.0107), 'AXP': np.float32(0.0), 'GS': np.float32(0.0443), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0323), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0601), 'CSCO': np.float32(0.0867), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0691), 'CVX': np.float32(0.0201), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.081), 'AMZN': np.float32(0.0417), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1538), 'VZ': np.float32(0.0735)}\n",
      "Cumulative reward for holding period: -1.0031\n",
      "\n",
      "==============================\n",
      "Starting Training Window 32/69\n",
      "Training Period: 2014-03-14 to 2015-03-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_31.zip\n",
      "\n",
      "Testing Period: 2015-03-16 to 2015-06-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2015-03-16\n",
      "Holding period: 2015-03-16 to 2015-04-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0443), 'HON': np.float32(0.1402), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0042), 'AXP': np.float32(0.0), 'GS': np.float32(0.0794), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.049), 'AAPL': np.float32(0.219), 'CRM': np.float32(0.0303), 'CSCO': np.float32(0.2559), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0145), 'CVX': np.float32(0.1199), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0279), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0154), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9585\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2015-04-15\n",
      "Holding period: 2015-04-15 to 2015-05-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0922), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1675), 'HON': np.float32(0.0297), 'MMM': np.float32(0.0615), 'CAT': np.float32(0.0445), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0112), 'GS': np.float32(0.0746), 'JPM': np.float32(0.0537), 'MCD': np.float32(0.0), 'HD': np.float32(0.0168), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1074), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0142), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0767), 'WMT': np.float32(0.0391), 'INTC': np.float32(0.1779), 'VZ': np.float32(0.0329)}\n",
      "Cumulative reward for holding period: -0.9566\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2015-05-14\n",
      "Holding period: 2015-05-14 to 2015-06-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1393), 'AMGN': np.float32(0.0474), 'DIS': np.float32(0.1869), 'NKE': np.float32(0.0381), 'HON': np.float32(0.007), 'MMM': np.float32(0.1104), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0975), 'AXP': np.float32(0.0), 'GS': np.float32(0.1328), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1285), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0076), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0341), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0703)}\n",
      "Cumulative reward for holding period: -0.9520\n",
      "\n",
      "==============================\n",
      "Starting Training Window 33/69\n",
      "Training Period: 2014-06-13 to 2015-06-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_32.zip\n",
      "\n",
      "Testing Period: 2015-06-15 to 2015-09-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2015-06-15\n",
      "Holding period: 2015-06-15 to 2015-07-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0331), 'NKE': np.float32(0.0551), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0657), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.2138), 'AAPL': np.float32(0.001), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.2599), 'MSFT': np.float32(0.1271), 'TRV': np.float32(0.0197), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0049), 'JNJ': np.float32(0.0665), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0256), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1276), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1815\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2015-07-15\n",
      "Holding period: 2015-07-15 to 2015-08-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.035), 'DIS': np.float32(0.0969), 'NKE': np.float32(0.011), 'HON': np.float32(0.0266), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0622), 'AXP': np.float32(0.0), 'GS': np.float32(0.0546), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0554), 'AAPL': np.float32(0.0685), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0248), 'IBM': np.float32(0.1562), 'MSFT': np.float32(0.0143), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0079), 'JNJ': np.float32(0.0052), 'MRK': np.float32(0.0132), 'AMZN': np.float32(0.1353), 'WMT': np.float32(0.0179), 'INTC': np.float32(0.1073), 'VZ': np.float32(0.1077)}\n",
      "Cumulative reward for holding period: -1.0072\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2015-08-13\n",
      "Holding period: 2015-08-13 to 2015-09-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0447), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0449), 'HON': np.float32(0.0748), 'MMM': np.float32(0.0116), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0818), 'GS': np.float32(0.0107), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0629), 'HD': np.float32(0.0026), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1754), 'IBM': np.float32(0.0142), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0745), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0305), 'JNJ': np.float32(0.1082), 'MRK': np.float32(0.099), 'AMZN': np.float32(0.0762), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.088)}\n",
      "Cumulative reward for holding period: -0.9927\n",
      "\n",
      "==============================\n",
      "Starting Training Window 34/69\n",
      "Training Period: 2014-09-12 to 2015-09-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_33.zip\n",
      "\n",
      "Testing Period: 2015-09-14 to 2015-12-11 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2015-09-14\n",
      "Holding period: 2015-09-14 to 2015-10-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1632), 'DIS': np.float32(0.1035), 'NKE': np.float32(0.1037), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1216), 'PG': np.float32(0.0614), 'AXP': np.float32(0.0058), 'GS': np.float32(0.0181), 'JPM': np.float32(0.1205), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0121), 'IBM': np.float32(0.0364), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0031), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0089), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0659), 'INTC': np.float32(0.176), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9575\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2015-10-13\n",
      "Holding period: 2015-10-13 to 2015-11-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.146), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0057), 'PG': np.float32(0.0), 'AXP': np.float32(0.1589), 'GS': np.float32(0.0189), 'JPM': np.float32(0.1771), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1576), 'MSFT': np.float32(0.1225), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0048), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.2086), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8914\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2015-11-11\n",
      "Holding period: 2015-11-11 to 2015-12-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0797), 'DIS': np.float32(0.0647), 'NKE': np.float32(0.0956), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1215), 'PG': np.float32(0.0), 'AXP': np.float32(0.0681), 'GS': np.float32(0.0405), 'JPM': np.float32(0.0729), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1397), 'CSCO': np.float32(0.0695), 'IBM': np.float32(0.0834), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.045), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1194), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9962\n",
      "\n",
      "==============================\n",
      "Starting Training Window 35/69\n",
      "Training Period: 2014-12-11 to 2015-12-10\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_34.zip\n",
      "\n",
      "Testing Period: 2015-12-11 to 2016-03-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2015-12-11\n",
      "Holding period: 2015-12-11 to 2016-01-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0501), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.1244), 'JPM': np.float32(0.0), 'MCD': np.float32(0.2231), 'HD': np.float32(0.0274), 'AAPL': np.float32(0.011), 'CRM': np.float32(0.0232), 'CSCO': np.float32(0.0043), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1748), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0414), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1496), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0595), 'VZ': np.float32(0.1112)}\n",
      "Cumulative reward for holding period: -1.0015\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2016-01-13\n",
      "Holding period: 2016-01-13 to 2016-02-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.134), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0256), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.3628), 'HD': np.float32(0.0563), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0412), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1281), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0021), 'JNJ': np.float32(0.0947), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1552), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9956\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2016-02-12\n",
      "Holding period: 2016-02-12 to 2016-03-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0908), 'HON': np.float32(0.1028), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0853), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0324), 'JPM': np.float32(0.0234), 'MCD': np.float32(0.0), 'HD': np.float32(0.0305), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0806), 'CSCO': np.float32(0.0484), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1073), 'UNH': np.float32(0.0818), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0886), 'AMZN': np.float32(0.0805), 'WMT': np.float32(0.0101), 'INTC': np.float32(0.0992), 'VZ': np.float32(0.0384)}\n",
      "Cumulative reward for holding period: 4.3989\n",
      "\n",
      "==============================\n",
      "Starting Training Window 36/69\n",
      "Training Period: 2015-03-16 to 2016-03-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_35.zip\n",
      "\n",
      "Testing Period: 2016-03-15 to 2016-06-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2016-03-15\n",
      "Holding period: 2016-03-15 to 2016-04-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0144), 'DIS': np.float32(0.0017), 'NKE': np.float32(0.0227), 'HON': np.float32(0.0), 'MMM': np.float32(0.1183), 'CAT': np.float32(0.0209), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0737), 'JPM': np.float32(0.0021), 'MCD': np.float32(0.0), 'HD': np.float32(0.1472), 'AAPL': np.float32(0.0574), 'CRM': np.float32(0.0402), 'CSCO': np.float32(0.0926), 'IBM': np.float32(0.005), 'MSFT': np.float32(0.1228), 'TRV': np.float32(0.0077), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0529), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0512), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1691)}\n",
      "Cumulative reward for holding period: -0.7494\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2016-04-14\n",
      "Holding period: 2016-04-14 to 2016-05-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0177), 'NKE': np.float32(0.0), 'HON': np.float32(0.1016), 'MMM': np.float32(0.0038), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0623), 'GS': np.float32(0.0955), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0749), 'AAPL': np.float32(0.0285), 'CRM': np.float32(0.0097), 'CSCO': np.float32(0.06), 'IBM': np.float32(0.0725), 'MSFT': np.float32(0.1638), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0029), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1472), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1399), 'VZ': np.float32(0.0196)}\n",
      "Cumulative reward for holding period: -0.9947\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2016-05-13\n",
      "Holding period: 2016-05-13 to 2016-06-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1319), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1001), 'HON': np.float32(0.0605), 'MMM': np.float32(0.0861), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0736), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0631), 'HD': np.float32(0.0156), 'AAPL': np.float32(0.0656), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0992), 'MSFT': np.float32(0.0857), 'TRV': np.float32(0.0589), 'UNH': np.float32(0.0506), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.034), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0751), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9010\n",
      "\n",
      "==============================\n",
      "Starting Training Window 37/69\n",
      "Training Period: 2015-06-15 to 2016-06-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_36.zip\n",
      "\n",
      "Testing Period: 2016-06-14 to 2016-09-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2016-06-14\n",
      "Holding period: 2016-06-14 to 2016-07-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0122), 'AMGN': np.float32(0.072), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0559), 'CAT': np.float32(0.0), 'KO': np.float32(0.0327), 'PG': np.float32(0.0), 'AXP': np.float32(0.1288), 'GS': np.float32(0.0), 'JPM': np.float32(0.0056), 'MCD': np.float32(0.1202), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0313), 'CRM': np.float32(0.0739), 'CSCO': np.float32(0.0749), 'IBM': np.float32(0.1001), 'MSFT': np.float32(0.0363), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0935), 'CVX': np.float32(0.0319), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0342), 'VZ': np.float32(0.0965)}\n",
      "Cumulative reward for holding period: 0.5619\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2016-07-14\n",
      "Holding period: 2016-07-14 to 2016-08-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0876), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0473), 'PG': np.float32(0.0047), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0642), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0863), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0833), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0188), 'UNH': np.float32(0.0264), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0842), 'AMZN': np.float32(0.039), 'WMT': np.float32(0.3275), 'INTC': np.float32(0.0549), 'VZ': np.float32(0.0758)}\n",
      "Cumulative reward for holding period: -0.3791\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2016-08-12\n",
      "Holding period: 2016-08-12 to 2016-09-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0931), 'AMGN': np.float32(0.0026), 'DIS': np.float32(0.0846), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0796), 'CAT': np.float32(0.0507), 'KO': np.float32(0.0), 'PG': np.float32(0.1233), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0273), 'MCD': np.float32(0.0), 'HD': np.float32(0.0055), 'AAPL': np.float32(0.0194), 'CRM': np.float32(0.095), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0166), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.122), 'UNH': np.float32(0.0454), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0459), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1611), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0248), 'VZ': np.float32(0.0031)}\n",
      "Cumulative reward for holding period: -1.1021\n",
      "\n",
      "==============================\n",
      "Starting Training Window 38/69\n",
      "Training Period: 2015-09-14 to 2016-09-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_37.zip\n",
      "\n",
      "Testing Period: 2016-09-13 to 2016-12-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2016-09-13\n",
      "Holding period: 2016-09-13 to 2016-10-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1241), 'AMGN': np.float32(0.0154), 'DIS': np.float32(0.084), 'NKE': np.float32(0.0357), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0499), 'KO': np.float32(0.0963), 'PG': np.float32(0.0), 'AXP': np.float32(0.0902), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0551), 'AAPL': np.float32(0.0232), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0267), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0143), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1497), 'MRK': np.float32(0.1403), 'AMZN': np.float32(0.0438), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0514)}\n",
      "Cumulative reward for holding period: -0.9879\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2016-10-12\n",
      "Holding period: 2016-10-12 to 2016-11-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0832), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0752), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0762), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0413), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0168), 'CSCO': np.float32(0.1), 'IBM': np.float32(0.0689), 'MSFT': np.float32(0.063), 'TRV': np.float32(0.1296), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1218), 'AMZN': np.float32(0.0146), 'WMT': np.float32(0.1299), 'INTC': np.float32(0.0133), 'VZ': np.float32(0.0661)}\n",
      "Cumulative reward for holding period: -0.7319\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2016-11-10\n",
      "Holding period: 2016-11-10 to 2016-12-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0895), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0497), 'HON': np.float32(0.0288), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1511), 'KO': np.float32(0.0), 'PG': np.float32(0.0484), 'AXP': np.float32(0.1764), 'GS': np.float32(0.0945), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0014), 'HD': np.float32(0.0), 'AAPL': np.float32(0.141), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0279), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0913), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0147), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0854)}\n",
      "Cumulative reward for holding period: 2.3170\n",
      "\n",
      "==============================\n",
      "Starting Training Window 39/69\n",
      "Training Period: 2015-12-11 to 2016-12-09\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_38.zip\n",
      "\n",
      "Testing Period: 2016-12-12 to 2017-03-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2016-12-12\n",
      "Holding period: 2016-12-12 to 2017-01-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0665), 'AMGN': np.float32(0.0664), 'DIS': np.float32(0.074), 'NKE': np.float32(0.0), 'HON': np.float32(0.0633), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0336), 'MCD': np.float32(0.1129), 'HD': np.float32(0.0633), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0236), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0722), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0423), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1436), 'AMZN': np.float32(0.0902), 'WMT': np.float32(0.0191), 'INTC': np.float32(0.0477), 'VZ': np.float32(0.0813)}\n",
      "Cumulative reward for holding period: -0.2220\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2017-01-12\n",
      "Holding period: 2017-01-12 to 2017-02-10\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.2696), 'DIS': np.float32(0.1611), 'NKE': np.float32(0.1179), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.1046), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0252), 'MCD': np.float32(0.1484), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0319), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1412), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 1.4263\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2017-02-13\n",
      "Holding period: 2017-02-13 to 2017-03-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0513), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0388), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0418), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1355), 'MCD': np.float32(0.1376), 'HD': np.float32(0.0731), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0279), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.1188), 'MSFT': np.float32(0.0694), 'TRV': np.float32(0.0972), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0231), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1151), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0703), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.1007\n",
      "\n",
      "==============================\n",
      "Starting Training Window 40/69\n",
      "Training Period: 2016-03-15 to 2017-03-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_39.zip\n",
      "\n",
      "Testing Period: 2017-03-15 to 2017-06-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2017-03-15\n",
      "Holding period: 2017-03-15 to 2017-04-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1258), 'AMGN': np.float32(0.0508), 'DIS': np.float32(0.0068), 'NKE': np.float32(0.0), 'HON': np.float32(0.0864), 'MMM': np.float32(0.0396), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1125), 'GS': np.float32(0.0), 'JPM': np.float32(0.0975), 'MCD': np.float32(0.0262), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1446), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0452), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0547), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.09), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0954), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0245)}\n",
      "Cumulative reward for holding period: -0.9187\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2017-04-13\n",
      "Holding period: 2017-04-13 to 2017-05-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0663), 'AMGN': np.float32(0.0845), 'DIS': np.float32(0.0006), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.1097), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0865), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0677), 'CSCO': np.float32(0.0896), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0351), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0655), 'JNJ': np.float32(0.1397), 'MRK': np.float32(0.0782), 'AMZN': np.float32(0.0739), 'WMT': np.float32(0.0413), 'INTC': np.float32(0.0615), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.3382\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2017-05-15\n",
      "Holding period: 2017-05-15 to 2017-06-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.133), 'AMGN': np.float32(0.0208), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1253), 'MMM': np.float32(0.0606), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0447), 'AXP': np.float32(0.0588), 'GS': np.float32(0.0), 'JPM': np.float32(0.0176), 'MCD': np.float32(0.0), 'HD': np.float32(0.0039), 'AAPL': np.float32(0.0399), 'CRM': np.float32(0.0087), 'CSCO': np.float32(0.1495), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0059), 'TRV': np.float32(0.0422), 'UNH': np.float32(0.1534), 'CVX': np.float32(0.0274), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0006), 'AMZN': np.float32(0.0156), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0922)}\n",
      "Cumulative reward for holding period: -0.4899\n",
      "\n",
      "==============================\n",
      "Starting Training Window 41/69\n",
      "Training Period: 2016-06-14 to 2017-06-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_40.zip\n",
      "\n",
      "Testing Period: 2017-06-14 to 2017-09-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2017-06-14\n",
      "Holding period: 2017-06-14 to 2017-07-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1158), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1351), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0211), 'CAT': np.float32(0.048), 'KO': np.float32(0.0), 'PG': np.float32(0.0412), 'AXP': np.float32(0.0851), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0128), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0267), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0265), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1037), 'MRK': np.float32(0.0629), 'AMZN': np.float32(0.1075), 'WMT': np.float32(0.1778), 'INTC': np.float32(0.0316), 'VZ': np.float32(0.0043)}\n",
      "Cumulative reward for holding period: -0.8790\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2017-07-14\n",
      "Holding period: 2017-07-14 to 2017-08-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0586), 'AMGN': np.float32(0.002), 'DIS': np.float32(0.0273), 'NKE': np.float32(0.0674), 'HON': np.float32(0.0332), 'MMM': np.float32(0.0517), 'CAT': np.float32(0.0206), 'KO': np.float32(0.0521), 'PG': np.float32(0.0096), 'AXP': np.float32(0.0), 'GS': np.float32(0.0136), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0294), 'HD': np.float32(0.0529), 'AAPL': np.float32(0.0082), 'CRM': np.float32(0.0281), 'CSCO': np.float32(0.0412), 'IBM': np.float32(0.0787), 'MSFT': np.float32(0.0656), 'TRV': np.float32(0.0146), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1149), 'MRK': np.float32(0.0389), 'AMZN': np.float32(0.018), 'WMT': np.float32(0.1013), 'INTC': np.float32(0.0719), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.2474\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2017-08-14\n",
      "Holding period: 2017-08-14 to 2017-09-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1104), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0911), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.067), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0265), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0093), 'AAPL': np.float32(0.0366), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0643), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0857), 'CVX': np.float32(0.0641), 'JNJ': np.float32(0.1411), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1008), 'WMT': np.float32(0.0802), 'INTC': np.float32(0.0582), 'VZ': np.float32(0.0649)}\n",
      "Cumulative reward for holding period: -0.8273\n",
      "\n",
      "==============================\n",
      "Starting Training Window 42/69\n",
      "Training Period: 2016-09-13 to 2017-09-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_41.zip\n",
      "\n",
      "Testing Period: 2017-09-13 to 2017-12-12 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2017-09-13\n",
      "Holding period: 2017-09-13 to 2017-10-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1431), 'HON': np.float32(0.1745), 'MMM': np.float32(0.0775), 'CAT': np.float32(0.0067), 'KO': np.float32(0.0), 'PG': np.float32(0.0657), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0356), 'AAPL': np.float32(0.0925), 'CRM': np.float32(0.1691), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0932), 'TRV': np.float32(0.0), 'UNH': np.float32(0.065), 'CVX': np.float32(0.0161), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0609)}\n",
      "Cumulative reward for holding period: -0.5032\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2017-10-12\n",
      "Holding period: 2017-10-12 to 2017-11-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0212), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0903), 'MMM': np.float32(0.0951), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0547), 'AXP': np.float32(0.0), 'GS': np.float32(0.154), 'JPM': np.float32(0.1025), 'MCD': np.float32(0.0376), 'HD': np.float32(0.0542), 'AAPL': np.float32(0.0126), 'CRM': np.float32(0.0833), 'CSCO': np.float32(0.1791), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0452), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0119), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.003), 'WMT': np.float32(0.0555), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.1213\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2017-11-10\n",
      "Holding period: 2017-11-10 to 2017-12-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0723), 'AMGN': np.float32(0.0233), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1551), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0276), 'PG': np.float32(0.0637), 'AXP': np.float32(0.006), 'GS': np.float32(0.0852), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0793), 'HD': np.float32(0.0208), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(1e-04), 'UNH': np.float32(0.1407), 'CVX': np.float32(0.101), 'JNJ': np.float32(0.0951), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0822), 'WMT': np.float32(0.0476), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 5.2344\n",
      "\n",
      "==============================\n",
      "Starting Training Window 43/69\n",
      "Training Period: 2016-12-12 to 2017-12-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_42.zip\n",
      "\n",
      "Testing Period: 2017-12-12 to 2018-03-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2017-12-12\n",
      "Holding period: 2017-12-12 to 2018-01-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0309), 'HON': np.float32(0.0), 'MMM': np.float32(0.0307), 'CAT': np.float32(0.1465), 'KO': np.float32(0.0), 'PG': np.float32(0.0567), 'AXP': np.float32(0.0086), 'GS': np.float32(0.0386), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0455), 'AAPL': np.float32(0.2025), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0657), 'IBM': np.float32(0.0561), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0822), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1631), 'INTC': np.float32(0.0), 'VZ': np.float32(0.073)}\n",
      "Cumulative reward for holding period: 2.2321\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2018-01-12\n",
      "Holding period: 2018-01-12 to 2018-02-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0202), 'AMGN': np.float32(0.1184), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0794), 'CAT': np.float32(0.0), 'KO': np.float32(0.0152), 'PG': np.float32(0.0), 'AXP': np.float32(0.0113), 'GS': np.float32(0.0), 'JPM': np.float32(0.1255), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1615), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1991), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0674), 'UNH': np.float32(0.0642), 'CVX': np.float32(0.0134), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1244), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.4122\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2018-02-13\n",
      "Holding period: 2018-02-13 to 2018-03-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0315), 'AMGN': np.float32(0.1433), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0176), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0373), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1733), 'HD': np.float32(0.0711), 'AAPL': np.float32(0.2447), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0813), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0554), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0027), 'MRK': np.float32(0.0782), 'AMZN': np.float32(0.0636), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9173\n",
      "\n",
      "==============================\n",
      "Starting Training Window 44/69\n",
      "Training Period: 2017-03-15 to 2018-03-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_43.zip\n",
      "\n",
      "Testing Period: 2018-03-15 to 2018-06-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2018-03-15\n",
      "Holding period: 2018-03-15 to 2018-04-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0242), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.2078), 'MMM': np.float32(0.1719), 'CAT': np.float32(0.1561), 'KO': np.float32(0.094), 'PG': np.float32(0.0), 'AXP': np.float32(0.0867), 'GS': np.float32(0.0), 'JPM': np.float32(0.0533), 'MCD': np.float32(0.0), 'HD': np.float32(0.0104), 'AAPL': np.float32(0.0796), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0613), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0179), 'INTC': np.float32(0.0368), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9945\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2018-04-16\n",
      "Holding period: 2018-04-16 to 2018-05-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0994), 'AMGN': np.float32(0.0233), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0194), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0489), 'KO': np.float32(0.0), 'PG': np.float32(0.0293), 'AXP': np.float32(0.0), 'GS': np.float32(0.1421), 'JPM': np.float32(0.0358), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0279), 'IBM': np.float32(0.1142), 'MSFT': np.float32(0.021), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0142), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0197), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1002), 'VZ': np.float32(0.3046)}\n",
      "Cumulative reward for holding period: -0.9772\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2018-05-15\n",
      "Holding period: 2018-05-15 to 2018-06-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1617), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.063), 'PG': np.float32(0.1725), 'AXP': np.float32(0.0), 'GS': np.float32(0.2043), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1113), 'HD': np.float32(0.0061), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.08), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0481), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0189), 'MRK': np.float32(0.0332), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0607), 'VZ': np.float32(0.0403)}\n",
      "Cumulative reward for holding period: -0.6678\n",
      "\n",
      "==============================\n",
      "Starting Training Window 45/69\n",
      "Training Period: 2017-06-14 to 2018-06-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_44.zip\n",
      "\n",
      "Testing Period: 2018-06-14 to 2018-09-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2018-06-14\n",
      "Holding period: 2018-06-14 to 2018-07-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1186), 'DIS': np.float32(0.1182), 'NKE': np.float32(0.0215), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0618), 'KO': np.float32(0.0), 'PG': np.float32(0.0225), 'AXP': np.float32(0.0), 'GS': np.float32(0.1746), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0182), 'CRM': np.float32(0.0696), 'CSCO': np.float32(0.061), 'IBM': np.float32(0.1635), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0692), 'WMT': np.float32(0.1012), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.7310\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2018-07-16\n",
      "Holding period: 2018-07-16 to 2018-08-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1579), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0411), 'NKE': np.float32(0.0), 'HON': np.float32(0.0028), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0759), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0736), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.2019), 'CSCO': np.float32(0.0938), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1212), 'UNH': np.float32(0.0749), 'CVX': np.float32(0.0158), 'JNJ': np.float32(0.0895), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0515), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.7363\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2018-08-14\n",
      "Holding period: 2018-08-14 to 2018-09-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1031), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0905), 'NKE': np.float32(0.0532), 'HON': np.float32(0.1045), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0552), 'KO': np.float32(0.0), 'PG': np.float32(0.0936), 'AXP': np.float32(0.0194), 'GS': np.float32(0.1377), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0028), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0907), 'CSCO': np.float32(0.0928), 'IBM': np.float32(0.0033), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0223), 'UNH': np.float32(0.0552), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0272), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0009), 'INTC': np.float32(0.0474), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.2049\n",
      "\n",
      "==============================\n",
      "Starting Training Window 46/69\n",
      "Training Period: 2017-09-13 to 2018-09-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_45.zip\n",
      "\n",
      "Testing Period: 2018-09-13 to 2018-12-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2018-09-13\n",
      "Holding period: 2018-09-13 to 2018-10-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1118), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1223), 'HON': np.float32(0.0694), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0647), 'KO': np.float32(0.0409), 'PG': np.float32(0.0), 'AXP': np.float32(0.0048), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.005), 'HD': np.float32(0.0207), 'AAPL': np.float32(0.0144), 'CRM': np.float32(0.064), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0773), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0905), 'UNH': np.float32(0.0093), 'CVX': np.float32(0.024), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1824), 'INTC': np.float32(0.0239), 'VZ': np.float32(0.0748)}\n",
      "Cumulative reward for holding period: -0.9289\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2018-10-12\n",
      "Holding period: 2018-10-12 to 2018-11-09\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0919), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0095), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.107), 'CAT': np.float32(0.0), 'KO': np.float32(0.0879), 'PG': np.float32(0.0), 'AXP': np.float32(0.0097), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0225), 'HD': np.float32(0.014), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1147), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0704), 'TRV': np.float32(0.1343), 'UNH': np.float32(0.0422), 'CVX': np.float32(0.2423), 'JNJ': np.float32(0.0535), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.3197\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2018-11-12\n",
      "Holding period: 2018-11-12 to 2018-12-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1439), 'DIS': np.float32(0.0718), 'NKE': np.float32(0.0), 'HON': np.float32(0.0114), 'MMM': np.float32(0.0236), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0265), 'AXP': np.float32(0.0633), 'GS': np.float32(0.103), 'JPM': np.float32(0.1233), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.2554), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0657), 'MRK': np.float32(0.1121), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1999\n",
      "\n",
      "==============================\n",
      "Starting Training Window 47/69\n",
      "Training Period: 2017-12-12 to 2018-12-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_46.zip\n",
      "\n",
      "Testing Period: 2018-12-13 to 2019-03-18 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2018-12-13\n",
      "Holding period: 2018-12-13 to 2019-01-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0908), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0406), 'NKE': np.float32(0.0), 'HON': np.float32(0.1285), 'MMM': np.float32(0.0472), 'CAT': np.float32(0.1096), 'KO': np.float32(0.072), 'PG': np.float32(0.0271), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1103), 'MCD': np.float32(0.014), 'HD': np.float32(0.0051), 'AAPL': np.float32(0.1039), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0074), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0577), 'UNH': np.float32(0.0262), 'CVX': np.float32(0.0612), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0982), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0002\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2019-01-15\n",
      "Holding period: 2019-01-15 to 2019-02-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0571), 'AMGN': np.float32(0.0564), 'DIS': np.float32(0.0126), 'NKE': np.float32(0.1219), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0592), 'AXP': np.float32(0.0), 'GS': np.float32(0.1291), 'JPM': np.float32(0.0579), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0096), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0927), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0105), 'UNH': np.float32(0.1065), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0216), 'MRK': np.float32(0.0667), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1982)}\n",
      "Cumulative reward for holding period: -0.1740\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2019-02-14\n",
      "Holding period: 2019-02-14 to 2019-03-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0898), 'KO': np.float32(0.1501), 'PG': np.float32(0.1206), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.2304), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.2526), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0149), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0229), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1186)}\n",
      "Cumulative reward for holding period: 0.0115\n",
      "\n",
      "==============================\n",
      "Starting Training Window 48/69\n",
      "Training Period: 2018-03-15 to 2019-03-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_47.zip\n",
      "\n",
      "Testing Period: 2019-03-18 to 2019-06-17 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2019-03-18\n",
      "Holding period: 2019-03-18 to 2019-04-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0188), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0096), 'HON': np.float32(0.0505), 'MMM': np.float32(0.0368), 'CAT': np.float32(0.0), 'KO': np.float32(0.038), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0309), 'JPM': np.float32(0.0822), 'MCD': np.float32(0.096), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1923), 'CRM': np.float32(0.0642), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0315), 'TRV': np.float32(0.0692), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.062), 'MRK': np.float32(0.1216), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0963)}\n",
      "Cumulative reward for holding period: -0.2638\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2019-04-16\n",
      "Holding period: 2019-04-16 to 2019-05-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0696), 'NKE': np.float32(0.089), 'HON': np.float32(0.0), 'MMM': np.float32(0.1355), 'CAT': np.float32(0.0105), 'KO': np.float32(0.0162), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1392), 'HD': np.float32(0.0189), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1538), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1), 'UNH': np.float32(0.0247), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0477), 'MRK': np.float32(0.1144), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0259), 'INTC': np.float32(0.0372), 'VZ': np.float32(0.0175)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2019-05-16\n",
      "Holding period: 2019-05-16 to 2019-06-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0513), 'DIS': np.float32(0.0), 'NKE': np.float32(0.043), 'HON': np.float32(0.057), 'MMM': np.float32(0.0211), 'CAT': np.float32(0.0952), 'KO': np.float32(0.0314), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0847), 'MCD': np.float32(0.1564), 'HD': np.float32(0.0347), 'AAPL': np.float32(0.0451), 'CRM': np.float32(0.0383), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0102), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0896), 'UNH': np.float32(0.0283), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0402), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.034), 'VZ': np.float32(0.1395)}\n",
      "Cumulative reward for holding period: -0.9402\n",
      "\n",
      "==============================\n",
      "Starting Training Window 49/69\n",
      "Training Period: 2018-06-14 to 2019-06-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_48.zip\n",
      "\n",
      "Testing Period: 2019-06-17 to 2019-09-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2019-06-17\n",
      "Holding period: 2019-06-17 to 2019-07-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0496), 'AMGN': np.float32(0.0198), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0253), 'HON': np.float32(0.0368), 'MMM': np.float32(0.0946), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0605), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.1327), 'AAPL': np.float32(0.0377), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.2426), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.074), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1829), 'INTC': np.float32(0.0434), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 1.5629\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2019-07-17\n",
      "Holding period: 2019-07-17 to 2019-08-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.113), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1779), 'MMM': np.float32(0.0092), 'CAT': np.float32(0.0555), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.2402), 'JPM': np.float32(0.0772), 'MCD': np.float32(0.0), 'HD': np.float32(0.0628), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1436), 'TRV': np.float32(0.112), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0086)}\n",
      "Cumulative reward for holding period: -0.7681\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2019-08-15\n",
      "Holding period: 2019-08-15 to 2019-09-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.2087), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0326), 'HON': np.float32(0.0), 'MMM': np.float32(0.0759), 'CAT': np.float32(0.0), 'KO': np.float32(0.0797), 'PG': np.float32(0.0), 'AXP': np.float32(0.143), 'GS': np.float32(0.0), 'JPM': np.float32(0.0548), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0515), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0958), 'UNH': np.float32(0.051), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0185), 'AMZN': np.float32(0.0939), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0947), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -2.5570\n",
      "\n",
      "==============================\n",
      "Starting Training Window 50/69\n",
      "Training Period: 2018-09-13 to 2019-09-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_49.zip\n",
      "\n",
      "Testing Period: 2019-09-16 to 2019-12-13 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2019-09-16\n",
      "Holding period: 2019-09-16 to 2019-10-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0394), 'DIS': np.float32(0.1627), 'NKE': np.float32(0.0), 'HON': np.float32(0.1439), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0208), 'KO': np.float32(0.0484), 'PG': np.float32(0.0673), 'AXP': np.float32(0.0), 'GS': np.float32(0.0805), 'JPM': np.float32(0.0), 'MCD': np.float32(0.1574), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0456), 'TRV': np.float32(0.0579), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1213), 'JNJ': np.float32(0.0318), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0231)}\n",
      "Cumulative reward for holding period: -0.9989\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2019-10-15\n",
      "Holding period: 2019-10-15 to 2019-11-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.004), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1555), 'HON': np.float32(0.021), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0277), 'PG': np.float32(0.0945), 'AXP': np.float32(0.0), 'GS': np.float32(0.0188), 'JPM': np.float32(0.0358), 'MCD': np.float32(0.1088), 'HD': np.float32(0.1134), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0219), 'CSCO': np.float32(0.0908), 'IBM': np.float32(0.0306), 'MSFT': np.float32(0.0916), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0054), 'CVX': np.float32(0.055), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.063), 'AMZN': np.float32(0.0229), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0098), 'VZ': np.float32(0.0294)}\n",
      "Cumulative reward for holding period: -0.7803\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2019-11-13\n",
      "Holding period: 2019-11-13 to 2019-12-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0762), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0662), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0113), 'KO': np.float32(0.0119), 'PG': np.float32(0.0332), 'AXP': np.float32(0.0532), 'GS': np.float32(0.0562), 'JPM': np.float32(0.0116), 'MCD': np.float32(0.0457), 'HD': np.float32(0.0384), 'AAPL': np.float32(0.1418), 'CRM': np.float32(0.0706), 'CSCO': np.float32(0.0216), 'IBM': np.float32(0.0305), 'MSFT': np.float32(0.1105), 'TRV': np.float32(0.058), 'UNH': np.float32(0.0219), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0292), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0593), 'INTC': np.float32(0.0525), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.1194\n",
      "\n",
      "==============================\n",
      "Starting Training Window 51/69\n",
      "Training Period: 2018-12-13 to 2019-12-12\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_50.zip\n",
      "\n",
      "Testing Period: 2019-12-13 to 2020-03-17 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2019-12-13\n",
      "Holding period: 2019-12-13 to 2020-01-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1334), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0422), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0363), 'KO': np.float32(0.056), 'PG': np.float32(0.1727), 'AXP': np.float32(0.1843), 'GS': np.float32(0.1772), 'JPM': np.float32(0.0745), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0646), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0587), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.2383\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2020-01-15\n",
      "Holding period: 2020-01-15 to 2020-02-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0707), 'AMGN': np.float32(0.078), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0015), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0201), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1973), 'GS': np.float32(0.0332), 'JPM': np.float32(0.1449), 'MCD': np.float32(0.0908), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0816), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0569), 'IBM': np.float32(0.1115), 'MSFT': np.float32(0.0212), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0691), 'CVX': np.float32(0.0183), 'JNJ': np.float32(0.0048), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0441\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2020-02-14\n",
      "Holding period: 2020-02-14 to 2020-03-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0066), 'AMGN': np.float32(0.1311), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0537), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.047), 'KO': np.float32(0.1548), 'PG': np.float32(0.0), 'AXP': np.float32(0.0692), 'GS': np.float32(0.0), 'JPM': np.float32(0.0721), 'MCD': np.float32(0.1195), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1584), 'CRM': np.float32(0.048), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.07), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0695), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 269.5053\n",
      "\n",
      "==============================\n",
      "Starting Training Window 52/69\n",
      "Training Period: 2019-03-18 to 2020-03-16\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_51.zip\n",
      "\n",
      "Testing Period: 2020-03-17 to 2020-06-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2020-03-17\n",
      "Holding period: 2020-03-17 to 2020-04-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0244), 'HON': np.float32(0.0), 'MMM': np.float32(0.0288), 'CAT': np.float32(0.0232), 'KO': np.float32(0.0), 'PG': np.float32(0.1021), 'AXP': np.float32(0.02), 'GS': np.float32(0.0), 'JPM': np.float32(0.1102), 'MCD': np.float32(0.0684), 'HD': np.float32(0.0353), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0607), 'MSFT': np.float32(0.0032), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0702), 'CVX': np.float32(0.1638), 'JNJ': np.float32(0.0669), 'MRK': np.float32(0.0812), 'AMZN': np.float32(0.0999), 'WMT': np.float32(0.0417), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 165.2075\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2020-04-16\n",
      "Holding period: 2020-04-16 to 2020-05-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0745), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0285), 'HON': np.float32(0.0948), 'MMM': np.float32(0.0477), 'CAT': np.float32(0.0471), 'KO': np.float32(0.093), 'PG': np.float32(0.1136), 'AXP': np.float32(0.0), 'GS': np.float32(0.0415), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0355), 'HD': np.float32(0.0287), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0414), 'CSCO': np.float32(0.0743), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0035), 'UNH': np.float32(0.0545), 'CVX': np.float32(0.0269), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0815), 'AMZN': np.float32(0.0409), 'WMT': np.float32(0.0447), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0275)}\n",
      "Cumulative reward for holding period: -1.0043\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2020-05-15\n",
      "Holding period: 2020-05-15 to 2020-06-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.2019), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0568), 'HON': np.float32(0.0613), 'MMM': np.float32(0.0106), 'CAT': np.float32(0.0698), 'KO': np.float32(0.0), 'PG': np.float32(0.1032), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1276), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.017), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0224), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0564), 'CVX': np.float32(0.0181), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0355), 'AMZN': np.float32(0.007), 'WMT': np.float32(0.0855), 'INTC': np.float32(0.0646), 'VZ': np.float32(0.0623)}\n",
      "Cumulative reward for holding period: 8.4512\n",
      "\n",
      "==============================\n",
      "Starting Training Window 53/69\n",
      "Training Period: 2019-06-17 to 2020-06-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_52.zip\n",
      "\n",
      "Testing Period: 2020-06-16 to 2020-09-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2020-06-16\n",
      "Holding period: 2020-06-16 to 2020-07-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0426), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.1587), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.1051), 'JPM': np.float32(0.157), 'MCD': np.float32(0.021), 'HD': np.float32(0.0372), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.07), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1032), 'TRV': np.float32(0.18), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0471), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0779)}\n",
      "Cumulative reward for holding period: -1.0127\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2020-07-16\n",
      "Holding period: 2020-07-16 to 2020-08-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0765), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0672), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.1288), 'CAT': np.float32(0.1624), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0732), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0824), 'JNJ': np.float32(0.0514), 'MRK': np.float32(0.3581), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8782\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2020-08-14\n",
      "Holding period: 2020-08-14 to 2020-09-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.1677), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0621), 'NKE': np.float32(0.0065), 'HON': np.float32(0.0621), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0599), 'KO': np.float32(0.028), 'PG': np.float32(0.0664), 'AXP': np.float32(0.0272), 'GS': np.float32(0.0136), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0382), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0185), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0613), 'MSFT': np.float32(0.0164), 'TRV': np.float32(0.0461), 'UNH': np.float32(0.1069), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0362), 'MRK': np.float32(0.0848), 'AMZN': np.float32(0.0023), 'WMT': np.float32(0.0068), 'INTC': np.float32(0.089), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9291\n",
      "\n",
      "==============================\n",
      "Starting Training Window 54/69\n",
      "Training Period: 2019-09-16 to 2020-09-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_53.zip\n",
      "\n",
      "Testing Period: 2020-09-15 to 2020-12-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2020-09-15\n",
      "Holding period: 2020-09-15 to 2020-10-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0809), 'NKE': np.float32(0.0269), 'HON': np.float32(0.1278), 'MMM': np.float32(0.0033), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.2019), 'JPM': np.float32(0.2112), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0338), 'CRM': np.float32(0.0873), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1472), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0796), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0229\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2020-10-14\n",
      "Holding period: 2020-10-14 to 2020-11-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0188), 'NKE': np.float32(0.0535), 'HON': np.float32(0.0283), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1234), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0651), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0905), 'AAPL': np.float32(0.0401), 'CRM': np.float32(0.1087), 'CSCO': np.float32(0.1649), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0577), 'TRV': np.float32(0.0654), 'UNH': np.float32(0.1471), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0364)}\n",
      "Cumulative reward for holding period: 0.7230\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2020-11-12\n",
      "Holding period: 2020-11-12 to 2020-12-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0946), 'PG': np.float32(0.0324), 'AXP': np.float32(0.2621), 'GS': np.float32(0.0389), 'JPM': np.float32(0.1061), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1077), 'CRM': np.float32(0.026), 'CSCO': np.float32(0.0895), 'IBM': np.float32(0.0887), 'MSFT': np.float32(0.0964), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0107), 'WMT': np.float32(0.0468), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.6903\n",
      "\n",
      "==============================\n",
      "Starting Training Window 55/69\n",
      "Training Period: 2019-12-13 to 2020-12-11\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_54.zip\n",
      "\n",
      "Testing Period: 2020-12-14 to 2021-03-17 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2020-12-14\n",
      "Holding period: 2020-12-14 to 2021-01-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1886), 'NKE': np.float32(0.0383), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0948), 'GS': np.float32(0.2635), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.12), 'CRM': np.float32(0.19), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0668), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.038)}\n",
      "Cumulative reward for holding period: 7.5568\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2021-01-14\n",
      "Holding period: 2021-01-14 to 2021-02-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0034), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1185), 'NKE': np.float32(0.1268), 'HON': np.float32(0.0104), 'MMM': np.float32(0.1331), 'CAT': np.float32(0.0205), 'KO': np.float32(0.0405), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.084), 'JPM': np.float32(0.0664), 'MCD': np.float32(0.082), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0459), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0471), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0642), 'CVX': np.float32(0.0892), 'JNJ': np.float32(0.0205), 'MRK': np.float32(0.0185), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0287), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.2958\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2021-02-16\n",
      "Holding period: 2021-02-16 to 2021-03-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0953), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.148), 'NKE': np.float32(0.2572), 'HON': np.float32(0.0176), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0874), 'JPM': np.float32(0.0506), 'MCD': np.float32(0.052), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1024), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0397), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.051), 'TRV': np.float32(0.0409), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0581), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0009\n",
      "\n",
      "==============================\n",
      "Starting Training Window 56/69\n",
      "Training Period: 2020-03-17 to 2021-03-16\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_55.zip\n",
      "\n",
      "Testing Period: 2021-03-17 to 2021-06-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2021-03-17\n",
      "Holding period: 2021-03-17 to 2021-04-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1113), 'HON': np.float32(0.1081), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1929), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1442), 'GS': np.float32(0.0), 'JPM': np.float32(0.0228), 'MCD': np.float32(0.0), 'HD': np.float32(0.14), 'AAPL': np.float32(0.0538), 'CRM': np.float32(0.0226), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(1e-04), 'CVX': np.float32(0.2041), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8251\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2021-04-16\n",
      "Holding period: 2021-04-16 to 2021-05-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0151), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0777), 'HON': np.float32(0.0), 'MMM': np.float32(0.0916), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0633), 'GS': np.float32(0.1186), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0419), 'AAPL': np.float32(0.0483), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0663), 'IBM': np.float32(0.0769), 'MSFT': np.float32(0.0354), 'TRV': np.float32(0.0458), 'UNH': np.float32(0.1226), 'CVX': np.float32(0.1656), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0309), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9993\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2021-05-17\n",
      "Holding period: 2021-05-17 to 2021-06-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0526), 'AMGN': np.float32(0.0593), 'DIS': np.float32(0.0357), 'NKE': np.float32(0.036), 'HON': np.float32(0.0261), 'MMM': np.float32(0.0376), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0806), 'AXP': np.float32(0.0925), 'GS': np.float32(0.197), 'JPM': np.float32(0.0027), 'MCD': np.float32(0.0), 'HD': np.float32(0.0109), 'AAPL': np.float32(0.0133), 'CRM': np.float32(0.0809), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0562), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0367), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1518), 'JNJ': np.float32(0.0251), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0048), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.6971\n",
      "\n",
      "==============================\n",
      "Starting Training Window 57/69\n",
      "Training Period: 2020-06-16 to 2021-06-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_56.zip\n",
      "\n",
      "Testing Period: 2021-06-16 to 2021-09-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2021-06-16\n",
      "Holding period: 2021-06-16 to 2021-07-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0361), 'NKE': np.float32(0.0632), 'HON': np.float32(0.0), 'MMM': np.float32(0.012), 'CAT': np.float32(0.0668), 'KO': np.float32(0.0), 'PG': np.float32(0.0635), 'AXP': np.float32(0.0818), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.1071), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.12), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0326), 'UNH': np.float32(0.0718), 'CVX': np.float32(0.0869), 'JNJ': np.float32(0.1091), 'MRK': np.float32(0.1491), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.1065\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2021-07-16\n",
      "Holding period: 2021-07-16 to 2021-08-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0167), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0283), 'NKE': np.float32(0.0), 'HON': np.float32(0.0703), 'MMM': np.float32(0.0388), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0526), 'GS': np.float32(0.1296), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0939), 'CRM': np.float32(0.0679), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.021), 'MSFT': np.float32(0.0342), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0635), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0754), 'MRK': np.float32(0.1467), 'AMZN': np.float32(0.0586), 'WMT': np.float32(0.1024), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.2130\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2021-08-16\n",
      "Holding period: 2021-08-16 to 2021-09-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0007), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0402), 'HON': np.float32(0.2022), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0025), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0896), 'MCD': np.float32(0.076), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0682), 'CRM': np.float32(0.0078), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1311), 'CVX': np.float32(0.1605), 'JNJ': np.float32(0.1084), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1126), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9952\n",
      "\n",
      "==============================\n",
      "Starting Training Window 58/69\n",
      "Training Period: 2020-09-15 to 2021-09-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_57.zip\n",
      "\n",
      "Testing Period: 2021-09-15 to 2021-12-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2021-09-15\n",
      "Holding period: 2021-09-15 to 2021-10-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0249), 'CAT': np.float32(0.0), 'KO': np.float32(0.1142), 'PG': np.float32(0.0), 'AXP': np.float32(0.1999), 'GS': np.float32(0.1893), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0079), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0722), 'IBM': np.float32(0.0336), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.091), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1252), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1418)}\n",
      "Cumulative reward for holding period: -0.9942\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2021-10-14\n",
      "Holding period: 2021-10-14 to 2021-11-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.063), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0214), 'HON': np.float32(0.0), 'MMM': np.float32(0.0337), 'CAT': np.float32(0.0), 'KO': np.float32(0.0084), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0714), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0272), 'HD': np.float32(0.0372), 'AAPL': np.float32(0.0912), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0964), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0447), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1857), 'CVX': np.float32(0.0076), 'JNJ': np.float32(0.054), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0593), 'WMT': np.float32(0.0086), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1903)}\n",
      "Cumulative reward for holding period: 1.3309\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2021-11-12\n",
      "Holding period: 2021-11-12 to 2021-12-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0057), 'HON': np.float32(0.0769), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.047), 'GS': np.float32(0.0687), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0331), 'HD': np.float32(0.0448), 'AAPL': np.float32(0.0312), 'CRM': np.float32(0.0823), 'CSCO': np.float32(0.161), 'IBM': np.float32(0.0698), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1617), 'CVX': np.float32(0.1453), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0725), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0026\n",
      "\n",
      "==============================\n",
      "Starting Training Window 59/69\n",
      "Training Period: 2020-12-14 to 2021-12-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_58.zip\n",
      "\n",
      "Testing Period: 2021-12-14 to 2022-03-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2021-12-14\n",
      "Holding period: 2021-12-14 to 2022-01-12\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0763), 'CAT': np.float32(0.0258), 'KO': np.float32(0.0586), 'PG': np.float32(0.1236), 'AXP': np.float32(0.0205), 'GS': np.float32(0.0), 'JPM': np.float32(0.0186), 'MCD': np.float32(0.0272), 'HD': np.float32(0.1609), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1057), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0163), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.126), 'JNJ': np.float32(0.1948), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0456)}\n",
      "Cumulative reward for holding period: -2.1884\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2022-01-13\n",
      "Holding period: 2022-01-13 to 2022-02-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0455), 'AMGN': np.float32(0.0864), 'DIS': np.float32(0.0653), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0746), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0443), 'GS': np.float32(0.0484), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0582), 'TRV': np.float32(0.1914), 'UNH': np.float32(0.0), 'CVX': np.float32(0.182), 'JNJ': np.float32(0.2039), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9705\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2022-02-14\n",
      "Holding period: 2022-02-14 to 2022-03-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0238), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0545), 'NKE': np.float32(0.0521), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0731), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0826), 'MCD': np.float32(0.1056), 'HD': np.float32(0.0316), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.1006), 'IBM': np.float32(0.019), 'MSFT': np.float32(0.0704), 'TRV': np.float32(0.1212), 'UNH': np.float32(0.0938), 'CVX': np.float32(0.0693), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.1025), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0047\n",
      "\n",
      "==============================\n",
      "Starting Training Window 60/69\n",
      "Training Period: 2021-03-17 to 2022-03-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_59.zip\n",
      "\n",
      "Testing Period: 2022-03-16 to 2022-06-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2022-03-16\n",
      "Holding period: 2022-03-16 to 2022-04-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0508), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0485), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0578), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0822), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0374), 'HD': np.float32(0.0311), 'AAPL': np.float32(0.0438), 'CRM': np.float32(0.1058), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0895), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1869), 'JNJ': np.float32(0.0317), 'MRK': np.float32(0.0365), 'AMZN': np.float32(0.1463), 'WMT': np.float32(0.0517), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8267\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2022-04-14\n",
      "Holding period: 2022-04-14 to 2022-05-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0516), 'AMGN': np.float32(0.0021), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0771), 'HON': np.float32(0.0), 'MMM': np.float32(0.0149), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0241), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.2142), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0338), 'TRV': np.float32(0.2198), 'UNH': np.float32(0.0), 'CVX': np.float32(0.071), 'JNJ': np.float32(0.1277), 'MRK': np.float32(0.0342), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.076), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0532)}\n",
      "Cumulative reward for holding period: -0.9890\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2022-05-16\n",
      "Holding period: 2022-05-16 to 2022-06-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0071), 'AMGN': np.float32(0.0657), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.1246), 'GS': np.float32(0.0), 'JPM': np.float32(0.0054), 'MCD': np.float32(0.1477), 'HD': np.float32(0.0), 'AAPL': np.float32(0.2077), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0332), 'IBM': np.float32(0.0172), 'MSFT': np.float32(0.0978), 'TRV': np.float32(0.0434), 'UNH': np.float32(0.0247), 'CVX': np.float32(0.0464), 'JNJ': np.float32(0.0259), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1532)}\n",
      "Cumulative reward for holding period: -0.9707\n",
      "\n",
      "==============================\n",
      "Starting Training Window 61/69\n",
      "Training Period: 2021-06-16 to 2022-06-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_60.zip\n",
      "\n",
      "Testing Period: 2022-06-15 to 2022-09-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2022-06-15\n",
      "Holding period: 2022-06-15 to 2022-07-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0113), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1325), 'NKE': np.float32(0.0), 'HON': np.float32(0.0404), 'MMM': np.float32(0.0), 'CAT': np.float32(0.1317), 'KO': np.float32(0.0818), 'PG': np.float32(0.0), 'AXP': np.float32(0.022), 'GS': np.float32(0.0), 'JPM': np.float32(0.0932), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.079), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0178), 'UNH': np.float32(0.028), 'CVX': np.float32(0.0723), 'JNJ': np.float32(0.0259), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0425), 'WMT': np.float32(0.0682), 'INTC': np.float32(0.0946), 'VZ': np.float32(0.0589)}\n",
      "Cumulative reward for holding period: -1.0157\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2022-07-18\n",
      "Holding period: 2022-07-18 to 2022-08-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1261), 'NKE': np.float32(0.0), 'HON': np.float32(0.0074), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0554), 'KO': np.float32(0.0), 'PG': np.float32(0.0088), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0714), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0125), 'CRM': np.float32(0.0808), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.097), 'MSFT': np.float32(0.0084), 'TRV': np.float32(0.0478), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0431), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0375), 'AMZN': np.float32(0.0676), 'WMT': np.float32(0.0885), 'INTC': np.float32(0.2476), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.7049\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2022-08-16\n",
      "Holding period: 2022-08-16 to 2022-09-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0535), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0831), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0115), 'MCD': np.float32(0.0385), 'HD': np.float32(0.1432), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.2464), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.1229), 'UNH': np.float32(0.0659), 'CVX': np.float32(0.0462), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0539), 'WMT': np.float32(0.095), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0399)}\n",
      "Cumulative reward for holding period: -1.0190\n",
      "\n",
      "==============================\n",
      "Starting Training Window 62/69\n",
      "Training Period: 2021-09-15 to 2022-09-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_61.zip\n",
      "\n",
      "Testing Period: 2022-09-15 to 2022-12-14 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2022-09-15\n",
      "Holding period: 2022-09-15 to 2022-10-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0308), 'AMGN': np.float32(0.1069), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0304), 'HON': np.float32(0.1009), 'MMM': np.float32(0.1015), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0231), 'AXP': np.float32(0.0), 'GS': np.float32(0.0838), 'JPM': np.float32(0.0424), 'MCD': np.float32(0.0855), 'HD': np.float32(0.0607), 'AAPL': np.float32(0.0652), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0114), 'MSFT': np.float32(0.0074), 'TRV': np.float32(0.0), 'UNH': np.float32(0.064), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0697), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1162), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2022-10-14\n",
      "Holding period: 2022-10-14 to 2022-11-11\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0825), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0397), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.1523), 'AXP': np.float32(0.0), 'GS': np.float32(0.0893), 'JPM': np.float32(0.0366), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0669), 'CRM': np.float32(0.0706), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0147), 'MSFT': np.float32(0.0652), 'TRV': np.float32(0.0954), 'UNH': np.float32(0.0705), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.1014), 'AMZN': np.float32(0.0457), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0692)}\n",
      "Cumulative reward for holding period: 0.4003\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2022-11-14\n",
      "Holding period: 2022-11-14 to 2022-12-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.1176), 'HON': np.float32(0.083), 'MMM': np.float32(0.1166), 'CAT': np.float32(0.0657), 'KO': np.float32(0.0242), 'PG': np.float32(0.0592), 'AXP': np.float32(0.0), 'GS': np.float32(0.1035), 'JPM': np.float32(0.0807), 'MCD': np.float32(0.0), 'HD': np.float32(0.0151), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0175), 'MSFT': np.float32(0.0512), 'TRV': np.float32(0.0), 'UNH': np.float32(0.048), 'CVX': np.float32(0.0539), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0607), 'AMZN': np.float32(0.0083), 'WMT': np.float32(0.0672), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0276)}\n",
      "Cumulative reward for holding period: -1.0270\n",
      "\n",
      "==============================\n",
      "Starting Training Window 63/69\n",
      "Training Period: 2021-12-14 to 2022-12-13\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_62.zip\n",
      "\n",
      "Testing Period: 2022-12-14 to 2023-03-17 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2022-12-14\n",
      "Holding period: 2022-12-14 to 2023-01-13\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0008), 'NKE': np.float32(0.0935), 'HON': np.float32(0.0), 'MMM': np.float32(0.1211), 'CAT': np.float32(0.0), 'KO': np.float32(0.0258), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0502), 'MCD': np.float32(0.0309), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0697), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0385), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.078), 'UNH': np.float32(0.0969), 'CVX': np.float32(0.0909), 'JNJ': np.float32(0.0524), 'MRK': np.float32(0.1119), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.1393)}\n",
      "Cumulative reward for holding period: -1.0418\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2023-01-17\n",
      "Holding period: 2023-01-17 to 2023-02-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0112), 'AMGN': np.float32(0.021), 'DIS': np.float32(0.0121), 'NKE': np.float32(0.0), 'HON': np.float32(0.0794), 'MMM': np.float32(0.0366), 'CAT': np.float32(0.0816), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0489), 'JPM': np.float32(0.0813), 'MCD': np.float32(0.0859), 'HD': np.float32(0.0529), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0386), 'MSFT': np.float32(0.001), 'TRV': np.float32(0.0), 'UNH': np.float32(0.1436), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.1911), 'MRK': np.float32(0.0575), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0573), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0051\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2023-02-15\n",
      "Holding period: 2023-02-15 to 2023-03-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0284), 'AMGN': np.float32(0.0299), 'DIS': np.float32(0.0008), 'NKE': np.float32(0.0732), 'HON': np.float32(0.0589), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0712), 'KO': np.float32(0.0597), 'PG': np.float32(0.0351), 'AXP': np.float32(0.0497), 'GS': np.float32(0.0), 'JPM': np.float32(0.0378), 'MCD': np.float32(0.0318), 'HD': np.float32(0.084), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0667), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.065), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1376), 'WMT': np.float32(0.117), 'INTC': np.float32(0.0474), 'VZ': np.float32(0.0056)}\n",
      "Cumulative reward for holding period: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Training Window 64/69\n",
      "Training Period: 2022-03-16 to 2023-03-16\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_63.zip\n",
      "\n",
      "Testing Period: 2023-03-17 to 2023-06-16 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2023-03-17\n",
      "Holding period: 2023-03-17 to 2023-04-17\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0348), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0275), 'HON': np.float32(0.0), 'MMM': np.float32(0.0883), 'CAT': np.float32(0.0), 'KO': np.float32(0.0154), 'PG': np.float32(0.0102), 'AXP': np.float32(0.039), 'GS': np.float32(0.0898), 'JPM': np.float32(0.0087), 'MCD': np.float32(0.0892), 'HD': np.float32(0.0618), 'AAPL': np.float32(0.0016), 'CRM': np.float32(0.019), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0254), 'MSFT': np.float32(0.0199), 'TRV': np.float32(0.0), 'UNH': np.float32(0.03), 'CVX': np.float32(0.1097), 'JNJ': np.float32(0.1094), 'MRK': np.float32(0.0301), 'AMZN': np.float32(0.0402), 'WMT': np.float32(0.0733), 'INTC': np.float32(0.0035), 'VZ': np.float32(0.0734)}\n",
      "Cumulative reward for holding period: -4.3077\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2023-04-18\n",
      "Holding period: 2023-04-18 to 2023-05-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0498), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1168), 'NKE': np.float32(0.1005), 'HON': np.float32(0.1196), 'MMM': np.float32(0.0375), 'CAT': np.float32(0.0128), 'KO': np.float32(0.0), 'PG': np.float32(0.0378), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0503), 'CSCO': np.float32(0.1327), 'IBM': np.float32(0.04), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0671), 'UNH': np.float32(0.0695), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0755), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0788), 'INTC': np.float32(0.0), 'VZ': np.float32(0.011)}\n",
      "Cumulative reward for holding period: -0.9990\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2023-05-17\n",
      "Holding period: 2023-05-17 to 2023-06-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.1304), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0389), 'CAT': np.float32(0.0202), 'KO': np.float32(0.0), 'PG': np.float32(0.039), 'AXP': np.float32(0.0088), 'GS': np.float32(0.0113), 'JPM': np.float32(0.2399), 'MCD': np.float32(0.0817), 'HD': np.float32(0.1264), 'AAPL': np.float32(0.0169), 'CRM': np.float32(0.0043), 'CSCO': np.float32(0.0422), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1703), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0696), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.4102\n",
      "\n",
      "==============================\n",
      "Starting Training Window 65/69\n",
      "Training Period: 2022-06-15 to 2023-06-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_64.zip\n",
      "\n",
      "Testing Period: 2023-06-16 to 2023-09-18 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2023-06-16\n",
      "Holding period: 2023-06-16 to 2023-07-18\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.1306), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.1864), 'PG': np.float32(0.1064), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0321), 'MCD': np.float32(0.196), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1184), 'CSCO': np.float32(0.0059), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1376), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0866), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8710\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2023-07-19\n",
      "Holding period: 2023-07-19 to 2023-08-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.2153), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0913), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0794), 'PG': np.float32(0.0317), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0099), 'MCD': np.float32(0.0789), 'HD': np.float32(0.0381), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0381), 'CSCO': np.float32(0.1237), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.2074), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0391), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.047), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8576\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2023-08-17\n",
      "Holding period: 2023-08-17 to 2023-09-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0753), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0973), 'HON': np.float32(0.0304), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0435), 'PG': np.float32(0.0886), 'AXP': np.float32(0.0041), 'GS': np.float32(0.0), 'JPM': np.float32(0.1699), 'MCD': np.float32(0.0), 'HD': np.float32(0.0999), 'AAPL': np.float32(0.0106), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.05), 'IBM': np.float32(0.0712), 'MSFT': np.float32(0.1254), 'TRV': np.float32(0.0142), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0195), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.1001), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.8370\n",
      "\n",
      "==============================\n",
      "Starting Training Window 66/69\n",
      "Training Period: 2022-09-15 to 2023-09-15\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_65.zip\n",
      "\n",
      "Testing Period: 2023-09-18 to 2023-12-15 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2023-09-18\n",
      "Holding period: 2023-09-18 to 2023-10-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0959), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0125), 'HON': np.float32(0.0), 'MMM': np.float32(0.018), 'CAT': np.float32(0.0044), 'KO': np.float32(0.0765), 'PG': np.float32(0.0014), 'AXP': np.float32(0.0293), 'GS': np.float32(0.0), 'JPM': np.float32(0.0068), 'MCD': np.float32(0.1471), 'HD': np.float32(0.4016), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0151), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0094), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0974), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0846), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -1.0000\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2023-10-17\n",
      "Holding period: 2023-10-17 to 2023-11-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0643), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.071), 'HON': np.float32(0.0), 'MMM': np.float32(0.0286), 'CAT': np.float32(0.0), 'KO': np.float32(0.1157), 'PG': np.float32(0.1593), 'AXP': np.float32(0.0407), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0973), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0078), 'CRM': np.float32(0.0513), 'CSCO': np.float32(0.0947), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1275), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0433), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0108), 'AMZN': np.float32(0.0085), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0793), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: 0.0740\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2023-11-15\n",
      "Holding period: 2023-11-15 to 2023-12-14\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0793), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0553), 'MMM': np.float32(0.0677), 'CAT': np.float32(0.0089), 'KO': np.float32(0.0947), 'PG': np.float32(0.1899), 'AXP': np.float32(0.0), 'GS': np.float32(0.0817), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0), 'HD': np.float32(0.0172), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0433), 'CSCO': np.float32(0.1346), 'IBM': np.float32(0.0101), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0039), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0338), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0339), 'WMT': np.float32(0.0), 'INTC': np.float32(0.031), 'VZ': np.float32(0.1147)}\n",
      "Cumulative reward for holding period: 0.2522\n",
      "\n",
      "==============================\n",
      "Starting Training Window 67/69\n",
      "Training Period: 2022-12-14 to 2023-12-14\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_66.zip\n",
      "\n",
      "Testing Period: 2023-12-15 to 2024-03-19 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2023-12-15\n",
      "Holding period: 2023-12-15 to 2024-01-17\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0605), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.064), 'PG': np.float32(0.0401), 'AXP': np.float32(0.0641), 'GS': np.float32(0.0268), 'JPM': np.float32(0.0512), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.1761), 'CSCO': np.float32(0.0099), 'IBM': np.float32(0.0405), 'MSFT': np.float32(0.0926), 'TRV': np.float32(0.0633), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0598), 'WMT': np.float32(0.0862), 'INTC': np.float32(0.1254), 'VZ': np.float32(0.0395)}\n",
      "Cumulative reward for holding period: -0.2027\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2024-01-18\n",
      "Holding period: 2024-01-18 to 2024-02-15\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0058), 'AMGN': np.float32(0.0949), 'DIS': np.float32(0.1176), 'NKE': np.float32(0.0), 'HON': np.float32(0.0281), 'MMM': np.float32(0.0391), 'CAT': np.float32(0.0), 'KO': np.float32(0.0279), 'PG': np.float32(0.0), 'AXP': np.float32(0.1248), 'GS': np.float32(0.0434), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0397), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0066), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.1049), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.1038), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0045), 'AMZN': np.float32(0.0842), 'WMT': np.float32(0.0132), 'INTC': np.float32(0.0892), 'VZ': np.float32(0.0721)}\n",
      "Cumulative reward for holding period: 0.3606\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2024-02-16\n",
      "Holding period: 2024-02-16 to 2024-03-18\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.109), 'AMGN': np.float32(0.0415), 'DIS': np.float32(0.0168), 'NKE': np.float32(0.0376), 'HON': np.float32(0.0122), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0944), 'KO': np.float32(0.0), 'PG': np.float32(0.0236), 'AXP': np.float32(0.0), 'GS': np.float32(0.0987), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0852), 'HD': np.float32(0.073), 'AAPL': np.float32(0.0389), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0721), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0695), 'TRV': np.float32(0.0498), 'UNH': np.float32(0.0085), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0075), 'MRK': np.float32(0.1146), 'AMZN': np.float32(0.0023), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0412), 'VZ': np.float32(0.0037)}\n",
      "Cumulative reward for holding period: -0.8402\n",
      "\n",
      "==============================\n",
      "Starting Training Window 68/69\n",
      "Training Period: 2023-03-17 to 2024-03-18\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_67.zip\n",
      "\n",
      "Testing Period: 2024-03-19 to 2024-06-18 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2024-03-19\n",
      "Holding period: 2024-03-19 to 2024-04-17\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.1276), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0455), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0173), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.015), 'HD': np.float32(0.1206), 'AAPL': np.float32(0.2792), 'CRM': np.float32(0.0573), 'CSCO': np.float32(0.0342), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0208), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0437), 'CVX': np.float32(0.0597), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0142), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0302), 'INTC': np.float32(0.1346), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9997\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2024-04-18\n",
      "Holding period: 2024-04-18 to 2024-05-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0303), 'DIS': np.float32(0.0729), 'NKE': np.float32(0.0), 'HON': np.float32(0.1427), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.078), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.2016), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0932), 'JNJ': np.float32(0.1511), 'MRK': np.float32(0.0311), 'AMZN': np.float32(0.1818), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0), 'VZ': np.float32(0.0173)}\n",
      "Cumulative reward for holding period: -1.0075\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2024-05-17\n",
      "Holding period: 2024-05-17 to 2024-06-17\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0085), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0798), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.1383), 'MCD': np.float32(0.1136), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.3139), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.177), 'INTC': np.float32(0.1689), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.9875\n",
      "\n",
      "==============================\n",
      "Starting Training Window 69/69\n",
      "Training Period: 2023-06-16 to 2024-06-17\n",
      "Training new PPO model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/ppo_model_window_68.zip\n",
      "\n",
      "Testing Period: 2024-06-18 to 2024-09-18 (63 days total)\n",
      "\n",
      "--- Rebalance 1 ---\n",
      "Rebalance date: 2024-06-18\n",
      "Holding period: 2024-06-18 to 2024-07-18\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0906), 'MMM': np.float32(0.0522), 'CAT': np.float32(0.0118), 'KO': np.float32(0.0), 'PG': np.float32(0.1859), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.0), 'MCD': np.float32(0.0242), 'HD': np.float32(0.0553), 'AAPL': np.float32(0.106), 'CRM': np.float32(0.0), 'CSCO': np.float32(0.0), 'IBM': np.float32(0.0347), 'MSFT': np.float32(0.0), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0451), 'JNJ': np.float32(0.1679), 'MRK': np.float32(0.015), 'AMZN': np.float32(0.0622), 'WMT': np.float32(0.1012), 'INTC': np.float32(0.0479), 'VZ': np.float32(0.0)}\n",
      "Cumulative reward for holding period: -0.1666\n",
      "\n",
      "--- Rebalance 2 ---\n",
      "Rebalance date: 2024-07-19\n",
      "Holding period: 2024-07-19 to 2024-08-16\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0929), 'DIS': np.float32(0.0), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0352), 'CAT': np.float32(0.0247), 'KO': np.float32(0.0), 'PG': np.float32(0.0), 'AXP': np.float32(0.0), 'GS': np.float32(0.0), 'JPM': np.float32(0.018), 'MCD': np.float32(0.1477), 'HD': np.float32(0.0), 'AAPL': np.float32(0.2548), 'CRM': np.float32(0.0275), 'CSCO': np.float32(0.0175), 'IBM': np.float32(0.0), 'MSFT': np.float32(0.003), 'TRV': np.float32(0.0633), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0258), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0), 'AMZN': np.float32(0.1121), 'WMT': np.float32(0.0), 'INTC': np.float32(0.0888), 'VZ': np.float32(0.0887)}\n",
      "Cumulative reward for holding period: -0.5954\n",
      "\n",
      "--- Rebalance 3 ---\n",
      "Rebalance date: 2024-08-19\n",
      "Holding period: 2024-08-19 to 2024-09-17\n",
      "Normalized Portfolio weights:\n",
      "{'BA': np.float32(0.0), 'AMGN': np.float32(0.0283), 'DIS': np.float32(0.143), 'NKE': np.float32(0.0), 'HON': np.float32(0.0), 'MMM': np.float32(0.0), 'CAT': np.float32(0.0), 'KO': np.float32(0.0383), 'PG': np.float32(0.0), 'AXP': np.float32(0.0163), 'GS': np.float32(0.1047), 'JPM': np.float32(0.0769), 'MCD': np.float32(0.0), 'HD': np.float32(0.0), 'AAPL': np.float32(0.0), 'CRM': np.float32(0.0656), 'CSCO': np.float32(0.021), 'IBM': np.float32(0.1355), 'MSFT': np.float32(0.1132), 'TRV': np.float32(0.0), 'UNH': np.float32(0.0), 'CVX': np.float32(0.0), 'JNJ': np.float32(0.0), 'MRK': np.float32(0.0383), 'AMZN': np.float32(0.0), 'WMT': np.float32(0.0979), 'INTC': np.float32(0.0518), 'VZ': np.float32(0.0693)}\n",
      "Cumulative reward for holding period: -0.5333\n",
      "\n",
      "==============================\n",
      "All training/testing windows completed successfully.\n",
      "==============================\n",
      "Final results saved to 'single_step_allocations_dates_rebalanced.csv'\n"
     ]
    }
   ],
   "source": [
    "# reb every 21 days\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21  # rebalance every 21 days\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "selected_columns = daily_regimes.columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist()\n",
    "use_factor_returns = False\n",
    "records = []\n",
    "raw_stock_returns = stock_returns_norm_filter\n",
    "load_existing_model = False\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Training Window {i+1}/{total_windows}\")\n",
    "    print(f\"Training Period: {merged_data.index[start].date()} to {merged_data.index[start + train_window - 1].date()}\")\n",
    "\n",
    "    # Explicit training and testing dataset slicing\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # Train PPO model explicitly\n",
    "    model_filename = os.path.join(model_save_dir, f\"ppo_model_window_{i}.zip\")\n",
    "\n",
    "    # Setup environment\n",
    "    env = DummyVecEnv([\n",
    "        lambda: SinglePPOEnv(\n",
    "            train_df[tickers],\n",
    "            train_df[selected_columns + factor_columns] if use_factor_returns else train_df[selected_columns],\n",
    "            raw_returns_train\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "     # Load existing model if indicated and file exists\n",
    "    if load_existing_model and i > 0 and os.path.exists(os.path.join(model_save_dir, f\"ppo_model_window_{i-1}.zip\")):\n",
    "        previous_model_filename = os.path.join(model_save_dir, f\"ppo_model_window_{i-1}.zip\")\n",
    "        print(f\"Loading and retraining previous PPO model from {previous_model_filename}\")\n",
    "        model = PPO.load(previous_model_filename, env=env)\n",
    "        model.learn(total_timesteps=10000)\n",
    "    else:\n",
    "        print(\"Training new PPO model from scratch...\")\n",
    "        model = PPO('MlpPolicy', env, verbose=0)\n",
    "        model.learn(total_timesteps=10000)\n",
    "\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    # Testing phase setup\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[selected_columns + factor_columns].values if use_factor_returns else test_df[selected_columns].values\n",
    "\n",
    "    print(f\"\\nTesting Period: {test_dates[0].date()} to {test_dates[-1].date()} (63 days total)\")\n",
    "\n",
    "    # Evaluate every 21 days (3 rebalances per testing window)\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        print(f\"\\n--- Rebalance {rebalance_num + 1} ---\")\n",
    "        print(f\"Rebalance date: {test_dates[rebalance_start].date()}\")\n",
    "        print(f\"Holding period: {test_dates[rebalance_start].date()} to {test_dates[rebalance_end - 1].date()}\")\n",
    "\n",
    "        obs_returns = test_returns[rebalance_start:rebalance_end]\n",
    "        obs_regimes = test_regimes[rebalance_start:rebalance_end]\n",
    "        obs_raw_returns = raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "\n",
    "        env_test = SinglePPOEnv(\n",
    "            returns_df=pd.DataFrame(obs_returns, columns=tickers),\n",
    "            regime_df=pd.DataFrame(obs_regimes, columns=(selected_columns + factor_columns) if use_factor_returns else selected_columns),\n",
    "            raw_returns_df=obs_raw_returns\n",
    "        )\n",
    "\n",
    "        obs = env_test.reset()\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # Explicit normalization right here:\n",
    "        action_sum = action.sum()\n",
    "        if action_sum != 0:\n",
    "            action /= action_sum\n",
    "        else:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        print(f\"Normalized Portfolio weights:\\n{weights_dict}\")\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, obs_raw_returns.iloc[step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward for holding period: {cumulative_reward:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \"\\nAll training/testing windows completed successfully.\\n\" + \"=\"*30)\n",
    "\n",
    "# Save final results explicitly\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"Final results saved to 'single_step_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-13T02:02:52.263260Z",
     "start_time": "2025-04-13T01:49:28.852557Z"
    }
   },
   "id": "6f741ad7b986bb6e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*30 + \"\\nAll training/testing windows completed successfully.\\n\" + \"=\"*30)\n",
    "\n",
    "# Save final results explicitly\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates_rebalanced.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff36318ecdaef1db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea46a06e07568b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f1dd301757f4969"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "# Load data explicitly\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Explicitly filter only 'Test' phase SHAP metrics\n",
    "shap_metrics_test = shap_metrics[shap_metrics['Phase'] == 'Test'].copy()\n",
    "\n",
    "# Verify explicitly\n",
    "print(f\"Total SHAP records (Test Phase): {len(shap_metrics_test)}\")\n",
    "\n",
    "# Select SHAP metrics explicitly\n",
    "selected_columns = [\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA',\n",
    "    'mean_abs_over_std_Mkt-RF', 'mean_abs_over_std_SMB', 'mean_abs_over_std_HML',\n",
    "    'mean_abs_over_std_RMW', 'mean_abs_over_std_CMA'\n",
    "]\n",
    "\n",
    "# Aggregate SHAP metrics explicitly by Start_Date and End_Date across stocks\n",
    "shap_agg = shap_metrics_test.groupby(['Start_Date', 'End_Date'])[selected_columns].mean().reset_index()\n",
    "\n",
    "# Explicitly scale SHAP metrics\n",
    "scaler_shap = StandardScaler()\n",
    "shap_agg[selected_columns] = scaler_shap.fit_transform(shap_agg[selected_columns])\n",
    "\n",
    "# Verify explicitly scaled SHAP metrics\n",
    "# print(\"Scaled SHAP metrics (Test phase):\", shap_agg.head())\n",
    "\n",
    "# Explicitly map SHAP intervals to daily returns\n",
    "daily_regimes = pd.DataFrame(index=stock_returns.index)\n",
    "\n",
    "for _, row in shap_agg.iterrows():\n",
    "    mask = (daily_regimes.index >= row['Start_Date']) & (daily_regimes.index <= row['End_Date'])\n",
    "    daily_regimes.loc[mask, selected_columns] = row[selected_columns].values\n",
    "\n",
    "# Explicit forward-fill for continuity\n",
    "daily_regimes.ffill(inplace=True)\n",
    "daily_regimes.dropna(inplace=True)\n",
    "\n",
    "# Perform KMeans clustering explicitly on daily regimes\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "daily_regimes['Cluster'] = kmeans.fit_predict(daily_regimes[selected_columns])\n",
    "# daily_regimes['Cluster'] = 1 - daily_regimes['Cluster']\n",
    "# cluster_mapping = {0: 1, 1: 0}  # Good explicitly set as 1\n",
    "# daily_regimes['Cluster_Mapped'] = daily_regimes['Cluster'].map(cluster_mapping)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Example: Clustering raw returns into regimes\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# regime_labels = kmeans.fit_predict(raw_future_returns_df)\n",
    "# regime_labels_series = pd.Series(regime_labels, index=raw_future_returns_df.index)\n",
    "\n",
    "# Verify explicitly aligned daily regimes\n",
    "# print(\"Daily regimes (aligned):\", daily_regimes.head())\n",
    "\n",
    "# Normalize explicitly factor returns\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize explicitly stock returns\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Merge explicitly into final dataset\n",
    "merged_data = stock_returns_norm.join(daily_regimes[['Cluster'] + selected_columns], how='inner')\\\n",
    "                                .join(factor_returns_norm, rsuffix='_factor')\\\n",
    "                                .dropna()\n",
    "\n",
    "# Explicit final dataset verification\n",
    "# print(\"Merged normalized data preview:\", merged_data.head())\n",
    "\n",
    "# Save explicitly final aligned dataset\n",
    "merged_data.to_csv(\"final_merged_data.csv\")\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "start_date = merged_data.index.min()\n",
    "end_date = merged_data.index.max()\n",
    "\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "raw_stock_returns = stock_returns.loc[start_date:end_date].copy()\n",
    "raw_stock_returns.to_csv(\"aligned_raw_stock_returns.csv\")\n",
    "\n",
    "stock_returns_norm_filter = stock_returns_norm.loc[start_date:end_date].copy()\n",
    "cluster_avg_returns = raw_stock_returns.join(daily_regimes['Cluster']).groupby('Cluster').mean().mean(axis=1)\n",
    "print(\"Explicit Cluster Mean Returns Check:\\n\", cluster_avg_returns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c0027f46cdbabce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use existing explicitly scaled SHAP metrics from daily_regimes\n",
    "regime_data = daily_regimes.values\n",
    "cluster_range = range(2, 11)  # Evaluate 2 to 10 clusters explicitly\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "calinski_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(regime_data)\n",
    "\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(regime_data, labels))\n",
    "    calinski_scores.append(calinski_harabasz_score(regime_data, labels))\n",
    "\n",
    "    print(f\"Clusters: {k} | Inertia: {kmeans.inertia_:.2f} | \"\n",
    "          f\"Silhouette: {silhouette_scores[-1]:.4f} | \"\n",
    "          f\"Calinski-Harabasz: {calinski_scores[-1]:.2f}\")\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "ax[0].plot(cluster_range, inertia, 'bo-', linewidth=2)\n",
    "ax[0].set_title('Elbow Method (Inertia)', fontsize=14)\n",
    "ax[0].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[0].set_ylabel('Inertia', fontsize=12)\n",
    "\n",
    "ax[1].plot(cluster_range, silhouette_scores, 'go-', linewidth=2)\n",
    "ax[1].set_title('Silhouette Score', fontsize=14)\n",
    "ax[1].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "\n",
    "ax[2].plot(cluster_range, calinski_scores, 'ro-', linewidth=2)\n",
    "ax[2].set_title('Calinski-Harabasz Index', fontsize=14)\n",
    "ax[2].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[2].set_ylabel('Calinski-Harabasz Score', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5e18248d57def17",
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "# daily_regimes['Cluster'] = labels\n",
    "# returns_by_cluster = stock_returns_norm.join(daily_regimes['Cluster'])\n",
    "# # print(returns_by_cluster.groupby('Cluster').mean())\n",
    "# \n",
    "# print(returns_by_cluster.groupby('Cluster').std())\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "daily_regimes['Cluster'] = kmeans.fit_predict(daily_regimes[selected_columns])\n",
    "# Do NOT include 'Cluster' in regime_columns explicitly, because that's a label not a feature:\n",
    "regime_columns = selected_columns.copy()\n",
    "# Explicit join:\n",
    "merged_data = stock_returns_norm.join(\n",
    "    daily_regimes[['Cluster'] + regime_columns], \n",
    "    how='inner'\n",
    ").dropna()\n",
    "\n",
    "# Verify explicitly:\n",
    "print(merged_data.head())\n",
    "# High-Level environment explicitly using only regime_columns (SHAP metrics):\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50eec2710513c348"
  },
  {
   "cell_type": "raw",
   "source": [
    "Step 1: High-Level PPO (Regime Selector)\n",
    "\n",
    "High-Level Regime Selector Environment:\n",
    "Step 2: Low-Level PPO (Portfolio Allocator)\n",
    "\n",
    "Regime-Conditioned Portfolio Environment:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5792785ff137338f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeSelectorEnv(gym.Env):\n",
    "    def __init__(self, regime_features_df, raw_future_returns_df):\n",
    "        super().__init__()\n",
    "        self.regime_features = regime_features_df.values\n",
    "        # self.raw_future_returns = raw_future_returns_df.values\n",
    "        self.raw_future_returns = raw_future_returns_df\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.n_regimes = 2  # Regimes: 0 = bad, 1 = good\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.n_regimes)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.regime_features.shape[1],),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.regime_features[self.current_step]\n",
    "\n",
    "    def step(self, action):\n",
    "        avg_future_return = np.mean(self.raw_future_returns[self.current_step])\n",
    "\n",
    "        # Reward logic explicitly explained:\n",
    "        # - action = 1 (predict good regime): reward = avg_future_return\n",
    "        # - action = 0 (predict bad regime): reward = -avg_future_return\n",
    "        # Thus, correct predictions yield positive rewards, incorrect yield negative rewards.\n",
    "        reward = avg_future_return if action == 1 else -avg_future_return\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.regime_features) - 1\n",
    "\n",
    "        obs = (\n",
    "            self.regime_features[self.current_step]\n",
    "            if not done else np.zeros(self.observation_space.shape)\n",
    "        )\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeConditionedPortfolioEnv(gym.Env):\n",
    "    def __init__(self, returns_df, chosen_regime_vector, raw_returns_df, factor_returns_df=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stock_returns = returns_df.values\n",
    "        self.chosen_regime_vector = chosen_regime_vector\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.factor_returns = factor_returns_df.values if factor_returns_df is not None else None\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        \n",
    "        obs_dim = self.n_assets + 1\n",
    "        if self.factor_returns is not None:\n",
    "            obs_dim += self.factor_returns.shape[1]\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_dim,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = np.array([self.chosen_regime_vector[self.current_step]])\n",
    "        obs = np.concatenate([returns, regime])\n",
    "\n",
    "        if self.factor_returns is not None:\n",
    "            factor_obs = self.factor_returns[self.current_step]\n",
    "            obs = np.concatenate([obs, factor_obs])\n",
    "\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        if action_sum == 0:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "        else:\n",
    "            action = action / action_sum\n",
    "\n",
    "        # Intuitive reward: explicitly realized portfolio return\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fa6000d68203e53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "use_factor_returns = False  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "# regime_columns = daily_regimes.columns.tolist() #### remove cluster in the feature set!!\n",
    "regime_columns = daily_regimes.columns.drop('Cluster').tolist()\n",
    "# regime_columns = daily_regimes[['Cluster']].columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "raw_stock_returns = stock_returns_norm_filter\n",
    "load_existing_model = False\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # High-Level training data preparation (no look-ahead bias)\n",
    "    regime_features_high = train_df[regime_columns + factor_columns][:-rebalance_freq]\n",
    "    future_returns_high = np.array([\n",
    "        raw_returns_train.iloc[idx + 1: idx + rebalance_freq + 1].mean().mean()\n",
    "        for idx in range(len(regime_features_high))\n",
    "    ])\n",
    "\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(regime_features_high, future_returns_high)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Load existing high-level model or train a new one\n",
    "    if load_existing_model and os.path.exists(high_model_path):\n",
    "        print(\"Loading existing High-Level Regime Selector model...\")\n",
    "        high_model = PPO.load(high_model_path, env=high_env)\n",
    "        high_model.learn(total_timesteps=3000)  # continue training briefly\n",
    "        print(f\"Continued training on High-Level model. Saved again to {high_model_path}.\")\n",
    "    else:\n",
    "        print(\"Training new High-Level Regime Selector model...\")\n",
    "        # policy_kwargs = dict(net_arch=[128, 64], activation_fn=nn.Tanh)\n",
    "        # \n",
    "        # high_model = PPO(\n",
    "        #     'MlpPolicy', high_env, verbose=0,\n",
    "        #     learning_rate=1e-4,\n",
    "        #     n_steps=2048,\n",
    "        #     batch_size=128,\n",
    "        #     gamma=0.95,\n",
    "        #     ent_coef=0.005,  # Slightly lower entropy encourages differentiation\n",
    "        #     clip_range=0.2,\n",
    "        #     n_epochs=10,\n",
    "        #     policy_kwargs=policy_kwargs\n",
    "        # )\n",
    "        # high_model.learn(total_timesteps=10000)\n",
    "    \n",
    "        print(\"Training High-Level Regime Selector...\")\n",
    "        high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "        high_model.learn(total_timesteps=50000)\n",
    "    # high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "    # high_model.save(high_model_path)\n",
    "    # print(f\"High-level model saved at: {high_model_path}\")\n",
    "\n",
    "    # Generate historical regimes for low-level model training (no look-ahead)\n",
    "    historical_regimes = []\n",
    "    for idx in range(len(regime_features_high)):\n",
    "        obs = regime_features_high.iloc[idx].values\n",
    "        regime, _ = high_model.predict(obs, deterministic=True)\n",
    "        historical_regimes.append(int(regime))\n",
    "\n",
    "    historical_regimes = pd.Series(historical_regimes, index=regime_features_high.index)\n",
    "\n",
    "    # Train low-level models per historical regime\n",
    "    low_level_models = {}\n",
    "    for regime in historical_regimes.unique():\n",
    "        low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        regime_indices = historical_regimes[historical_regimes == regime].index\n",
    "        regime_df = train_df.loc[regime_indices]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        if load_existing_model and os.path.exists(low_model_path):\n",
    "            print(f\"Loading existing Low-Level model for regime {regime}...\")\n",
    "            low_model = PPO.load(low_model_path, env=low_env_train)\n",
    "            low_model.learn(total_timesteps=3000)  # brief continued training\n",
    "            print(f\"Continued training on Low-Level model regime {regime}. Saved again to {low_model_path}.\")\n",
    "        else:\n",
    "            print(f\"Training new Low-Level model for regime {regime}...\")\n",
    "            # low_model = PPO(\n",
    "            #     'MlpPolicy', low_env_train, verbose=0,\n",
    "            #     learning_rate=5e-5,\n",
    "            #     n_steps=2048,\n",
    "            #     batch_size=128,\n",
    "            #     gamma=0.97,\n",
    "            #     ent_coef=0.003,  # Reduced entropy to discourage uniform policy\n",
    "            #     clip_range=0.2,\n",
    "            #     n_epochs=10,\n",
    "            #     policy_kwargs=policy_kwargs\n",
    "            # )\n",
    "            # low_model.learn(total_timesteps=10000)\n",
    "\n",
    "            low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "            low_model.learn(total_timesteps=50000)\n",
    "        # low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        # low_model.save(low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        # print(f\"Low-level model for regime {regime} saved at: {low_model_path}\")\n",
    "\n",
    "    # Testing\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns + factor_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "        print(f'chosen_regime = {chosen_regime} and check is {chosen_regime in low_level_models}')\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a3b88d647f58602",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 1/69\n",
      "Training new High-Level Regime Selector from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_0.zip\n",
      "Training new Low-Level model for regime 1 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_0_regime_1.zip\n",
      "Training new Low-Level model for regime 0 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_0_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9998\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9827\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0030\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 2/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_1.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_1_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_1_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 4.5405\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -2.0394\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0411\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 3/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_2.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_2_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_2_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0090\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9966\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 4/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_3.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_3_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_3_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0001\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9475\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9991\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 5/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_4.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_4_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_4_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0011\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9713\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9961\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 6/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_5.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_5_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_5_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -42.9232\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -3277.7236\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1676.3724\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 7/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_6.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_6_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_6_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0207\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -2.2250\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 8/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_7.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_7_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_7_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -2.1877\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.2201\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1634\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 9/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_8.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_8_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_8_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9994\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -6.5759\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1251\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 10/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_9.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_9_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_9_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9722\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9701\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0063\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 11/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_10.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_10_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_10_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9877\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0008\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 14.1490\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 12/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_11.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_11_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_11_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1312\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0236\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0041\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 13/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_12.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_12_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_12_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0086\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9981\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 14/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_13.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_13_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_13_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0034\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9994\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0009\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 15/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_14.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_14_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_14_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.1592\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.8633\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9969\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 16/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_15.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_15_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_15_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.5241\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 4.5769\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9974\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 17/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_16.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_16_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_16_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9522\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0023\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -44.2267\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 18/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_17.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_17_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_17_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -6.6258\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -34.4259\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 19/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_18.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_18_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_18_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4326\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 1.6111\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.0948\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 20/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_19.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_19_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_19_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9850\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0007\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.4036\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 21/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_20.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_20_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_20_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.4919\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6491\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.7632\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 22/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_21.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_21_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_21_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1751\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9998\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6428\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 23/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_22.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_22_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_22_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.2940\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8399\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.1326\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 24/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_23.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_23_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_23_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9172\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0052\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9986\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 25/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_24.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_24_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_24_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7849\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.1798\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0205\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 26/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_25.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_25_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_25_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9804\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4262\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6731\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 27/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_26.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_26_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_26_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.5183\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9783\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8811\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 28/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_27.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_27_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_27_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0258\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7129\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4837\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 29/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_28.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_28_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_28_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.6458\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0371\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.3988\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 30/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_29.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_29_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_29_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6306\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0039\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 31/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_30.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_30_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_30_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9982\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0090\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9968\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 32/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_31.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_31_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_31_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.8070\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9794\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.0260\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 33/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_32.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_32_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_32_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.3312\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0109\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 34/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_33.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_33_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_33_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0991\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.6872\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0027\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 35/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_34.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_34_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_34_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0003\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0011\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 23.8354\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 36/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_35.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_35_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_35_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.5232\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9933\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0545\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 37/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_36.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_36_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_36_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -5.4147\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4883\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.3047\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 38/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_37.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_37_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_37_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9819\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1104\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 3.7817\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 39/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_38.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_38_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_38_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8260\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.1480\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.4563\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 40/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_39.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_39_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_39_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3161\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.4302\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.1289\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 41/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_40.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_40_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_40_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9447\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1363\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9919\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 42/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_41.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_41_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_41_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 2.5612\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1265\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.0202\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 43/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_42.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_42_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_42_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1725\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7380\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9800\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 44/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_43.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_43_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_43_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0014\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -4.1068\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9341\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 45/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_44.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_44_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_44_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.6051\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7786\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 2.1712\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 46/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_45.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_45_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_45_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0038\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9969\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0307\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 47/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_46.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_46_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_46_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9990\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9071\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.3994\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 48/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_47.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_47_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_47_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7874\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9948\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 49/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_48.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_48_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_48_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.7770\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8810\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -66.2549\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 50/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_49.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_49_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_49_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0810\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.0899\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.2625\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 51/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_50.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_50_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_50_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0790\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0029\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -58.7656\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 52/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_51.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_51_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_51_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.9437\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.2509\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -13.7440\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 53/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_52.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_52_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_52_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1024\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.3238\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.2931\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 54/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_53.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_53_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_53_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9987\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9902\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9159\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 55/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_54.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_54_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_54_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.2946\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9987\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1390\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 56/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_55.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_55_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_55_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.2268\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7284\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 57/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_56.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_56_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_56_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.7252\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0551\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9985\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 58/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_57.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_57_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_57_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9997\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0895\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 12.5671\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 59/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_58.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_58_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_58_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4685\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 60/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_59.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_59_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_59_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9864\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9247\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 61/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_60.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_60_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_60_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9001\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3177\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0184\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 62/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_61.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_61_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_61_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -2.7210\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0413\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 63/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_62.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_62_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_62_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0687\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0802\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 64/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_63.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_63_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_63_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.5834\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9992\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 3.1743\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 65/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_64.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_64_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_64_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0010\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -32.0058\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.0627\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 66/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_65.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_65_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_65_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9974\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.5561\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 15.1915\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 67/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_66.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_66_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_66_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9101\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6757\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3558\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 68/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_67.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_67_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_67_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9997\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7234\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9919\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 69/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_68.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_68_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_68_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.1713\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7580\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.3835\n",
      "\n",
      "Hierarchical training/testing completed successfully.\n",
      "Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# retrain model using the previous trained agents for high and low:\n",
    "############################\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "use_factor_returns = True  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "# regime_columns = daily_regimes.columns.tolist() \n",
    "# regime_columns = daily_regimes.columns.drop('Cluster').tolist() #### remove cluster in the feature set!!\n",
    "regime_columns = daily_regimes[['Cluster']].columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "raw_stock_returns = stock_returns_norm_filter\n",
    "load_existing_model = True\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "    \n",
    "    # Model paths explicitly defined for high and low-level models\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i-1}.zip\")  # Load previous model\n",
    "    new_high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")  # Save current model\n",
    "    \n",
    "    # Data splitting\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    # High-Level training data preparation (no look-ahead bias)\n",
    "    regime_features_high = train_df[regime_columns + factor_columns][:-rebalance_freq]\n",
    "    future_returns_high = np.array([\n",
    "        raw_returns_train.iloc[idx + 1: idx + rebalance_freq + 1].mean().mean()\n",
    "        for idx in range(len(regime_features_high))\n",
    "    ])\n",
    "\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(regime_features_high, future_returns_high)\n",
    "    ])\n",
    "    \n",
    "    # Load and continue training from previous window's model\n",
    "    if load_existing_model and i > 0 and os.path.exists(high_model_path):\n",
    "        print(\"Loading existing High-Level model from previous window...\")\n",
    "        high_model = PPO.load(high_model_path, env=high_env)\n",
    "        high_model.learn(total_timesteps=20000)  # shorter fine-tuning\n",
    "    else:\n",
    "        print(\"Training new High-Level Regime Selector from scratch...\")\n",
    "        high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "        high_model.learn(total_timesteps=50000)  # full training only for first window\n",
    "    \n",
    "    # Save updated high-level model explicitly for next window's reuse\n",
    "    high_model.save(new_high_model_path)\n",
    "    print(f\"High-level model saved at: {new_high_model_path}\")\n",
    "\n",
    "    # Generate historical regimes using the trained high-level model\n",
    "    historical_regimes = []\n",
    "    for idx in range(len(regime_features_high)):\n",
    "        obs = regime_features_high.iloc[idx].values\n",
    "        regime, _ = high_model.predict(obs, deterministic=True)\n",
    "        historical_regimes.append(int(regime))\n",
    "\n",
    "    historical_regimes = pd.Series(historical_regimes, index=regime_features_high.index)\n",
    "\n",
    "    # Low-level model training with incremental training\n",
    "    low_level_models = {}\n",
    "    for regime in historical_regimes.unique():\n",
    "        prev_low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i-1}_regime_{regime}.zip\")\n",
    "        current_low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        \n",
    "        regime_indices = historical_regimes[historical_regimes == regime].index\n",
    "        regime_df = train_df.loc[regime_indices]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        if load_existing_model and i > 0 and os.path.exists(prev_low_model_path):\n",
    "            print(f\"Loading existing Low-Level model for regime {regime} from previous window...\")\n",
    "            low_model = PPO.load(prev_low_model_path, env=low_env_train)\n",
    "            low_model.learn(total_timesteps=20000)  # shorter fine-tuning\n",
    "        else:\n",
    "            print(f\"Training new Low-Level model for regime {regime} from scratch...\")\n",
    "            low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "            low_model.learn(total_timesteps=50000)  # full training for first window or new regime\n",
    "\n",
    "        low_model.save(current_low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        print(f\"Low-level model for regime {regime} saved at: {current_low_model_path}\")\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns + factor_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "        print(f'chosen_regime = {chosen_regime} and check is {chosen_regime in low_level_models}')\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T21:24:31.589863Z",
     "start_time": "2025-04-12T20:01:46.008409Z"
    }
   },
   "id": "ce36553869f31a64",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e349ded169b8f2e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data explicitly\n",
    "port_wts = pd.read_csv('port_wt_test.csv', parse_dates=['Date'], index_col='Date')\n",
    "daily_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "common_tickers = [col for col in port_wts.columns if col in daily_returns.columns]\n",
    "daily_returns = daily_returns[common_tickers]\n",
    "\n",
    "# Explicitly filter daily returns to the date range covered by portfolio weights\n",
    "start_date, end_date = port_wts.index.min(), port_wts.index.max() + pd.Timedelta(days=30)\n",
    "daily_returns = daily_returns.loc[start_date:end_date]\n",
    "\n",
    "# Initialize drifted weights with the first available rebalance weights\n",
    "initial_weights = port_wts.loc[start_date].values\n",
    "\n",
    "equal_weight = np.array([1.0 / len(common_tickers)] * len(common_tickers))\n",
    "\n",
    "# Create drifted weights DataFrame explicitly initialized\n",
    "drifted_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "equal_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "\n",
    "current_weights = initial_weights\n",
    "current_equal_weights = equal_weight\n",
    "\n",
    "# Initialize returns DataFrame explicitly\n",
    "returns_df = pd.DataFrame(index=daily_returns.index, columns=['Optimal_Portfolio_Return', 'Equal_Weight_Return'])\n",
    "\n",
    "for current_date in daily_returns.index:\n",
    "    if current_date in port_wts.index:\n",
    "        # Explicit rebalance date: assign new weights\n",
    "        current_weights = port_wts.loc[current_date].values\n",
    "        current_equal_weights = equal_weight\n",
    "    else:\n",
    "        # Explicitly drift weights using previous day's return\n",
    "        prev_day_return = daily_returns.loc[current_date]\n",
    "\n",
    "        drifted_wts_numerator = current_weights * (1 + prev_day_return.values)\n",
    "        current_weights = drifted_wts_numerator / np.sum(drifted_wts_numerator)\n",
    "\n",
    "        equal_drifted_numerator = current_equal_weights * (1 + prev_day_return.values)\n",
    "        current_equal_weights = equal_drifted_numerator / np.sum(equal_drifted_numerator)\n",
    "\n",
    "    drifted_weights.loc[current_date] = current_weights\n",
    "    equal_weights.loc[current_date] = current_equal_weights\n",
    "    shifted_drifted_weights = drifted_weights.shift(1)\n",
    "    shifted_equal_weights = equal_weights.shift(1)\n",
    "    if current_date == daily_returns.index[0]:\n",
    "        # On the first day, use initial weights directly\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "    else:\n",
    "        # Explicitly use previous day's weights\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            shifted_drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            shifted_equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "\n",
    "# Check explicitly\n",
    "print(\"Drifted weights (head):\\n\", drifted_weights.head())\n",
    "print(\"\\nPortfolio returns (head):\\n\", returns_df.head())\n",
    "\n",
    "# Save explicitly\n",
    "drifted_weights.to_csv('drifted_weights_corrected.csv')\n",
    "equal_weights.to_csv('equal_weights.csv')\n",
    "returns_df.to_csv('portfolio_returns_combined.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-04-13T03:08:26.631145Z"
    }
   },
   "id": "7a61afcc56dc1982",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c210396b0873fdcd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3fe562f6a940d499"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b26da3b6ae907495"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30bcb8c14e88ec27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96198cc9e47c45cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8547ac5c980f9dda"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1dada654d4dfb0e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45958b710b89cbb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c4bb705a5ccda10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d64a4f2d2c8dd56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7e978ae98160ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d8b6daeffcdea6f"
  },
  {
   "cell_type": "raw",
   "source": [
    "OLD LOGIC "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4fd4eed4dbc1aff"
  },
  {
   "cell_type": "raw",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeSelectorEnv(gym.Env):\n",
    "    def __init__(self, regime_features_df, raw_future_returns_df):\n",
    "        super().__init__()\n",
    "        self.regime_features = regime_features_df.values\n",
    "        self.raw_future_returns = raw_future_returns_df.values  # Forward raw returns for evaluating regimes\n",
    "        self.current_step = 0\n",
    "        self.n_regimes = 2  # Adjust based on your clustering choice\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.n_regimes)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.regime_features.shape[1],),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.regime_features[self.current_step]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Reward calculated explicitly using raw future returns\n",
    "        reward = np.mean(self.raw_future_returns[self.current_step])\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.regime_features) - 1\n",
    "        \n",
    "        obs = self.regime_features[self.current_step] if not done else np.zeros(self.observation_space.shape)\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n",
    "class RegimeConditionedPortfolioEnv(gym.Env):\n",
    "    def __init__(self, returns_df, chosen_regime_vector, raw_returns_df):\n",
    "        super().__init__()\n",
    "        self.stock_returns = returns_df.values\n",
    "        self.chosen_regime_vector = chosen_regime_vector  # Regime indicator (chosen by high-level model)\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.n_assets + 1,),  # returns + chosen regime\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = np.array([self.chosen_regime_vector[self.current_step]])\n",
    "        obs = np.concatenate([returns, regime])\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        action = action / action_sum if action_sum != 0 else np.ones_like(action) / len(action)\n",
    "\n",
    "        # Explicitly use raw returns for reward calculation\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cee97d703e01592"
  },
  {
   "cell_type": "raw",
   "source": [
    "Step 3: Rolling Training and Out-of-Sample Testing (Hierarchical PPO)\n",
    "\n",
    "Here's how you train and test your hierarchical PPO model explicitly using rolling windows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c62e3ceb4c404943"
  },
  {
   "cell_type": "raw",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "# use_factor_returns = False  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "regime_columns = daily_regimes.columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # ----- High-Level Regime Selector Training -----\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(train_df[regime_columns], raw_returns_train)\n",
    "    ])\n",
    "    print(\"Training High-Level Regime Selector...\")\n",
    "    high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "    high_model.learn(total_timesteps=10000)\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "    high_model.save(high_model_path)\n",
    "    print(f\"High-level model saved at: {high_model_path}\")\n",
    "\n",
    "    # ----- Train Low-Level Models per Historical Regime -----\n",
    "    low_level_models = {}\n",
    "    unique_train_regimes = train_df['Cluster'].unique()\n",
    "\n",
    "    for regime in unique_train_regimes:\n",
    "        regime_df = train_df[train_df['Cluster'] == regime]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "        low_model.learn(total_timesteps=10000)\n",
    "        low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        low_model.save(low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        print(f\"Low-level model for regime {regime} saved at: {low_model_path}\")\n",
    "\n",
    "    # ----- Testing -----\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        ## choose random and average over 200 samples\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "             ## choose random and average over 200 samples\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8125d5e9d9e88f0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2044a2848f0119bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a54d2668debf911b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af248394e7e3c7f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c86be064a1e9705b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "271d7709439ea06c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "587d725b483c79fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a18ac95932480672"
  },
  {
   "cell_type": "raw",
   "source": [
    "# (1) Compute SHAP Regime Consistency (SRC)\n",
    "# \n",
    "# This metric measures how consistently SHAP values reflect the regime structure:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_src(shap_df, regime_labels):\n",
    "    \"\"\"\n",
    "    shap_df: DataFrame of SHAP values, shape [time, stock, factor]\n",
    "    regime_labels: Series/DataFrame with regime label per time period\n",
    "    \"\"\"\n",
    "    unique_dates = shap_df['End_Date'].unique()\n",
    "    src_values = []\n",
    "\n",
    "    for date in unique_dates:\n",
    "        # SHAP matrix S_t for current date\n",
    "        S_t_df = shap_df[shap_df['End_Date'] == date]\n",
    "        factors = ['mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "                   'mean_abs_shap_RMW', 'mean_abs_shap_CMA']\n",
    "        S_t = S_t_df[factors].values\n",
    "\n",
    "        regime = regime_labels.loc[date]\n",
    "\n",
    "        # SHAP matrix S_t|r (average SHAP in regime)\n",
    "        regime_dates = regime_labels[regime_labels == regime].index\n",
    "        S_r_df = shap_df[shap_df['End_Date'].isin(regime_dates)]\n",
    "        S_r = S_r_df[factors].values.mean(axis=0)\n",
    "\n",
    "        # Compute SRC numerator and denominator\n",
    "        numerator = np.trace(S_t @ S_t.T)\n",
    "        denominator = np.linalg.norm(S_t, 'fro') * np.linalg.norm(S_r, 'fro')\n",
    "        src = numerator / denominator if denominator != 0 else 0\n",
    "        src_values.append(src)\n",
    "\n",
    "    return np.mean(src_values)\n",
    "\n",
    "# Example call:\n",
    "# regime_labels: pd.Series(index=dates, data=regime numbers)\n",
    "# shap_metrics: loaded previously\n",
    "# SRC_result = compute_src(shap_metrics, regime_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9839f11da2a8f98f"
  },
  {
   "cell_type": "raw",
   "source": [
    "# (2) Compute Explanation Risk Premium (ERP)\n",
    "# \n",
    "# This metric assesses the returns premium tied to higher SHAP explanation stability:\n",
    "def compute_erp(shap_df, returns_df):\n",
    "    \"\"\"\n",
    "    shap_df: DataFrame containing Explanation Stability Index (psi) per stock per date\n",
    "    returns_df: DataFrame containing stock returns, same dates/stocks aligned\n",
    "    \"\"\"\n",
    "    erp_values = []\n",
    "    stocks = shap_df['Stock'].unique()\n",
    "\n",
    "    for stock in stocks:\n",
    "        # Filter data for the current stock\n",
    "        stock_shap = shap_df[shap_df['Stock'] == stock].copy()\n",
    "        stock_returns = returns_df[stock].loc[stock_shap['End_Date']].values\n",
    "        \n",
    "        # Stability index psi for the current stock\n",
    "        psi = stock_shap['mean_abs_over_std_Stock'].values\n",
    "\n",
    "        # Compute thresholds\n",
    "        psi_75 = np.percentile(psi, 75)\n",
    "        psi_25 = np.percentile(psi, 25)\n",
    "\n",
    "        # Returns conditioned on psi\n",
    "        high_psi_returns = stock_returns[psi > psi_75]\n",
    "        low_psi_returns = stock_returns[psi < psi_25]\n",
    "\n",
    "        # Calculate mean returns, handle division by zero\n",
    "        mean_high = np.mean(high_psi_returns) if len(high_psi_returns) > 0 else 0\n",
    "        mean_low = np.mean(low_psi_returns) if len(low_psi_returns) > 0 else 1e-8  # Avoid zero division\n",
    "\n",
    "        # ERP for current stock\n",
    "        erp_stock = (mean_high / mean_low) - 1\n",
    "        erp_values.append(erp_stock)\n",
    "\n",
    "    return np.mean(erp_values)\n",
    "\n",
    "# Example call:\n",
    "# returns_df: DataFrame [date  stock] returns loaded previously\n",
    "# shap_df: DataFrame loaded previously\n",
    "# ERP_result = compute_erp(shap_metrics, stock_returns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772ccc93fd01c00a"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Use the normalized SHAP features explicitly for validation metrics calculation:\n",
    "# Ensure regime labels are correctly aligned after clustering\n",
    "regime_labels = regime_features_norm['Regime']\n",
    "\n",
    "# Compute SHAP Regime Consistency (SRC) with normalized SHAP metrics\n",
    "SRC_result = compute_src(shap_features_norm_df, regime_labels)\n",
    "print(\"Normalized SHAP Regime Consistency (SRC):\", SRC_result)\n",
    "\n",
    "# Compute Explanation Risk Premium (ERP) using normalized data\n",
    "ERP_result = compute_erp(shap_features_norm_df, stock_returns_norm)\n",
    "print(\"Normalized Explanation Risk Premium (ERP):\", ERP_result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b18b3b06a0149fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
