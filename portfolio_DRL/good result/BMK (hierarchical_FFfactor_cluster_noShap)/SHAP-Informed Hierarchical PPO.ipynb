{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from SVERL_icml_2023.portfolio_DRL.data_function import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SVERL_icml_2023.portfolio_DRL.create_model import *\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from SVERL_icml_2023.shapley import Shapley\n",
    "import shap\n",
    "sys.path.append(\"E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023\")\n",
    "# from portfolio_DRL.create_model import StockPredictWrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data (as before)\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Select relevant SHAP features for regime clustering\n",
    "shap_features = shap_metrics[[\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA'\n",
    "]]\n",
    "\n",
    "# Normalize SHAP metrics using StandardScaler (mean=0, std=1)\n",
    "scaler_shap = StandardScaler()\n",
    "shap_features_normalized = scaler_shap.fit_transform(shap_features)\n",
    "\n",
    "# Save normalized SHAP metrics back to a DataFrame\n",
    "shap_features_norm_df = pd.DataFrame(\n",
    "    shap_features_normalized,\n",
    "    columns=shap_features.columns,\n",
    "    index=shap_metrics.index\n",
    ")\n",
    "\n",
    "# Include 'End_Date' and 'Stock' columns for reference\n",
    "shap_features_norm_df['End_Date'] = shap_metrics['End_Date']\n",
    "shap_features_norm_df['Stock'] = shap_metrics['Stock']\n",
    "\n",
    "# Drop non-numeric columns explicitly before aggregation\n",
    "numeric_columns = shap_features_norm_df.columns.drop(['End_Date', 'Stock'])\n",
    "\n",
    "# Aggregated SHAP regime-level features (average over DJ30 stocks per date)\n",
    "regime_features_norm = shap_features_norm_df.groupby('End_Date')[numeric_columns].mean().dropna()\n",
    "\n",
    "# Inspect aggregated and normalized regime-level SHAP features\n",
    "print(regime_features_norm.head())\n",
    "\n",
    "# Normalize factor returns similarly for PPO input\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize stock returns for PPO environment\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Inspect normalized data\n",
    "print(\"Normalized SHAP features:\", regime_features_norm.head())\n",
    "print(\"Normalized factor returns:\", factor_returns_norm.head())\n",
    "print(\"Normalized stock returns:\", stock_returns_norm.head())\n",
    "regime_features_norm.to_csv(\"regime_features_norm.csv\")\n",
    "factor_returns_norm.to_csv(\"factor_returns_norm.csv\")\n",
    "stock_returns_norm.to_csv(\"stock_returns_norm.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c807fd6acd5211a2"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Implement t-SNE and clustering to detect market regimes:\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# t-SNE Dimension reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(regime_features_norm)\n",
    "\n",
    "# Gaussian Mixture clustering (or KMeans as simpler alternative)\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "clusters = gmm.fit_predict(tsne_result)\n",
    "\n",
    "regime_features_norm['Regime'] = clusters\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(tsne_result[:,0], tsne_result[:,1], c=clusters, cmap='viridis')\n",
    "plt.title(\"t-SNE SHAP Regime Clustering\")\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.colorbar(label='Regime')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acee54455ebb1102"
  },
  {
   "cell_type": "raw",
   "source": [
    "1. Single-Step PPO: \"SinglePPOEnv\"\n",
    "\n",
    "Environment definition (rename explicitly):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81abba305046567"
  },
  {
   "cell_type": "raw",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "class SinglePPOEnv(gym.Env):\n",
    "    def __init__(self, stock_returns_norm, regime_features_norm):\n",
    "        super().__init__()\n",
    "        self.stock_returns = stock_returns_norm.values\n",
    "        self.regime_features = regime_features_norm['Regime'].values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets + 1,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = self.regime_features[self.current_step]\n",
    "        obs = np.concatenate([returns, [regime]])\n",
    "        obs = np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        if action_sum == 0:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "        else:\n",
    "            action /= action_sum\n",
    "\n",
    "        reward = np.dot(action, self.stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Explicit fix to ensure exactly 63 observations\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        # Adjust observation to always return valid step explicitly\n",
    "        if not done:\n",
    "            obs = self._get_obs()\n",
    "        else:\n",
    "            obs = np.zeros(self.observation_space.shape)\n",
    "\n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = 0.0\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b684f58e04c996c2"
  },
  {
   "cell_type": "raw",
   "source": [
    "Rolling Training and Out-of-Sample Testing (Single-Step PPO):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88d84e25cf2eeea"
  },
  {
   "cell_type": "raw",
   "source": [
    "single_step_records = []\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "total_windows = len(range(0, len(stock_returns_norm) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(stock_returns_norm) - train_window - test_window, test_window)):\n",
    "    \n",
    "    print(f\"\\nStarting training window {i+1}/{total_windows}...\")\n",
    "    \n",
    "    train_returns_df = stock_returns_norm.iloc[start : start + train_window].ffill()\n",
    "    test_returns_df = stock_returns_norm.iloc[start + train_window : start + train_window + test_window + 1].ffill()\n",
    "\n",
    "    train_regimes_df = regime_features_norm.iloc[start : start + train_window].ffill()\n",
    "    test_regimes_df = regime_features_norm.iloc[start + train_window : start + train_window + test_window + 1].ffill()\n",
    "\n",
    "    env = DummyVecEnv([lambda: SinglePPOEnv(train_returns_df, train_regimes_df)])\n",
    "    model = PPO('MlpPolicy', env, verbose=0)\n",
    "\n",
    "    print(\"Training PPO model...\")\n",
    "    model.learn(total_timesteps=10000)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    env_test = SinglePPOEnv(test_returns_df, test_regimes_df)\n",
    "    obs = env_test.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "\n",
    "    test_dates = test_returns_df.index[:-1].tolist()  # explicitly matching 63 steps\n",
    "\n",
    "    print(\"Starting out-of-sample evaluation...\")\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env_test.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        single_step_records.append({\n",
    "            'Date': test_dates[step_idx],\n",
    "            'Window': i,\n",
    "            'Step': step_idx,\n",
    "            'Reward': reward,\n",
    "            **{ticker: weight for ticker, weight in zip(tickers, action)}\n",
    "        })\n",
    "\n",
    "        step_idx += 1\n",
    "\n",
    "    print(f\"Window {i+1}/{total_windows} completed. Total Steps: {step_idx}, Total Out-of-Sample Reward: {total_reward:.4f}\")\n",
    "\n",
    "single_df = pd.DataFrame(single_step_records)\n",
    "single_df['Cumulative_Return'] = single_df['Reward'].cumsum()\n",
    "\n",
    "single_df.to_csv('single_step_allocations_with_dates.csv', index=False)\n",
    "\n",
    "single_pnl_df = single_df[['Date', 'Cumulative_Return']]\n",
    "single_pnl_df.to_csv('single_step_pnl_with_dates.csv', index=False)\n",
    "\n",
    "print(\"\\nAll training windows completed successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e6c5c167b729846"
  },
  {
   "cell_type": "raw",
   "source": [
    "New: 1. Single-Step PPO: \"SinglePPOEnv\"\n",
    "\n",
    "Environment definition (rename explicitly):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6597bad74c5aa6c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data explicitly\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Explicitly filter only 'Test' phase SHAP metrics\n",
    "shap_metrics_test = shap_metrics[shap_metrics['Phase'] == 'Test'].copy()\n",
    "\n",
    "# Verify explicitly\n",
    "print(f\"Total SHAP records (Test Phase): {len(shap_metrics_test)}\")\n",
    "\n",
    "# Select SHAP metrics explicitly\n",
    "selected_columns = [\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA',\n",
    "    'mean_abs_over_std_Mkt-RF', 'mean_abs_over_std_SMB', 'mean_abs_over_std_HML',\n",
    "    'mean_abs_over_std_RMW', 'mean_abs_over_std_CMA'\n",
    "]\n",
    "\n",
    "# Aggregate SHAP metrics explicitly by Start_Date and End_Date across stocks\n",
    "shap_agg = shap_metrics_test.groupby(['Start_Date', 'End_Date'])[selected_columns].mean().reset_index()\n",
    "\n",
    "# Explicitly scale SHAP metrics\n",
    "scaler_shap = StandardScaler()\n",
    "shap_agg[selected_columns] = scaler_shap.fit_transform(shap_agg[selected_columns])\n",
    "\n",
    "# Verify explicitly scaled SHAP metrics\n",
    "print(\"Scaled SHAP metrics (Test phase):\", shap_agg.head())\n",
    "\n",
    "# Explicitly map SHAP intervals to daily returns\n",
    "daily_regimes = pd.DataFrame(index=stock_returns.index)\n",
    "\n",
    "for _, row in shap_agg.iterrows():\n",
    "    mask = (daily_regimes.index >= row['Start_Date']) & (daily_regimes.index <= row['End_Date'])\n",
    "    daily_regimes.loc[mask, selected_columns] = row[selected_columns].values\n",
    "\n",
    "# Explicit forward-fill for continuity\n",
    "daily_regimes.ffill(inplace=True)\n",
    "daily_regimes.dropna(inplace=True)\n",
    "\n",
    "# Verify explicitly aligned daily regimes\n",
    "print(\"Daily regimes (aligned):\", daily_regimes.head())\n",
    "\n",
    "# Normalize explicitly factor returns\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize explicitly stock returns\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Merge explicitly into final dataset\n",
    "merged_data = stock_returns_norm.join(daily_regimes, how='inner').join(factor_returns_norm, rsuffix='_factor').dropna()\n",
    "\n",
    "# Explicit final dataset verification\n",
    "print(\"Merged normalized data preview:\", merged_data.head())\n",
    "\n",
    "# Save explicitly final aligned dataset\n",
    "merged_data.to_csv(\"final_merged_data.csv\")\n",
    "\n",
    "start_date = merged_data.index.min()\n",
    "end_date = merged_data.index.max()\n",
    "\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "raw_stock_returns = stock_returns.loc[start_date:end_date].copy()\n",
    "raw_stock_returns.to_csv(\"aligned_raw_stock_returns.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50052cf6eee1b086",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class SinglePPOEnv(gym.Env):\n",
    "    def __init__(self, returns_df, regime_df, raw_returns_df):\n",
    "        super().__init__()\n",
    "        self.stock_returns = returns_df.values\n",
    "        self.regime_features = regime_df.values\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "\n",
    "        # Adjust observation space shape accordingly\n",
    "        obs_dim = self.n_assets + self.regime_features.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_dim,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        stock_returns = self.stock_returns[self.current_step]\n",
    "        regime = self.regime_features[self.current_step]\n",
    "\n",
    "        obs = np.concatenate([stock_returns, regime])\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        action = action / action_sum if action_sum != 0 else np.ones_like(action) / len(action)\n",
    "\n",
    "        # Reward calculated explicitly using raw returns\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16986ba29a0650f7",
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "# reb every day\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "records = []\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\nStarting Window {i+1}/{total_windows}\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start+train_window]\n",
    "    test_df = merged_data.iloc[start+train_window:start+train_window+test_window+1]\n",
    "\n",
    "    env = DummyVecEnv([\n",
    "        lambda: SinglePPOEnv(train_df[tickers], train_df[selected_columns])\n",
    "    ])\n",
    "\n",
    "    model = PPO('MlpPolicy', env, verbose=0)\n",
    "    print(\"Training PPO model...\")\n",
    "    model.learn(total_timesteps=10000)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    print(\"Starting out-of-sample evaluation...\")\n",
    "    env_test = SinglePPOEnv(test_df[tickers], test_df[selected_columns])\n",
    "    obs = env_test.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    test_dates = test_df.index[:-1]\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env_test.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        records.append({\n",
    "            'Date': test_dates[step_idx],\n",
    "            'Window': i,\n",
    "            'Step': step_idx,\n",
    "            'Reward': reward,\n",
    "            **{ticker: weight for ticker, weight in zip(tickers, action)}\n",
    "        })\n",
    "\n",
    "        step_idx += 1\n",
    "\n",
    "    # print(f\"Window {i+1} completed, Steps: {step_idx}\")\n",
    "    print(f\"Window {i+1}/{total_windows} completed. Total Steps: {step_idx}, Total Out-of-Sample Reward: {total_reward:.4f}\")\n",
    "\n",
    "# Save explicitly final results\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"All windows completed successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "456e4f509a40f0be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# reb every 21 days\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_single_ppo/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21  # rebalance every 21 days\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "selected_columns = daily_regimes.columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist()\n",
    "use_factor_returns = False\n",
    "records = []\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Training Window {i+1}/{total_windows}\")\n",
    "    print(f\"Training Period: {merged_data.index[start].date()} to {merged_data.index[start + train_window - 1].date()}\")\n",
    "\n",
    "    # Explicit training and testing dataset slicing\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # Train PPO model explicitly\n",
    "    if use_factor_returns:\n",
    "        env = DummyVecEnv([\n",
    "            lambda: SinglePPOEnv(train_df[tickers], train_df[selected_columns + factor_columns], raw_returns_train)\n",
    "        ])\n",
    "    else:\n",
    "        env = DummyVecEnv([\n",
    "            lambda: SinglePPOEnv(train_df[tickers], train_df[selected_columns], raw_returns_train)\n",
    "        ])\n",
    "\n",
    "    model = PPO('MlpPolicy', env, verbose=0)\n",
    "    print(\"Training PPO model...\")\n",
    "    model.learn(total_timesteps=50000)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Save the trained model explicitly\n",
    "    model_filename = os.path.join(model_save_dir, f\"ppo_model_window_{i+1}.zip\")\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    # Testing phase setup\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[selected_columns + factor_columns].values if use_factor_returns else test_df[selected_columns].values\n",
    "\n",
    "    print(f\"\\nTesting Period: {test_dates[0].date()} to {test_dates[-1].date()} (63 days total)\")\n",
    "\n",
    "    # Evaluate every 21 days (3 rebalances per testing window)\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        print(f\"\\n--- Rebalance {rebalance_num + 1} ---\")\n",
    "        print(f\"Rebalance date: {test_dates[rebalance_start].date()}\")\n",
    "        print(f\"Holding period: {test_dates[rebalance_start].date()} to {test_dates[rebalance_end - 1].date()}\")\n",
    "\n",
    "        obs_returns = test_returns[rebalance_start:rebalance_end]\n",
    "        obs_regimes = test_regimes[rebalance_start:rebalance_end]\n",
    "        obs_raw_returns = raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "\n",
    "        env_test = SinglePPOEnv(\n",
    "            returns_df=pd.DataFrame(obs_returns, columns=tickers),\n",
    "            regime_df=pd.DataFrame(obs_regimes, columns=(selected_columns + factor_columns) if use_factor_returns else selected_columns),\n",
    "            raw_returns_df=obs_raw_returns\n",
    "        )\n",
    "\n",
    "        obs = env_test.reset()\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # Explicit normalization right here:\n",
    "        action_sum = action.sum()\n",
    "        if action_sum != 0:\n",
    "            action /= action_sum\n",
    "        else:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        print(f\"Normalized Portfolio weights:\\n{weights_dict}\")\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, obs_raw_returns.iloc[step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward for holding period: {cumulative_reward:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \"\\nAll training/testing windows completed successfully.\\n\" + \"=\"*30)\n",
    "\n",
    "# Save final results explicitly\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"Final results saved to 'single_step_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f741ad7b986bb6e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*30 + \"\\nAll training/testing windows completed successfully.\\n\" + \"=\"*30)\n",
    "\n",
    "# Save final results explicitly\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('single_step_allocations_dates_rebalanced.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff36318ecdaef1db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea46a06e07568b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f1dd301757f4969"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "# Load data explicitly\n",
    "shap_metrics = pd.read_csv('shap_value_metrics_export.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "factor_returns = pd.read_csv('aligned_factors.csv', parse_dates=['Date'], index_col='Date')\n",
    "stock_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Explicitly filter only 'Test' phase SHAP metrics\n",
    "shap_metrics_test = shap_metrics[shap_metrics['Phase'] == 'Test'].copy()\n",
    "\n",
    "# Verify explicitly\n",
    "print(f\"Total SHAP records (Test Phase): {len(shap_metrics_test)}\")\n",
    "\n",
    "# Select SHAP metrics explicitly\n",
    "selected_columns = [\n",
    "    'mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "    'mean_abs_shap_RMW', 'mean_abs_shap_CMA',\n",
    "    'shap_std_Mkt-RF', 'shap_std_SMB', 'shap_std_HML',\n",
    "    'shap_std_RMW', 'shap_std_CMA',\n",
    "    'mean_abs_over_std_Mkt-RF', 'mean_abs_over_std_SMB', 'mean_abs_over_std_HML',\n",
    "    'mean_abs_over_std_RMW', 'mean_abs_over_std_CMA'\n",
    "]\n",
    "\n",
    "# Aggregate SHAP metrics explicitly by Start_Date and End_Date across stocks\n",
    "shap_agg = shap_metrics_test.groupby(['Start_Date', 'End_Date'])[selected_columns].mean().reset_index()\n",
    "\n",
    "# Explicitly scale SHAP metrics\n",
    "scaler_shap = StandardScaler()\n",
    "shap_agg[selected_columns] = scaler_shap.fit_transform(shap_agg[selected_columns])\n",
    "\n",
    "# Verify explicitly scaled SHAP metrics\n",
    "# print(\"Scaled SHAP metrics (Test phase):\", shap_agg.head())\n",
    "\n",
    "# Explicitly map SHAP intervals to daily returns\n",
    "daily_regimes = pd.DataFrame(index=stock_returns.index)\n",
    "\n",
    "for _, row in shap_agg.iterrows():\n",
    "    mask = (daily_regimes.index >= row['Start_Date']) & (daily_regimes.index <= row['End_Date'])\n",
    "    daily_regimes.loc[mask, selected_columns] = row[selected_columns].values\n",
    "\n",
    "# Explicit forward-fill for continuity\n",
    "daily_regimes.ffill(inplace=True)\n",
    "daily_regimes.dropna(inplace=True)\n",
    "\n",
    "# Perform KMeans clustering explicitly on daily regimes\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "daily_regimes['Cluster'] = kmeans.fit_predict(daily_regimes[selected_columns])\n",
    "# daily_regimes['Cluster'] = 1 - daily_regimes['Cluster']\n",
    "# cluster_mapping = {0: 1, 1: 0}  # Good explicitly set as 1\n",
    "# daily_regimes['Cluster_Mapped'] = daily_regimes['Cluster'].map(cluster_mapping)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Example: Clustering raw returns into regimes\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# regime_labels = kmeans.fit_predict(raw_future_returns_df)\n",
    "# regime_labels_series = pd.Series(regime_labels, index=raw_future_returns_df.index)\n",
    "\n",
    "# Verify explicitly aligned daily regimes\n",
    "# print(\"Daily regimes (aligned):\", daily_regimes.head())\n",
    "\n",
    "# Normalize explicitly factor returns\n",
    "factor_scaler = StandardScaler()\n",
    "factor_returns_norm = pd.DataFrame(\n",
    "    factor_scaler.fit_transform(factor_returns),\n",
    "    index=factor_returns.index,\n",
    "    columns=factor_returns.columns\n",
    ")\n",
    "\n",
    "# Normalize explicitly stock returns\n",
    "stock_scaler = StandardScaler()\n",
    "stock_returns_norm = pd.DataFrame(\n",
    "    stock_scaler.fit_transform(stock_returns),\n",
    "    index=stock_returns.index,\n",
    "    columns=stock_returns.columns\n",
    ")\n",
    "\n",
    "# Merge explicitly into final dataset\n",
    "merged_data = stock_returns_norm.join(daily_regimes[['Cluster'] + selected_columns], how='inner')\\\n",
    "                                .join(factor_returns_norm, rsuffix='_factor')\\\n",
    "                                .dropna()\n",
    "\n",
    "# Explicit final dataset verification\n",
    "# print(\"Merged normalized data preview:\", merged_data.head())\n",
    "\n",
    "# Save explicitly final aligned dataset\n",
    "merged_data.to_csv(\"final_merged_data.csv\")\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "start_date = merged_data.index.min()\n",
    "end_date = merged_data.index.max()\n",
    "\n",
    "# Explicitly filter raw stock returns to match the merged_data dates\n",
    "raw_stock_returns = stock_returns.loc[start_date:end_date].copy()\n",
    "raw_stock_returns.to_csv(\"aligned_raw_stock_returns.csv\")\n",
    "\n",
    "stock_returns_norm_filter = stock_returns_norm.loc[start_date:end_date].copy()\n",
    "cluster_avg_returns = raw_stock_returns.join(daily_regimes['Cluster']).groupby('Cluster').mean().mean(axis=1)\n",
    "print(\"Explicit Cluster Mean Returns Check:\\n\", cluster_avg_returns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c0027f46cdbabce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use existing explicitly scaled SHAP metrics from daily_regimes\n",
    "regime_data = daily_regimes.values\n",
    "cluster_range = range(2, 11)  # Evaluate 2 to 10 clusters explicitly\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "calinski_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(regime_data)\n",
    "\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(regime_data, labels))\n",
    "    calinski_scores.append(calinski_harabasz_score(regime_data, labels))\n",
    "\n",
    "    print(f\"Clusters: {k} | Inertia: {kmeans.inertia_:.2f} | \"\n",
    "          f\"Silhouette: {silhouette_scores[-1]:.4f} | \"\n",
    "          f\"Calinski-Harabasz: {calinski_scores[-1]:.2f}\")\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "ax[0].plot(cluster_range, inertia, 'bo-', linewidth=2)\n",
    "ax[0].set_title('Elbow Method (Inertia)', fontsize=14)\n",
    "ax[0].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[0].set_ylabel('Inertia', fontsize=12)\n",
    "\n",
    "ax[1].plot(cluster_range, silhouette_scores, 'go-', linewidth=2)\n",
    "ax[1].set_title('Silhouette Score', fontsize=14)\n",
    "ax[1].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "\n",
    "ax[2].plot(cluster_range, calinski_scores, 'ro-', linewidth=2)\n",
    "ax[2].set_title('Calinski-Harabasz Index', fontsize=14)\n",
    "ax[2].set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax[2].set_ylabel('Calinski-Harabasz Score', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5e18248d57def17",
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "# daily_regimes['Cluster'] = labels\n",
    "# returns_by_cluster = stock_returns_norm.join(daily_regimes['Cluster'])\n",
    "# # print(returns_by_cluster.groupby('Cluster').mean())\n",
    "# \n",
    "# print(returns_by_cluster.groupby('Cluster').std())\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "daily_regimes['Cluster'] = kmeans.fit_predict(daily_regimes[selected_columns])\n",
    "# Do NOT include 'Cluster' in regime_columns explicitly, because that's a label not a feature:\n",
    "regime_columns = selected_columns.copy()\n",
    "# Explicit join:\n",
    "merged_data = stock_returns_norm.join(\n",
    "    daily_regimes[['Cluster'] + regime_columns], \n",
    "    how='inner'\n",
    ").dropna()\n",
    "\n",
    "# Verify explicitly:\n",
    "print(merged_data.head())\n",
    "# High-Level environment explicitly using only regime_columns (SHAP metrics):\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50eec2710513c348"
  },
  {
   "cell_type": "raw",
   "source": [
    "Step 1: High-Level PPO (Regime Selector)\n",
    "\n",
    "High-Level Regime Selector Environment:\n",
    "Step 2: Low-Level PPO (Portfolio Allocator)\n",
    "\n",
    "Regime-Conditioned Portfolio Environment:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5792785ff137338f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeSelectorEnv(gym.Env):\n",
    "    def __init__(self, regime_features_df, raw_future_returns_df):\n",
    "        super().__init__()\n",
    "        self.regime_features = regime_features_df.values\n",
    "        # self.raw_future_returns = raw_future_returns_df.values\n",
    "        self.raw_future_returns = raw_future_returns_df\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.n_regimes = 2  # Regimes: 0 = bad, 1 = good\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.n_regimes)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.regime_features.shape[1],),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.regime_features[self.current_step]\n",
    "\n",
    "    def step(self, action):\n",
    "        avg_future_return = np.mean(self.raw_future_returns[self.current_step])\n",
    "\n",
    "        # Reward logic explicitly explained:\n",
    "        # - action = 1 (predict good regime): reward = avg_future_return\n",
    "        # - action = 0 (predict bad regime): reward = -avg_future_return\n",
    "        # Thus, correct predictions yield positive rewards, incorrect yield negative rewards.\n",
    "        reward = avg_future_return if action == 1 else -avg_future_return\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.regime_features) - 1\n",
    "\n",
    "        obs = (\n",
    "            self.regime_features[self.current_step]\n",
    "            if not done else np.zeros(self.observation_space.shape)\n",
    "        )\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeConditionedPortfolioEnv(gym.Env):\n",
    "    def __init__(self, returns_df, chosen_regime_vector, raw_returns_df, factor_returns_df=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stock_returns = returns_df.values\n",
    "        self.chosen_regime_vector = chosen_regime_vector\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.factor_returns = factor_returns_df.values if factor_returns_df is not None else None\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        \n",
    "        obs_dim = self.n_assets + 1\n",
    "        if self.factor_returns is not None:\n",
    "            obs_dim += self.factor_returns.shape[1]\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_dim,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = np.array([self.chosen_regime_vector[self.current_step]])\n",
    "        obs = np.concatenate([returns, regime])\n",
    "\n",
    "        if self.factor_returns is not None:\n",
    "            factor_obs = self.factor_returns[self.current_step]\n",
    "            obs = np.concatenate([obs, factor_obs])\n",
    "\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        if action_sum == 0:\n",
    "            action = np.ones_like(action) / len(action)\n",
    "        else:\n",
    "            action = action / action_sum\n",
    "\n",
    "        # Intuitive reward: explicitly realized portfolio return\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fa6000d68203e53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "use_factor_returns = False  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "# regime_columns = daily_regimes.columns.tolist() #### remove cluster in the feature set!!\n",
    "regime_columns = daily_regimes.columns.drop('Cluster').tolist()\n",
    "# regime_columns = daily_regimes[['Cluster']].columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "raw_stock_returns = stock_returns_norm_filter\n",
    "load_existing_model = False\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # High-Level training data preparation (no look-ahead bias)\n",
    "    regime_features_high = train_df[regime_columns + factor_columns][:-rebalance_freq]\n",
    "    future_returns_high = np.array([\n",
    "        raw_returns_train.iloc[idx + 1: idx + rebalance_freq + 1].mean().mean()\n",
    "        for idx in range(len(regime_features_high))\n",
    "    ])\n",
    "\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(regime_features_high, future_returns_high)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Load existing high-level model or train a new one\n",
    "    if load_existing_model and os.path.exists(high_model_path):\n",
    "        print(\"Loading existing High-Level Regime Selector model...\")\n",
    "        high_model = PPO.load(high_model_path, env=high_env)\n",
    "        high_model.learn(total_timesteps=3000)  # continue training briefly\n",
    "        print(f\"Continued training on High-Level model. Saved again to {high_model_path}.\")\n",
    "    else:\n",
    "        print(\"Training new High-Level Regime Selector model...\")\n",
    "        # policy_kwargs = dict(net_arch=[128, 64], activation_fn=nn.Tanh)\n",
    "        # \n",
    "        # high_model = PPO(\n",
    "        #     'MlpPolicy', high_env, verbose=0,\n",
    "        #     learning_rate=1e-4,\n",
    "        #     n_steps=2048,\n",
    "        #     batch_size=128,\n",
    "        #     gamma=0.95,\n",
    "        #     ent_coef=0.005,  # Slightly lower entropy encourages differentiation\n",
    "        #     clip_range=0.2,\n",
    "        #     n_epochs=10,\n",
    "        #     policy_kwargs=policy_kwargs\n",
    "        # )\n",
    "        # high_model.learn(total_timesteps=10000)\n",
    "    \n",
    "        print(\"Training High-Level Regime Selector...\")\n",
    "        high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "        high_model.learn(total_timesteps=50000)\n",
    "    # high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "    # high_model.save(high_model_path)\n",
    "    # print(f\"High-level model saved at: {high_model_path}\")\n",
    "\n",
    "    # Generate historical regimes for low-level model training (no look-ahead)\n",
    "    historical_regimes = []\n",
    "    for idx in range(len(regime_features_high)):\n",
    "        obs = regime_features_high.iloc[idx].values\n",
    "        regime, _ = high_model.predict(obs, deterministic=True)\n",
    "        historical_regimes.append(int(regime))\n",
    "\n",
    "    historical_regimes = pd.Series(historical_regimes, index=regime_features_high.index)\n",
    "\n",
    "    # Train low-level models per historical regime\n",
    "    low_level_models = {}\n",
    "    for regime in historical_regimes.unique():\n",
    "        low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        regime_indices = historical_regimes[historical_regimes == regime].index\n",
    "        regime_df = train_df.loc[regime_indices]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        if load_existing_model and os.path.exists(low_model_path):\n",
    "            print(f\"Loading existing Low-Level model for regime {regime}...\")\n",
    "            low_model = PPO.load(low_model_path, env=low_env_train)\n",
    "            low_model.learn(total_timesteps=3000)  # brief continued training\n",
    "            print(f\"Continued training on Low-Level model regime {regime}. Saved again to {low_model_path}.\")\n",
    "        else:\n",
    "            print(f\"Training new Low-Level model for regime {regime}...\")\n",
    "            # low_model = PPO(\n",
    "            #     'MlpPolicy', low_env_train, verbose=0,\n",
    "            #     learning_rate=5e-5,\n",
    "            #     n_steps=2048,\n",
    "            #     batch_size=128,\n",
    "            #     gamma=0.97,\n",
    "            #     ent_coef=0.003,  # Reduced entropy to discourage uniform policy\n",
    "            #     clip_range=0.2,\n",
    "            #     n_epochs=10,\n",
    "            #     policy_kwargs=policy_kwargs\n",
    "            # )\n",
    "            # low_model.learn(total_timesteps=10000)\n",
    "\n",
    "            low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "            low_model.learn(total_timesteps=50000)\n",
    "        # low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        # low_model.save(low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        # print(f\"Low-level model for regime {regime} saved at: {low_model_path}\")\n",
    "\n",
    "    # Testing\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns + factor_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "        print(f'chosen_regime = {chosen_regime} and check is {chosen_regime in low_level_models}')\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a3b88d647f58602",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 1/69\n",
      "Training new High-Level Regime Selector from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_0.zip\n",
      "Training new Low-Level model for regime 1 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_0_regime_1.zip\n",
      "Training new Low-Level model for regime 0 from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_0_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9998\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9827\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0030\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 2/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_1.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_1_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_1_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 4.5405\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -2.0394\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0411\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 3/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_2.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_2_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_2_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0090\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9966\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 4/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_3.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_3_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_3_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0001\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9475\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9991\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 5/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_4.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_4_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_4_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0011\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9713\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9961\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 6/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_5.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_5_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_5_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -42.9232\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -3277.7236\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1676.3724\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 7/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_6.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_6_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_6_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0207\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -2.2250\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 8/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_7.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_7_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_7_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -2.1877\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.2201\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1634\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 9/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_8.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_8_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_8_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9994\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -6.5759\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1251\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 10/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_9.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_9_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_9_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9722\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9701\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0063\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 11/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_10.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_10_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_10_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9877\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0008\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 14.1490\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 12/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_11.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_11_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_11_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1312\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0236\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0041\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 13/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_12.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_12_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_12_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0086\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9981\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 14/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_13.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_13_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_13_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0034\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9994\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0009\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 15/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_14.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_14_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_14_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.1592\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.8633\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9969\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 16/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_15.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_15_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_15_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.5241\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 4.5769\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9974\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 17/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_16.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_16_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_16_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9522\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0023\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -44.2267\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 18/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_17.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_17_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_17_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -6.6258\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -34.4259\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 19/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_18.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_18_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_18_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4326\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 1.6111\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.0948\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 20/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_19.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_19_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_19_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9850\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0007\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.4036\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 21/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_20.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_20_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_20_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.4919\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6491\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.7632\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 22/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_21.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_21_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_21_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1751\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9998\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6428\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 23/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_22.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_22_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_22_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.2940\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8399\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.1326\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 24/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_23.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_23_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_23_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9172\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0052\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9986\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 25/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_24.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_24_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_24_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7849\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.1798\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0205\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 26/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_25.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_25_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_25_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9804\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4262\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6731\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 27/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_26.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_26_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_26_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.5183\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9783\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8811\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 28/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_27.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_27_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_27_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0258\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7129\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4837\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 29/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_28.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_28_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_28_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.6458\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0371\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.3988\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 30/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_29.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_29_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_29_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6306\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0039\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 31/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_30.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_30_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_30_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9982\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0090\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9968\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 32/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_31.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_31_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_31_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.8070\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9794\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.0260\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 33/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_32.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_32_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_32_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.3312\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0109\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9999\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 34/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_33.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_33_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_33_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0991\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.6872\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0027\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 35/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_34.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_34_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_34_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0003\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0011\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 23.8354\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 36/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_35.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_35_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_35_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.5232\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9933\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0545\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 37/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_36.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_36_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_36_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -5.4147\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4883\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.3047\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 38/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_37.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_37_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_37_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9819\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1104\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 3.7817\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 39/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_38.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_38_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_38_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8260\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.1480\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.4563\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 40/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_39.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_39_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_39_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3161\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.4302\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.1289\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 41/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_40.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_40_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_40_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9447\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1363\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9919\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 42/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_41.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_41_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_41_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 2.5612\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.1265\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.0202\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 43/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_42.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_42_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_42_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.1725\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7380\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9800\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 44/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_43.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_43_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_43_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0014\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -4.1068\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9341\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 45/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_44.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_44_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_44_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.6051\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7786\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 2.1712\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 46/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_45.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_45_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_45_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0038\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9969\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0307\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 47/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_46.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_46_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_46_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9990\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9071\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.3994\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 48/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_47.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_47_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_47_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7874\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9948\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 49/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_48.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_48_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_48_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.7770\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.8810\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -66.2549\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 50/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_49.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_49_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_49_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0810\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.0899\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.2625\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 51/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_50.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_50_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_50_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.0790\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0029\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -58.7656\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 52/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_51.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_51_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_51_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.9437\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.2509\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -13.7440\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 53/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_52.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_52_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_52_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1024\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.3238\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.2931\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 54/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_53.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_53_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_53_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9987\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9902\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9159\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 55/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_54.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_54_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_54_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.2946\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9987\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.1390\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 56/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_55.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_55_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_55_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 1.2268\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7284\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 57/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_56.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_56_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_56_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.7252\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0551\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9985\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 58/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_57.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_57_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_57_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9997\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0895\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 12.5671\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 59/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_58.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_58_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_58_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.4685\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 60/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_59.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_59_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_59_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9864\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9247\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 61/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_60.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_60_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_60_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9001\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3177\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0184\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 62/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_61.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_61_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_61_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0000\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -2.7210\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0413\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 63/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_62.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_62_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_62_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0687\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -1.0802\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0002\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 64/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_63.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_63_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_63_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 0.5834\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9992\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 3.1743\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 65/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_64.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_64_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_64_regime_0.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -1.0010\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -32.0058\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.0627\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 66/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_65.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_65_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_65_regime_1.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9974\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.5561\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: 15.1915\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 67/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_66.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_66_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_66_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.9101\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.6757\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.3558\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 68/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_67.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_67_regime_1.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_67_regime_0.zip\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9997\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7234\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.9919\n",
      "\n",
      "==============================\n",
      "Starting Hierarchical Training Window 69/69\n",
      "Loading existing High-Level model from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-level model saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/high_model_window_68.zip\n",
      "Loading existing Low-Level model for regime 0 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 0 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_68_regime_0.zip\n",
      "Loading existing Low-Level model for regime 1 from previous window...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level model for regime 1 saved at: E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/low_model_window_68_regime_1.zip\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: 0.1713\n",
      "chosen_regime = 1 and check is True\n",
      "Cumulative reward: -0.7580\n",
      "chosen_regime = 0 and check is True\n",
      "Cumulative reward: -0.3835\n",
      "\n",
      "Hierarchical training/testing completed successfully.\n",
      "Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# retrain model using the previous trained agents for high and low:\n",
    "############################\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "use_factor_returns = True  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "# regime_columns = daily_regimes.columns.tolist() \n",
    "# regime_columns = daily_regimes.columns.drop('Cluster').tolist() #### remove cluster in the feature set!!\n",
    "regime_columns = daily_regimes[['Cluster']].columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "raw_stock_returns = stock_returns_norm_filter\n",
    "load_existing_model = True\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "    \n",
    "    # Model paths explicitly defined for high and low-level models\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i-1}.zip\")  # Load previous model\n",
    "    new_high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")  # Save current model\n",
    "    \n",
    "    # Data splitting\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    # High-Level training data preparation (no look-ahead bias)\n",
    "    regime_features_high = train_df[regime_columns + factor_columns][:-rebalance_freq]\n",
    "    future_returns_high = np.array([\n",
    "        raw_returns_train.iloc[idx + 1: idx + rebalance_freq + 1].mean().mean()\n",
    "        for idx in range(len(regime_features_high))\n",
    "    ])\n",
    "\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(regime_features_high, future_returns_high)\n",
    "    ])\n",
    "    \n",
    "    # Load and continue training from previous window's model\n",
    "    if load_existing_model and i > 0 and os.path.exists(high_model_path):\n",
    "        print(\"Loading existing High-Level model from previous window...\")\n",
    "        high_model = PPO.load(high_model_path, env=high_env)\n",
    "        high_model.learn(total_timesteps=20000)  # shorter fine-tuning\n",
    "    else:\n",
    "        print(\"Training new High-Level Regime Selector from scratch...\")\n",
    "        high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "        high_model.learn(total_timesteps=50000)  # full training only for first window\n",
    "    \n",
    "    # Save updated high-level model explicitly for next window's reuse\n",
    "    high_model.save(new_high_model_path)\n",
    "    print(f\"High-level model saved at: {new_high_model_path}\")\n",
    "\n",
    "    # Generate historical regimes using the trained high-level model\n",
    "    historical_regimes = []\n",
    "    for idx in range(len(regime_features_high)):\n",
    "        obs = regime_features_high.iloc[idx].values\n",
    "        regime, _ = high_model.predict(obs, deterministic=True)\n",
    "        historical_regimes.append(int(regime))\n",
    "\n",
    "    historical_regimes = pd.Series(historical_regimes, index=regime_features_high.index)\n",
    "\n",
    "    # Low-level model training with incremental training\n",
    "    low_level_models = {}\n",
    "    for regime in historical_regimes.unique():\n",
    "        prev_low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i-1}_regime_{regime}.zip\")\n",
    "        current_low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        \n",
    "        regime_indices = historical_regimes[historical_regimes == regime].index\n",
    "        regime_df = train_df.loc[regime_indices]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        if load_existing_model and i > 0 and os.path.exists(prev_low_model_path):\n",
    "            print(f\"Loading existing Low-Level model for regime {regime} from previous window...\")\n",
    "            low_model = PPO.load(prev_low_model_path, env=low_env_train)\n",
    "            low_model.learn(total_timesteps=20000)  # shorter fine-tuning\n",
    "        else:\n",
    "            print(f\"Training new Low-Level model for regime {regime} from scratch...\")\n",
    "            low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "            low_model.learn(total_timesteps=50000)  # full training for first window or new regime\n",
    "\n",
    "        low_model.save(current_low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        print(f\"Low-level model for regime {regime} saved at: {current_low_model_path}\")\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns + factor_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "        print(f'chosen_regime = {chosen_regime} and check is {chosen_regime in low_level_models}')\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T21:24:31.589863Z",
     "start_time": "2025-04-12T20:01:46.008409Z"
    }
   },
   "id": "ce36553869f31a64",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e349ded169b8f2e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drifted weights (head):\n",
      "              BA AMGN       DIS       NKE       HON       MMM  CAT   KO  \\\n",
      "Date                                                                     \n",
      "2007-06-12  0.0  0.0    0.0338    0.0573     0.024    0.0579  0.0  0.0   \n",
      "2007-06-13  0.0  0.0  0.033766  0.057049  0.024147  0.058784  0.0  0.0   \n",
      "2007-06-14  0.0  0.0  0.033889  0.056808  0.024243  0.058471  0.0  0.0   \n",
      "2007-06-15  0.0  0.0  0.034323  0.056241  0.024379  0.058336  0.0  0.0   \n",
      "2007-06-18  0.0  0.0  0.034665  0.056794   0.02408  0.058644  0.0  0.0   \n",
      "\n",
      "                  PG  AXP  ...      MSFT  TRV  UNH       CVX  JNJ       MRK  \\\n",
      "Date                       ...                                                \n",
      "2007-06-12    0.1217  0.0  ...    0.1391  0.0  0.0    0.0722  0.0    0.0052   \n",
      "2007-06-13  0.120918  0.0  ...  0.140232  0.0  0.0  0.072018  0.0  0.005195   \n",
      "2007-06-14  0.120055  0.0  ...  0.139715  0.0  0.0  0.072486  0.0  0.005109   \n",
      "2007-06-15  0.119722  0.0  ...  0.138857  0.0  0.0  0.072847  0.0  0.005134   \n",
      "2007-06-18  0.118884  0.0  ...  0.139763  0.0  0.0  0.073468  0.0  0.005153   \n",
      "\n",
      "                AMZN       WMT      INTC        VZ  \n",
      "Date                                                \n",
      "2007-06-12    0.2027     0.007    0.0273    0.1154  \n",
      "2007-06-13  0.203068  0.007015  0.027605  0.113795  \n",
      "2007-06-14  0.204441  0.006929  0.028063  0.113734  \n",
      "2007-06-15  0.204686  0.006901  0.029132  0.112545  \n",
      "2007-06-18  0.204265  0.006909  0.029218  0.112046  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Portfolio returns (head):\n",
      "            Optimal_Portfolio_Return Equal_Weight_Return\n",
      "Date                                                   \n",
      "2007-06-12                -0.011148           -0.008804\n",
      "2007-06-13                 0.009871            0.011249\n",
      "2007-06-14                 0.007995            0.003241\n",
      "2007-06-15                 0.005189            0.006454\n",
      "2007-06-18                -0.005829           -0.001938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data explicitly\n",
    "port_wts = pd.read_csv('port_wt_test.csv', parse_dates=['Date'], index_col='Date')\n",
    "daily_returns = pd.read_csv('daily_returns.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "common_tickers = [col for col in port_wts.columns if col in daily_returns.columns]\n",
    "daily_returns = daily_returns[common_tickers]\n",
    "\n",
    "# Explicitly filter daily returns to the date range covered by portfolio weights\n",
    "start_date, end_date = port_wts.index.min(), port_wts.index.max() + pd.Timedelta(days=30)\n",
    "daily_returns = daily_returns.loc[start_date:end_date]\n",
    "\n",
    "# Initialize drifted weights with the first available rebalance weights\n",
    "initial_weights = port_wts.loc[start_date].values\n",
    "\n",
    "equal_weight = np.array([1.0 / len(common_tickers)] * len(common_tickers))\n",
    "\n",
    "# Create drifted weights DataFrame explicitly initialized\n",
    "drifted_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "equal_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "\n",
    "current_weights = initial_weights\n",
    "current_equal_weights = equal_weight\n",
    "\n",
    "# Initialize returns DataFrame explicitly\n",
    "returns_df = pd.DataFrame(index=daily_returns.index, columns=['Optimal_Portfolio_Return', 'Equal_Weight_Return'])\n",
    "\n",
    "for current_date in daily_returns.index:\n",
    "    if current_date in port_wts.index:\n",
    "        # Explicit rebalance date: assign new weights\n",
    "        current_weights = port_wts.loc[current_date].values\n",
    "        current_equal_weights = equal_weight\n",
    "    else:\n",
    "        # Explicitly drift weights using previous day's return\n",
    "        prev_day_return = daily_returns.loc[current_date]\n",
    "\n",
    "        drifted_wts_numerator = current_weights * (1 + prev_day_return.values)\n",
    "        current_weights = drifted_wts_numerator / np.sum(drifted_wts_numerator)\n",
    "\n",
    "        equal_drifted_numerator = current_equal_weights * (1 + prev_day_return.values)\n",
    "        current_equal_weights = equal_drifted_numerator / np.sum(equal_drifted_numerator)\n",
    "\n",
    "    drifted_weights.loc[current_date] = current_weights\n",
    "    equal_weights.loc[current_date] = current_equal_weights\n",
    "    shifted_drifted_weights = drifted_weights.shift(1)\n",
    "    shifted_equal_weights = equal_weights.shift(1)\n",
    "    if current_date == daily_returns.index[0]:\n",
    "        # On the first day, use initial weights directly\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "    else:\n",
    "        # Explicitly use previous day's weights\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            shifted_drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            shifted_equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "\n",
    "# Check explicitly\n",
    "print(\"Drifted weights (head):\\n\", drifted_weights.head())\n",
    "print(\"\\nPortfolio returns (head):\\n\", returns_df.head())\n",
    "\n",
    "# Save explicitly\n",
    "drifted_weights.to_csv('drifted_weights_corrected.csv')\n",
    "equal_weights.to_csv('equal_weights.csv')\n",
    "returns_df.to_csv('portfolio_returns_combined.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-12T23:16:10.649235Z",
     "start_time": "2025-04-12T23:15:58.160413Z"
    }
   },
   "id": "7a61afcc56dc1982",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c210396b0873fdcd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3fe562f6a940d499"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b26da3b6ae907495"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30bcb8c14e88ec27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96198cc9e47c45cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8547ac5c980f9dda"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1dada654d4dfb0e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45958b710b89cbb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c4bb705a5ccda10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d64a4f2d2c8dd56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7e978ae98160ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d8b6daeffcdea6f"
  },
  {
   "cell_type": "raw",
   "source": [
    "OLD LOGIC "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4fd4eed4dbc1aff"
  },
  {
   "cell_type": "raw",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class RegimeSelectorEnv(gym.Env):\n",
    "    def __init__(self, regime_features_df, raw_future_returns_df):\n",
    "        super().__init__()\n",
    "        self.regime_features = regime_features_df.values\n",
    "        self.raw_future_returns = raw_future_returns_df.values  # Forward raw returns for evaluating regimes\n",
    "        self.current_step = 0\n",
    "        self.n_regimes = 2  # Adjust based on your clustering choice\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.n_regimes)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.regime_features.shape[1],),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.regime_features[self.current_step]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Reward calculated explicitly using raw future returns\n",
    "        reward = np.mean(self.raw_future_returns[self.current_step])\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.regime_features) - 1\n",
    "        \n",
    "        obs = self.regime_features[self.current_step] if not done else np.zeros(self.observation_space.shape)\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "\n",
    "class RegimeConditionedPortfolioEnv(gym.Env):\n",
    "    def __init__(self, returns_df, chosen_regime_vector, raw_returns_df):\n",
    "        super().__init__()\n",
    "        self.stock_returns = returns_df.values\n",
    "        self.chosen_regime_vector = chosen_regime_vector  # Regime indicator (chosen by high-level model)\n",
    "        self.raw_stock_returns = raw_returns_df.values\n",
    "        self.current_step = 0\n",
    "        self.n_assets = self.stock_returns.shape[1]\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.n_assets + 1,),  # returns + chosen regime\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        returns = self.stock_returns[self.current_step]\n",
    "        regime = np.array([self.chosen_regime_vector[self.current_step]])\n",
    "        obs = np.concatenate([returns, regime])\n",
    "        return np.nan_to_num(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        action_sum = action.sum()\n",
    "        action = action / action_sum if action_sum != 0 else np.ones_like(action) / len(action)\n",
    "\n",
    "        # Explicitly use raw returns for reward calculation\n",
    "        reward = np.dot(action, self.raw_stock_returns[self.current_step + 1])\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.stock_returns) - 1\n",
    "\n",
    "        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape)\n",
    "        reward = 0.0 if np.isnan(reward) else reward\n",
    "        return obs, reward, done, {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cee97d703e01592"
  },
  {
   "cell_type": "raw",
   "source": [
    "Step 3: Rolling Training and Out-of-Sample Testing (Hierarchical PPO)\n",
    "\n",
    "Here's how you train and test your hierarchical PPO model explicitly using rolling windows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c62e3ceb4c404943"
  },
  {
   "cell_type": "raw",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "model_save_dir = 'E:/XAI/RL_with_SHAP/pythonProject1/SVERL_icml_2023/portfolio_DRL/trained_hierarchical_model/'\n",
    "\n",
    "train_window, test_window = 252, 63\n",
    "rebalance_freq = 21\n",
    "# use_factor_returns = False  # Set this flag as needed\n",
    "tickers = stock_returns_norm.columns.tolist()\n",
    "regime_columns = daily_regimes.columns.tolist()\n",
    "factor_columns = factor_returns_norm.columns.tolist() if use_factor_returns else []\n",
    "records = []\n",
    "\n",
    "total_windows = len(range(0, len(merged_data) - train_window - test_window, test_window))\n",
    "\n",
    "for i, start in enumerate(range(0, len(merged_data) - train_window - test_window, test_window)):\n",
    "    print(f\"\\n{'='*30}\\nStarting Hierarchical Training Window {i+1}/{total_windows}\")\n",
    "\n",
    "    train_df = merged_data.iloc[start:start + train_window]\n",
    "    test_df = merged_data.iloc[start + train_window:start + train_window + test_window + 1]\n",
    "    raw_returns_train = raw_stock_returns.loc[train_df.index]\n",
    "    raw_returns_test = raw_stock_returns.loc[test_df.index]\n",
    "\n",
    "    if train_df.isna().values.any() or test_df.isna().values.any():\n",
    "        print(f\"Skipping window {i+1} due to NaNs.\")\n",
    "        continue\n",
    "\n",
    "    # ----- High-Level Regime Selector Training -----\n",
    "    high_env = DummyVecEnv([\n",
    "        lambda: RegimeSelectorEnv(train_df[regime_columns], raw_returns_train)\n",
    "    ])\n",
    "    print(\"Training High-Level Regime Selector...\")\n",
    "    high_model = PPO('MlpPolicy', high_env, verbose=0)\n",
    "    high_model.learn(total_timesteps=10000)\n",
    "    high_model_path = os.path.join(model_save_dir, f\"high_model_window_{i}.zip\")\n",
    "    high_model.save(high_model_path)\n",
    "    print(f\"High-level model saved at: {high_model_path}\")\n",
    "\n",
    "    # ----- Train Low-Level Models per Historical Regime -----\n",
    "    low_level_models = {}\n",
    "    unique_train_regimes = train_df['Cluster'].unique()\n",
    "\n",
    "    for regime in unique_train_regimes:\n",
    "        regime_df = train_df[train_df['Cluster'] == regime]\n",
    "        chosen_regime_vector_train = np.repeat(regime, len(regime_df))\n",
    "\n",
    "        low_env_train = DummyVecEnv([\n",
    "            lambda: RegimeConditionedPortfolioEnv(\n",
    "                returns_df=regime_df[tickers],\n",
    "                chosen_regime_vector=chosen_regime_vector_train,\n",
    "                raw_returns_df=raw_returns_train.loc[regime_df.index]\n",
    "            )\n",
    "        ])\n",
    "        low_model = PPO('MlpPolicy', low_env_train, verbose=0)\n",
    "        low_model.learn(total_timesteps=10000)\n",
    "        low_model_path = os.path.join(model_save_dir, f\"low_model_window_{i}_regime_{regime}.zip\")\n",
    "        low_model.save(low_model_path)\n",
    "        low_level_models[regime] = low_model\n",
    "        print(f\"Low-level model for regime {regime} saved at: {low_model_path}\")\n",
    "\n",
    "    # ----- Testing -----\n",
    "    test_dates = test_df.index\n",
    "    test_returns = test_df[tickers].values\n",
    "    test_regimes = test_df[regime_columns].values\n",
    "\n",
    "    for rebalance_num, rebalance_start in enumerate(range(0, test_window, rebalance_freq)):\n",
    "        rebalance_end = min(rebalance_start + rebalance_freq, test_window)\n",
    "\n",
    "        high_obs = test_regimes[rebalance_start]\n",
    "        ## choose random and average over 200 samples\n",
    "        chosen_regime, _ = high_model.predict(high_obs, deterministic=True)\n",
    "        chosen_regime = int(chosen_regime.item())\n",
    "        # high_predictions = [high_model.predict(high_obs, deterministic=False)[0].item() for _ in range(200)]\n",
    "        # chosen_regime = int(pd.Series(high_predictions).mode()[0])  # take most common predicted regime\n",
    "\n",
    "        \n",
    "        chosen_regime_vector_test = np.repeat(chosen_regime, rebalance_end - rebalance_start)\n",
    "\n",
    "        if chosen_regime in low_level_models:\n",
    "            low_model = low_level_models[chosen_regime]\n",
    "            low_env_test = RegimeConditionedPortfolioEnv(\n",
    "                returns_df=pd.DataFrame(test_returns[rebalance_start:rebalance_end], columns=tickers),\n",
    "                chosen_regime_vector=chosen_regime_vector_test,\n",
    "                raw_returns_df=raw_returns_test.iloc[rebalance_start:rebalance_end]\n",
    "            )\n",
    "\n",
    "            low_obs = low_env_test.reset()\n",
    "             ## choose random and average over 200 samples\n",
    "            action, _ = low_model.predict(low_obs, deterministic=True)\n",
    "            action /= action.sum()\n",
    "            # action_samples = np.array([\n",
    "            #     low_model.predict(low_obs, deterministic=False)[0]\n",
    "            #     for _ in range(200)\n",
    "            # ])\n",
    "            # action_mean = action_samples.mean(axis=0)\n",
    "            # action_mean /= action_mean.sum()  # normalization\n",
    "            # action = action_mean\n",
    "            \n",
    "        else:\n",
    "            action = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "        portfolio_value = 1.0\n",
    "        for step in range(rebalance_end - rebalance_start - 1):\n",
    "            reward = np.dot(action, raw_returns_test.iloc[rebalance_start + step + 1])\n",
    "            portfolio_value *= (1 + reward)\n",
    "        cumulative_reward = portfolio_value - 1.0\n",
    "\n",
    "        weights_dict = {ticker: round(weight, 4) for ticker, weight in zip(tickers, action)}\n",
    "        records.append({\n",
    "            'Rebalance_Date': test_dates[rebalance_start],\n",
    "            'Window': i,\n",
    "            'Rebalance_Number': rebalance_num,\n",
    "            'Chosen_Regime': chosen_regime,\n",
    "            'Holding_Period_Start': test_dates[rebalance_start],\n",
    "            'Holding_Period_End': test_dates[rebalance_end - 1],\n",
    "            'Cumulative_Reward': cumulative_reward,\n",
    "            **weights_dict\n",
    "        })\n",
    "\n",
    "        print(f\"Cumulative reward: {cumulative_reward:.4f}\")\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df['Cumulative_Return'] = result_df['Cumulative_Reward'].cumsum()\n",
    "result_df.to_csv('hierarchical_allocations_dates_rebalanced.csv', index=False)\n",
    "\n",
    "print(\"\\nHierarchical training/testing completed successfully.\")\n",
    "print(\"Final hierarchical results saved to 'hierarchical_allocations_dates_rebalanced.csv'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8125d5e9d9e88f0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2044a2848f0119bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a54d2668debf911b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af248394e7e3c7f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c86be064a1e9705b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "271d7709439ea06c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "587d725b483c79fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a18ac95932480672"
  },
  {
   "cell_type": "raw",
   "source": [
    "# (1) Compute SHAP Regime Consistency (SRC)\n",
    "# \n",
    "# This metric measures how consistently SHAP values reflect the regime structure:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_src(shap_df, regime_labels):\n",
    "    \"\"\"\n",
    "    shap_df: DataFrame of SHAP values, shape [time, stock, factor]\n",
    "    regime_labels: Series/DataFrame with regime label per time period\n",
    "    \"\"\"\n",
    "    unique_dates = shap_df['End_Date'].unique()\n",
    "    src_values = []\n",
    "\n",
    "    for date in unique_dates:\n",
    "        # SHAP matrix S_t for current date\n",
    "        S_t_df = shap_df[shap_df['End_Date'] == date]\n",
    "        factors = ['mean_abs_shap_Mkt-RF', 'mean_abs_shap_SMB', 'mean_abs_shap_HML',\n",
    "                   'mean_abs_shap_RMW', 'mean_abs_shap_CMA']\n",
    "        S_t = S_t_df[factors].values\n",
    "\n",
    "        regime = regime_labels.loc[date]\n",
    "\n",
    "        # SHAP matrix S_t|r (average SHAP in regime)\n",
    "        regime_dates = regime_labels[regime_labels == regime].index\n",
    "        S_r_df = shap_df[shap_df['End_Date'].isin(regime_dates)]\n",
    "        S_r = S_r_df[factors].values.mean(axis=0)\n",
    "\n",
    "        # Compute SRC numerator and denominator\n",
    "        numerator = np.trace(S_t @ S_t.T)\n",
    "        denominator = np.linalg.norm(S_t, 'fro') * np.linalg.norm(S_r, 'fro')\n",
    "        src = numerator / denominator if denominator != 0 else 0\n",
    "        src_values.append(src)\n",
    "\n",
    "    return np.mean(src_values)\n",
    "\n",
    "# Example call:\n",
    "# regime_labels: pd.Series(index=dates, data=regime numbers)\n",
    "# shap_metrics: loaded previously\n",
    "# SRC_result = compute_src(shap_metrics, regime_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9839f11da2a8f98f"
  },
  {
   "cell_type": "raw",
   "source": [
    "# (2) Compute Explanation Risk Premium (ERP)\n",
    "# \n",
    "# This metric assesses the returns premium tied to higher SHAP explanation stability:\n",
    "def compute_erp(shap_df, returns_df):\n",
    "    \"\"\"\n",
    "    shap_df: DataFrame containing Explanation Stability Index (psi) per stock per date\n",
    "    returns_df: DataFrame containing stock returns, same dates/stocks aligned\n",
    "    \"\"\"\n",
    "    erp_values = []\n",
    "    stocks = shap_df['Stock'].unique()\n",
    "\n",
    "    for stock in stocks:\n",
    "        # Filter data for the current stock\n",
    "        stock_shap = shap_df[shap_df['Stock'] == stock].copy()\n",
    "        stock_returns = returns_df[stock].loc[stock_shap['End_Date']].values\n",
    "        \n",
    "        # Stability index psi for the current stock\n",
    "        psi = stock_shap['mean_abs_over_std_Stock'].values\n",
    "\n",
    "        # Compute thresholds\n",
    "        psi_75 = np.percentile(psi, 75)\n",
    "        psi_25 = np.percentile(psi, 25)\n",
    "\n",
    "        # Returns conditioned on psi\n",
    "        high_psi_returns = stock_returns[psi > psi_75]\n",
    "        low_psi_returns = stock_returns[psi < psi_25]\n",
    "\n",
    "        # Calculate mean returns, handle division by zero\n",
    "        mean_high = np.mean(high_psi_returns) if len(high_psi_returns) > 0 else 0\n",
    "        mean_low = np.mean(low_psi_returns) if len(low_psi_returns) > 0 else 1e-8  # Avoid zero division\n",
    "\n",
    "        # ERP for current stock\n",
    "        erp_stock = (mean_high / mean_low) - 1\n",
    "        erp_values.append(erp_stock)\n",
    "\n",
    "    return np.mean(erp_values)\n",
    "\n",
    "# Example call:\n",
    "# returns_df: DataFrame [date × stock] returns loaded previously\n",
    "# shap_df: DataFrame loaded previously\n",
    "# ERP_result = compute_erp(shap_metrics, stock_returns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772ccc93fd01c00a"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Use the normalized SHAP features explicitly for validation metrics calculation:\n",
    "# Ensure regime labels are correctly aligned after clustering\n",
    "regime_labels = regime_features_norm['Regime']\n",
    "\n",
    "# Compute SHAP Regime Consistency (SRC) with normalized SHAP metrics\n",
    "SRC_result = compute_src(shap_features_norm_df, regime_labels)\n",
    "print(\"Normalized SHAP Regime Consistency (SRC):\", SRC_result)\n",
    "\n",
    "# Compute Explanation Risk Premium (ERP) using normalized data\n",
    "ERP_result = compute_erp(shap_features_norm_df, stock_returns_norm)\n",
    "print(\"Normalized Explanation Risk Premium (ERP):\", ERP_result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b18b3b06a0149fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
