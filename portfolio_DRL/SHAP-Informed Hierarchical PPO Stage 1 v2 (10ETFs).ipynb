{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T03:49:10.422998Z",
     "start_time": "2025-08-10T03:48:57.661977Z"
    }
   },
   "outputs": [],
   "source": [
    "# stage 1 training and prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import ta\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "REG_PARAM_GRID = {\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [600, 1000],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"min_child_weight\": [1.0],\n",
    "    \"reg_lambda\": [1.0, 2.0],\n",
    "}\n",
    "SEEDS = [42, 202]\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "# ------------------------------------------------------------------------\n",
    "# 0. Load and align data\n",
    "# ------------------------------------------------------------------------\n",
    "factors = pd.read_csv(\"aligned_factors.csv\", index_col=0, parse_dates=True)\n",
    "returns = pd.read_csv(\"daily_returns_10ETFs.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align dates to ensure matching indices\n",
    "dates = factors.index.intersection(returns.index)\n",
    "factors = factors.loc[dates]\n",
    "returns = returns.loc[dates]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1. Compute technical indicators and lagged features per ETF\n",
    "# ------------------------------------------------------------------------\n",
    "all_tech_features = []\n",
    "\n",
    "for etf in returns.columns:\n",
    "    close = (1 + returns[etf]).cumprod()\n",
    "    tech_df = pd.DataFrame(index=returns.index)\n",
    "\n",
    "    # Selected indicators (others commented out to reduce noise)\n",
    "    tech_df[f'{etf}_SMA_5']   = ta.trend.sma_indicator(close, window=5)\n",
    "    tech_df[f'{etf}_EMA_12']  = ta.trend.ema_indicator(close, window=12)\n",
    "    tech_df[f'{etf}_RSI_7']   = ta.momentum.rsi(close, window=7)\n",
    "    tech_df[f'{etf}_MACD']    = ta.trend.macd_diff(close)\n",
    "    tech_df[f'{etf}_ATR']     = ta.volatility.average_true_range(\n",
    "        high=close * 1.01, low=close * 0.99, close=close, window=10\n",
    "    )\n",
    "    tech_df[f'{etf}_Vol_5']   = returns[etf].rolling(window=5).std()\n",
    "    tech_df[f'{etf}_Mom_3']   = returns[etf].rolling(window=3).mean()\n",
    "\n",
    "    # Lagged returns (shifted so only past information is used)\n",
    "    for lag in [1, 2, 3]:\n",
    "        tech_df[f'{etf}_LagRet_{lag}'] = returns[etf].shift(lag)\n",
    "\n",
    "    all_tech_features.append(tech_df)\n",
    "\n",
    "# Concatenate technical indicators for all ETFs\n",
    "technical_features = pd.concat(all_tech_features, axis=1)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. Create lagged factor features\n",
    "# ------------------------------------------------------------------------\n",
    "for factor in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']:\n",
    "    for lag in [1, 2, 3]:\n",
    "        factors[f'{factor}_lag_{lag}'] = factors[factor].shift(lag)\n",
    "\n",
    "# Drop rows with NA values arising from lagging\n",
    "factors = factors.dropna()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Combine factors, technical features, and VIX change\n",
    "# ------------------------------------------------------------------------\n",
    "features = pd.concat([factors, technical_features], axis=1).dropna()\n",
    "vix = pd.read_csv(\"VIX_History.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align VIX to our feature dates and compute lagged change\n",
    "vix_aligned = vix['CLOSE'].reindex(features.index).ffill()\n",
    "features['VIX'] = vix_aligned.pct_change(fill_method=None).shift(1)\n",
    "features['VIX'] = features['VIX'].fillna(0)\n",
    "\n",
    "# Define the target: next-day return per ETF\n",
    "target_returns = returns.shift(-1).loc[features.index].dropna()\n",
    "features = features.loc[target_returns.index]\n",
    "\n",
    "train_years = 12      # years used for training\n",
    "valid_years = 1       # years used for validation\n",
    "test_years  = 1       # years used for testing/prediction\n",
    "retrain_frequency = 1 # years between retrainings\n",
    "start_year = 2009\n",
    "end_year   = 2024\n",
    "\n",
    "# ========= SHAP gate: pick top-N features across ETF-specific + Fama-French =========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# How many total features to keep (ETF + global, combined)\n",
    "# TOP_N_FEATURES = 10   # <- tune this (e.g., 12–20 works well)\n",
    "\n",
    "# ---- Globals & helpers needed by the SHAP gate ----\n",
    "\n",
    "# Global (macro) factors you maintain in your `features` frame\n",
    "GLOBAL_FACTORS = [\n",
    "    \"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\",\n",
    "    \"Mkt-RF_lag_1\", \"Mkt-RF_lag_2\", \"Mkt-RF_lag_3\",\n",
    "    \"SMB_lag_1\", \"SMB_lag_2\", \"SMB_lag_3\",\n",
    "    \"HML_lag_1\", \"HML_lag_2\", \"HML_lag_3\",\n",
    "    \"RMW_lag_1\", \"RMW_lag_2\", \"RMW_lag_3\",\n",
    "    \"CMA_lag_1\", \"CMA_lag_2\", \"CMA_lag_3\",\n",
    "    \"VIX\"  # include if present; harmless if missing later\n",
    "]\n",
    "\n",
    "# ETF-specific feature suffixes (no ETF prefix here; we’ll prepend per-ETF when building panel)\n",
    "ETF_SUFFIX_POOL = [\n",
    "    \"SMA_5\",\"EMA_12\",\"RSI_7\",\"MACD\",\"ATR\",\"Vol_5\",\"Mom_3\",\"LagRet_1\",\"LagRet_2\",\"LagRet_3\"\n",
    "]\n",
    "\n",
    "def _robust_cs(x):\n",
    "    med = x.median()\n",
    "    mad = (x - med).abs().median()\n",
    "    return (x - med) / (mad + 1e-6)\n",
    "\n",
    "def _make_forward_returns(daily_ret_df: pd.DataFrame, horizon=21, method=\"compound\"):\n",
    "    if method == \"compound\":\n",
    "        cum = (1.0 + daily_ret_df).cumprod()\n",
    "        return cum.shift(-horizon) / cum - 1.0\n",
    "    return daily_ret_df.rolling(horizon).sum().shift(-horizon)\n",
    "\n",
    "def _build_panel_for_gate(features_df, returns_df, etfs, start, end, forward_h=21, use_risk_adj=True):\n",
    "    \"\"\"Same idea as your build_panel, used only for the SHAP gate on a base window.\"\"\"\n",
    "    feat = features_df.loc[start:end].copy()\n",
    "    rets = returns_df.loc[start:end].copy()\n",
    "\n",
    "    # forward returns (compound)\n",
    "    cum = (1.0 + rets).cumprod()\n",
    "    fwd = cum.shift(-forward_h) / cum - 1.0\n",
    "    vol20 = rets.rolling(20).std()\n",
    "\n",
    "    rows = []\n",
    "    for dt in feat.index:\n",
    "        if dt not in fwd.index: \n",
    "            continue\n",
    "        for etf in etfs:\n",
    "            row = {\"Date\": dt, \"ETF\": etf}\n",
    "            # ETF-specific columns\n",
    "            for suf in ETF_SUFFIX_POOL:\n",
    "                col = f\"{etf}_{suf}\"\n",
    "                if col not in feat.columns:\n",
    "                    continue\n",
    "                row[suf] = feat.at[dt, col]\n",
    "            # global factors (no ETF prefix) if present in features\n",
    "            for gf in GLOBAL_FACTORS:\n",
    "                if gf in feat.columns:\n",
    "                    row[gf] = feat.at[dt, gf]\n",
    "            # label\n",
    "            y = fwd.at[dt, etf]\n",
    "            if use_risk_adj:\n",
    "                v = vol20.at[dt, etf]\n",
    "                y = np.nan if (pd.isna(y) or pd.isna(v)) else (y / max(v, 1e-6))\n",
    "            row[\"y\"] = y\n",
    "            rows.append(row)\n",
    "\n",
    "    panel = pd.DataFrame(rows).dropna()\n",
    "    if panel.empty:\n",
    "        raise ValueError(\"SHAP gate panel is empty—check date ranges and column names.\")\n",
    "\n",
    "    feat_cols = [c for c in panel.columns if c not in [\"Date\",\"ETF\",\"y\"]]\n",
    "    # do NOT cross-sec standardize global factors; only ETF‑specific features\n",
    "    cs_cols = [c for c in feat_cols if c not in GLOBAL_FACTORS]\n",
    "    panel[cs_cols] = panel.groupby(\"Date\")[cs_cols].transform(_robust_cs)\n",
    "\n",
    "    # Light winsorization on ETF‑specific features\n",
    "    for c in cs_cols:\n",
    "        q1, q99 = panel[c].quantile([0.01, 0.99])\n",
    "        panel[c] = panel[c].clip(q1, q99)\n",
    "\n",
    "    panel.sort_values([\"Date\",\"ETF\"], inplace=True)\n",
    "    panel.reset_index(drop=True, inplace=True)\n",
    "    return panel\n",
    "\n",
    "def run_shap_gate_select_topN(features_df, returns_df, etfs,\n",
    "                              start_year, train_years, valid_years,\n",
    "                              forward_h=21, use_risk_adj=True,\n",
    "                              top_n=10, min_suffixes=6, max_globals=4, seed=42):\n",
    "    \"\"\"\n",
    "    Enforce a balanced mix: at least `min_suffixes` ETF-specific suffixes,\n",
    "    and at most `max_globals` macro families. Families are MKT/SMB/HML/RMW/CMA(+VIX if present).\n",
    "    We return:\n",
    "      - selected ETF suffixes (names like 'RSI_7', 'MACD', ...)\n",
    "      - selected macro columns (best single lag per family, e.g., 'Mkt-RF_lag_2')\n",
    "      - a table with the gate-ranking for debugging\n",
    "    \"\"\"\n",
    "    assert min_suffixes + max_globals <= top_n, \"Choose top_n >= min_suffixes + max_globals\"\n",
    "\n",
    "    base_train_start = pd.Timestamp(start_year - train_years, 1, 1)\n",
    "    base_train_end   = pd.Timestamp(start_year - valid_years - 1, 12, 31)\n",
    "\n",
    "    panel = _build_panel_for_gate(features_df, returns_df, etfs,\n",
    "                                  base_train_start, base_train_end,\n",
    "                                  forward_h=forward_h, use_risk_adj=use_risk_adj)\n",
    "    feat_cols = [c for c in panel.columns if c not in [\"Date\",\"ETF\",\"y\"]]\n",
    "    Xb, yb = panel[feat_cols].values, panel[\"y\"].values\n",
    "\n",
    "    # quick regression for SHAP importances\n",
    "    params = dict(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=4,\n",
    "        eta=0.08,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        seed=int(seed),\n",
    "        sampling_method=\"uniform\",\n",
    "    )\n",
    "    dtrain = xgb.DMatrix(Xb, label=yb)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=400, verbose_eval=False)\n",
    "\n",
    "    # SHAP importances per column\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    sv = explainer.shap_values(Xb)               # (n, d)\n",
    "    shap_mean_abs = np.abs(sv).mean(axis=0)      # (d,)\n",
    "    col_imp = pd.Series(shap_mean_abs, index=feat_cols).sort_values(ascending=False)\n",
    "\n",
    "    # --- ETF-specific suffix importance (one column per suffix) ---\n",
    "    suf_imp = {s: float(col_imp.get(s, 0.0)) for s in ETF_SUFFIX_POOL if s in col_imp.index}\n",
    "    suf_rank = pd.Series(suf_imp).sort_values(ascending=False)\n",
    "\n",
    "    # --- Macro family importance (aggregate all lags within a family) ---\n",
    "    fam_to_cols = {\n",
    "        \"MKT\": [c for c in feat_cols if c.startswith(\"Mkt-RF\")],\n",
    "        \"SMB\": [c for c in feat_cols if c.startswith(\"SMB\")],\n",
    "        \"HML\": [c for c in feat_cols if c.startswith(\"HML\")],\n",
    "        \"RMW\": [c for c in feat_cols if c.startswith(\"RMW\")],\n",
    "        \"CMA\": [c for c in feat_cols if c.startswith(\"CMA\")],\n",
    "    }\n",
    "    if \"VIX\" in feat_cols:\n",
    "        fam_to_cols[\"VIX\"] = [\"VIX\"]\n",
    "\n",
    "    fam_imp = {}\n",
    "    fam_best_col = {}\n",
    "    for fam, cols in fam_to_cols.items():\n",
    "        cols = [c for c in cols if c in col_imp.index]\n",
    "        if not cols:\n",
    "            continue\n",
    "        fam_imp[fam] = float(col_imp[cols].sum())\n",
    "        fam_best_col[fam] = col_imp[cols].idxmax()   # best single lag/column within the family\n",
    "\n",
    "    fam_rank = pd.Series(fam_imp).sort_values(ascending=False)\n",
    "\n",
    "    # --- Enforce quotas ---\n",
    "    sel_suffixes = list(suf_rank.head(min_suffixes).index)\n",
    "    sel_fams     = list(fam_rank.head(max_globals).index)\n",
    "\n",
    "    # If suffixes are scarce, backfill from pool order\n",
    "    if len(sel_suffixes) < min_suffixes:\n",
    "        backfill = [s for s in ETF_SUFFIX_POOL if s not in sel_suffixes]\n",
    "        sel_suffixes += backfill[:(min_suffixes - len(sel_suffixes))]\n",
    "    sel_suffixes = sel_suffixes[:min_suffixes]\n",
    "\n",
    "    # Map families to a single best column per family\n",
    "    sel_global_cols = [fam_best_col[f] for f in sel_fams if f in fam_best_col]\n",
    "\n",
    "    # Pretty table for logging\n",
    "    gate_table = pd.concat([\n",
    "        suf_rank.rename(\"mean_abs_shap\").to_frame().assign(kind=\"suffix\"),\n",
    "        fam_rank.rename(\"mean_abs_shap\").to_frame().assign(kind=\"family\"),\n",
    "    ], axis=0)\n",
    "\n",
    "    return sel_suffixes, sel_global_cols, gate_table\n",
    "\n",
    "\n",
    "\n",
    "# Infer ETF universe (if you don’t already have it)\n",
    "etf_list = list(returns.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified gate selected suffixes: ['ATR', 'LagRet_1', 'LagRet_2', 'EMA_12', 'MACD', 'Mom_3']\n",
      "Unified gate selected macro columns: ['Mkt-RF', 'CMA_lag_2', 'HML_lag_2', 'SMB_lag_2']\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2009 ===\n",
      "Window 2009 done in 418.92s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2010 ===\n",
      "Window 2010 done in 460.69s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2011 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2011 done in 424.74s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2012 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2012 done in 429.19s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2013 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2013 done in 427.40s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2014 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2014 done in 420.76s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2015 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2015 done in 413.23s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2016 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2016 done in 410.36s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2017 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2017 done in 403.40s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2018 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2018 done in 419.39s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2019 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2019 done in 405.18s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2020 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2020 done in 411.04s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2021 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2021 done in 520.06s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2022 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2022 done in 386.14s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2023 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2023 done in 369.17s\n",
      "\n",
      "=== Stage‑1 (Unified‑gate) per‑ETF regression | window 2024 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n",
      "C:\\Users\\Jiayang\\AppData\\Local\\Temp\\ipykernel_29064\\929335556.py:112: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  ic, _ = spearmanr(y, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2024 done in 412.62s\n",
      "Stage‑1 with unified SHAP gate complete. Wrote:\n",
      "  - stage1_predictions_with_shap_DIA_ETF.csv\n",
      "  - stage1_unified_gate_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ===================== Unified SHAP Gate -> Per-ETF Stage-1 =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import spearmanr\n",
    "import time, os, json\n",
    "import os, numpy as np, pandas as pd, xgboost as xgb, shap\n",
    "# ---------------- Config ----------------\n",
    "FWD_H_ETF          = 1      # predict next-day return; switch to 21 for 1-month forward\n",
    "USE_RISK_ADJ_ETF   = False  # risk-adjusted label? (start False for clarity)\n",
    "TOP_N_GENERIC      = 10     # <- your N\n",
    "MIN_SUFFIXES       = 6      # ensure enough ETF-specific cross-sectional info\n",
    "MAX_GLOBAL_FAMILIES= 4      # cap macro families kept\n",
    "EMA_SMOOTH_SPAN    = 0      # optional smoothing of Predicted_Score; 0 disables\n",
    "ART_DIR            = \"stage1_models_unified_gate\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "XGB_TREE_METHOD = \"hist\"    # \"hist\" (CPU) is deterministic; GPU can introduce tiny nondeterminism\n",
    "\n",
    "REG_PARAM_GRID = {\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [600, 1000],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"min_child_weight\": [1.0],\n",
    "    \"reg_lambda\": [1.0, 2.0],\n",
    "}\n",
    "SEEDS = [42, 202]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# Fixed pools (keep as you already defined)\n",
    "ETF_SUFFIX_POOL = [\n",
    "    \"SMA_5\",\"EMA_12\",\"RSI_7\",\"MACD\",\"ATR\",\"Vol_5\",\"Mom_3\",\"LagRet_1\",\"LagRet_2\",\"LagRet_3\"\n",
    "]\n",
    "MACRO_FAMILY_MAP = {\n",
    "    \"MKT\": [\"Mkt-RF\", \"Mkt-RF_lag_1\",\"Mkt-RF_lag_2\",\"Mkt-RF_lag_3\"],\n",
    "    \"SMB\": [\"SMB\",    \"SMB_lag_1\",\"SMB_lag_2\",\"SMB_lag_3\"],\n",
    "    \"HML\": [\"HML\",    \"HML_lag_1\",\"HML_lag_2\",\"HML_lag_3\"],\n",
    "    \"RMW\": [\"RMW\",    \"RMW_lag_1\",\"RMW_lag_2\",\"RMW_lag_3\"],\n",
    "    \"CMA\": [\"CMA\",    \"CMA_lag_1\",\"CMA_lag_2\",\"CMA_lag_3\"],\n",
    "}\n",
    "if \"VIX\" in features.columns:\n",
    "    MACRO_FAMILY_MAP[\"VIX\"] = [\"VIX\"]\n",
    "\n",
    "TOP_N_GENERIC       = 10   # your N\n",
    "MIN_SUFFIXES        = 6\n",
    "MAX_GLOBAL_FAMILIES = 4\n",
    "EPS_TIE = 1e-12            # treat values within this as equal\n",
    "\n",
    "# Stable, deterministic XGB for the gate (no subsampling, single thread)\n",
    "GATE_XGB = dict(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    n_estimators=512,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.08,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    min_child_weight=1.0,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    seed=GLOBAL_SEED,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# def _forward_returns(series: pd.Series, horizon=1, risk_adj=False):\n",
    "#     if horizon == 1:\n",
    "#         fwd = series.shift(-1)\n",
    "#     else:\n",
    "#         cum = (1.0 + series).cumprod()\n",
    "#         fwd = cum.shift(-horizon) / cum - 1.0\n",
    "#     if risk_adj:\n",
    "#         vol20 = series.rolling(20).std()\n",
    "#         fwd = fwd / (vol20.replace(0, np.nan) + 1e-6)\n",
    "#     return fwd\n",
    "\n",
    "def _stable_sort_pairs(pairs):\n",
    "    \"\"\"pairs: list of (name, score). Sort by score desc, then name asc.\"\"\"\n",
    "    return sorted(pairs, key=lambda t: (-t[1], t[0]))\n",
    "\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def _forward_returns_1d(series: pd.Series, horizon=1, risk_adj=False, vol20: pd.Series=None):\n",
    "    if horizon == 1:\n",
    "        fwd = series.shift(-1)\n",
    "    else:\n",
    "        cum = (1.0 + series).cumprod()\n",
    "        fwd = cum.shift(-horizon) / cum - 1.0\n",
    "    if risk_adj:\n",
    "        if vol20 is None:\n",
    "            vol20 = series.rolling(20).std()\n",
    "        fwd = fwd / (vol20.replace(0, np.nan) + 1e-6)\n",
    "    return fwd\n",
    "\n",
    "def _ts_ic(y, p):\n",
    "    y, p = np.asarray(y), np.asarray(p)\n",
    "    m = np.isfinite(y) & np.isfinite(p)\n",
    "    y, p = y[m], p[m]\n",
    "    if len(y) < 5 or np.std(y) < 1e-12 or np.std(p) < 1e-12:\n",
    "        return np.nan\n",
    "    ic, _ = spearmanr(y, p)\n",
    "    return float(ic) if np.isfinite(ic) else np.nan\n",
    "\n",
    "def build_ds_from_cols(etf: str, start, end, selected_suffixes: list, selected_macro_cols: list,\n",
    "                       horizon=1, risk_adj=False, imputer: SimpleImputer=None, fit_imputer=False):\n",
    "    \"\"\"\n",
    "    Dataset with FIXED column order: suffix names + selected macro column names.\n",
    "    Uses train-median imputation without indicators to keep shape stable.\n",
    "    \"\"\"\n",
    "    feat = features.loc[start:end]\n",
    "    y    = _forward_returns_1d(\n",
    "              returns[etf], horizon=horizon, risk_adj=risk_adj,\n",
    "              vol20=returns[etf].rolling(20).std()\n",
    "           ).loc[start:end]\n",
    "\n",
    "    cols = selected_suffixes + selected_macro_cols\n",
    "    X = pd.DataFrame(index=feat.index, columns=cols, dtype=float)\n",
    "\n",
    "    # Fill from source features\n",
    "    for s in selected_suffixes:\n",
    "        c = f\"{etf}_{s}\"\n",
    "        if c in feat.columns:\n",
    "            X[s] = feat[c].values\n",
    "    for g in selected_macro_cols:\n",
    "        if g in feat.columns:\n",
    "            X[g] = feat[g].values\n",
    "\n",
    "    df = pd.concat([X, y.rename(\"y\")], axis=1)\n",
    "\n",
    "    # Imputer: median (no indicators). Pre-fill all-NaN train columns to avoid fit errors.\n",
    "    if imputer is None:\n",
    "        imputer = SimpleImputer(strategy=\"median\")  # <-- NO add_indicator\n",
    "\n",
    "    if fit_imputer:\n",
    "        X_train = df[cols].copy()\n",
    "        all_nan_cols = [c for c in cols if X_train[c].isna().all()]\n",
    "        for c in all_nan_cols:\n",
    "            X_train[c] = 0.0  # safe fallback seed for median\n",
    "        X_imp = pd.DataFrame(imputer.fit_transform(X_train), index=df.index, columns=cols)\n",
    "    else:\n",
    "        # transform expects same columns in same order as fit\n",
    "        X_imp = pd.DataFrame(imputer.transform(df[cols]), index=df.index, columns=cols)\n",
    "\n",
    "    out = pd.concat([X_imp, df[\"y\"]], axis=1).dropna(subset=[\"y\"])\n",
    "    return out, imputer\n",
    "\n",
    "def daily_cs_rank(x):\n",
    "    return x.rank(pct=True) - 0.5\n",
    "\n",
    "def aggregate_shap_by_cols(shap_df: pd.DataFrame,\n",
    "                           selected_suffixes: list,\n",
    "                           selected_macro_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Emit SHAP_<suffix> for each selected ETF suffix feature,\n",
    "    and SHAP_<macrocol> for each selected macro *column* (e.g., SHAP_SMB_lag_2).\n",
    "    No family-level aggregation is performed here.\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=shap_df.index)\n",
    "\n",
    "    # ETF suffix columns (these are named by suffix in shap_df)\n",
    "    for s in selected_suffixes:\n",
    "        out[f\"SHAP_{s}\"] = shap_df[s] if s in shap_df.columns else 0.0\n",
    "\n",
    "    # Exact macro columns selected by the gate (e.g., \"SMB_lag_2\")\n",
    "    for c in selected_macro_cols:\n",
    "        out[f\"SHAP_{c}\"] = shap_df[c] if c in shap_df.columns else 0.0\n",
    "\n",
    "    # Optional diagnostic total (sum over raw feature columns in shap_df)\n",
    "    out[\"SHAP_Total\"] = shap_df.sum(axis=1) if shap_df.shape[1] else 0.0\n",
    "    return out.fillna(0.0)\n",
    "\n",
    "\n",
    "def build_stable_unified_gate(start_year, train_years, valid_years,\n",
    "                              horizon=1, risk_adj=False,\n",
    "                              top_n=10, min_suffixes=6, max_global_families=4):\n",
    "    # cache: if files exist, reuse\n",
    "    if os.path.exists(\"unified_gate_suffixes.csv\") and os.path.exists(\"unified_gate_macro_cols.csv\"):\n",
    "        suffixes = pd.read_csv(\"unified_gate_suffixes.csv\")[\"SELECTED_SUFFIXES\"].tolist()\n",
    "        macro_cols = pd.read_csv(\"unified_gate_macro_cols.csv\")[\"SELECTED_MACRO_COLS\"].tolist()\n",
    "        macro_fams = []\n",
    "        for fam, cols in MACRO_FAMILY_MAP.items():\n",
    "            if any(c in macro_cols for c in cols):\n",
    "                macro_fams.append(fam)\n",
    "        return suffixes, macro_cols, macro_fams\n",
    "\n",
    "    base_train_start = pd.Timestamp(start_year - train_years, 1, 1)\n",
    "    base_train_end   = pd.Timestamp(start_year - valid_years - 1, 12, 31)\n",
    "\n",
    "    etfs = sorted(list(returns.columns))  # stable order\n",
    "    # group accumulators\n",
    "    group_sum = {s:0.0 for s in ETF_SUFFIX_POOL}\n",
    "    group_cnt = {s:0   for s in ETF_SUFFIX_POOL}\n",
    "    for fam in MACRO_FAMILY_MAP.keys():\n",
    "        group_sum[fam] = 0.0\n",
    "        group_cnt[fam] = 0\n",
    "    macro_col_sum = {c:0.0 for fam in MACRO_FAMILY_MAP.values() for c in fam}\n",
    "    macro_col_cnt = {c:0   for fam in MACRO_FAMILY_MAP.values() for c in fam}\n",
    "\n",
    "    for etf in etfs:\n",
    "        # fixed column order: suffixes (alphabetical by our list), then all macro cols in family order\n",
    "        etf_cols = []\n",
    "        for s in ETF_SUFFIX_POOL:\n",
    "            c = f\"{etf}_{s}\"\n",
    "            if c in features.columns:\n",
    "                etf_cols.append(c)\n",
    "        for fam in MACRO_FAMILY_MAP.keys():\n",
    "            for c in MACRO_FAMILY_MAP[fam]:\n",
    "                if c in features.columns:\n",
    "                    etf_cols.append(c)\n",
    "\n",
    "        Xb = features.loc[base_train_start:base_train_end, etf_cols].copy()\n",
    "        yb = _forward_returns_1d(returns[etf], horizon=horizon, risk_adj=risk_adj).loc[base_train_start:base_train_end]\n",
    "        dfb = pd.concat([Xb, yb.rename(\"y\")], axis=1).dropna()\n",
    "        if dfb.empty:\n",
    "            continue\n",
    "\n",
    "        # enforce fixed column order\n",
    "        cols = [c for c in etf_cols if c in dfb.columns and c != \"y\"]\n",
    "        Xb = dfb[cols].values\n",
    "        yb = dfb[\"y\"].values\n",
    "\n",
    "        model = xgb.XGBRegressor(**GATE_XGB)\n",
    "        model.fit(Xb, yb)\n",
    "        exp = shap.TreeExplainer(model)\n",
    "        sv = exp.shap_values(Xb)\n",
    "        imp = np.abs(sv).mean(axis=0)\n",
    "        col_imp = list(zip(cols, imp))\n",
    "\n",
    "        # suffix groups (each suffix has exactly one column per ETF)\n",
    "        for s in ETF_SUFFIX_POOL:\n",
    "            c = f\"{etf}_{s}\"\n",
    "            if c in cols:\n",
    "                v = imp[cols.index(c)]\n",
    "                group_sum[s] += float(v); group_cnt[s] += 1\n",
    "\n",
    "        # macro families: sum their columns; also track each column\n",
    "        for fam, fam_cols in MACRO_FAMILY_MAP.items():\n",
    "            vals = []\n",
    "            for c in fam_cols:\n",
    "                if c in cols:\n",
    "                    v = imp[cols.index(c)]\n",
    "                    vals.append(v)\n",
    "                    macro_col_sum[c] += float(v)\n",
    "                    macro_col_cnt[c] += 1\n",
    "            if vals:\n",
    "                group_sum[fam] += float(np.sum(vals)); group_cnt[fam] += 1\n",
    "\n",
    "    # average across ETFs\n",
    "    group_avg = {g: (group_sum[g] / max(group_cnt[g],1)) for g in group_sum.keys()}\n",
    "\n",
    "    # stable rankings with tie‑break\n",
    "    suffix_pairs = [(s, group_avg[s]) for s in ETF_SUFFIX_POOL]\n",
    "    macro_pairs  = [(fam, group_avg[fam]) for fam in MACRO_FAMILY_MAP.keys()]\n",
    "\n",
    "    suffix_rank = _stable_sort_pairs(suffix_pairs)\n",
    "    macro_rank  = _stable_sort_pairs(macro_pairs)\n",
    "\n",
    "    chosen_suffixes = [name for name,_ in suffix_rank[:min_suffixes]]\n",
    "    chosen_fams     = [name for name,_ in macro_rank[:max_global_families]]\n",
    "\n",
    "    sel_groups = chosen_suffixes + chosen_fams\n",
    "    for name,_ in (suffix_rank + macro_rank):\n",
    "        if len(sel_groups) >= top_n: break\n",
    "        if name not in sel_groups:\n",
    "            sel_groups.append(name)\n",
    "    sel_groups = sel_groups[:top_n]\n",
    "\n",
    "    # pick the ONE best column per selected macro family (stable tie break)\n",
    "    selected_macro_cols = []\n",
    "    for fam in sel_groups:\n",
    "        if fam in MACRO_FAMILY_MAP:\n",
    "            items = []\n",
    "            for c in MACRO_FAMILY_MAP[fam]:\n",
    "                v = macro_col_sum.get(c, 0.0) / max(macro_col_cnt.get(c, 1), 1)\n",
    "                items.append((c, v))\n",
    "            # stable pick: sort by score desc, then column name asc\n",
    "            c_best = _stable_sort_pairs(items)[0][0]\n",
    "            selected_macro_cols.append(c_best)\n",
    "\n",
    "    selected_suffixes = [g for g in sel_groups if g in ETF_SUFFIX_POOL]\n",
    "    selected_macro_fams = [g for g in sel_groups if g in MACRO_FAMILY_MAP]\n",
    "\n",
    "    # cache to disk\n",
    "    pd.Series(selected_suffixes, name=\"SELECTED_SUFFIXES\").to_csv(\"unified_gate_suffixes.csv\", index=False)\n",
    "    pd.Series(selected_macro_cols, name=\"SELECTED_MACRO_COLS\").to_csv(\"unified_gate_macro_cols.csv\", index=False)\n",
    "\n",
    "    return selected_suffixes, selected_macro_cols, selected_macro_fams\n",
    "\n",
    "# ---- call it (use your window settings) ----\n",
    "SELECTED_SUFFIXES, SELECTED_MACRO_COLS, SELECTED_MACRO_FAMILIES = build_stable_unified_gate(\n",
    "    start_year=start_year,\n",
    "    train_years=train_years,\n",
    "    valid_years=valid_years,\n",
    "    horizon=FWD_H_ETF,\n",
    "    risk_adj=USE_RISK_ADJ_ETF,\n",
    "    top_n=TOP_N_GENERIC,\n",
    "    min_suffixes=MIN_SUFFIXES,\n",
    "    max_global_families=MAX_GLOBAL_FAMILIES,\n",
    ")\n",
    "print(\"Unified gate selected suffixes:\", SELECTED_SUFFIXES)\n",
    "print(\"Unified gate selected macro columns:\", SELECTED_MACRO_COLS)\n",
    "\n",
    "\n",
    "# ---------------- 2) Rolling per-ETF training with fixed selected features ----------------\n",
    "def mean_daily_ic(dates: np.ndarray, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    df = pd.DataFrame({\"Date\": dates, \"y\": y_true, \"p\": y_pred})\n",
    "    vals = []\n",
    "    for dt, g in df.groupby(\"Date\"):\n",
    "        y, p = g[\"y\"].values, g[\"p\"].values\n",
    "        m = np.isfinite(y) & np.isfinite(p)\n",
    "        y, p = y[m], p[m]\n",
    "        if len(y) >= 3 and np.std(y) > 1e-12 and np.std(p) > 1e-12:\n",
    "            ic, _ = spearmanr(y, p)\n",
    "            if np.isfinite(ic): vals.append(ic)\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "all_rows, metrics_rows = [], []\n",
    "year = start_year\n",
    "while year <= end_year - test_years + 1:\n",
    "    print(f\"\\n=== Stage‑1 (Unified‑gate) per‑ETF regression | window {year} ===\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_start = pd.Timestamp(year - train_years, 1, 1)\n",
    "    train_end   = pd.Timestamp(year - valid_years - 1, 12, 31)\n",
    "    valid_start = pd.Timestamp(year - valid_years, 1, 1)\n",
    "    valid_end   = pd.Timestamp(year - 1, 12, 31)\n",
    "    test_start  = pd.Timestamp(year, 1, 1)\n",
    "    test_end    = pd.Timestamp(year + test_years - 1, 12, 31)\n",
    "\n",
    "    for etf in etf_list:\n",
    "        # Build datasets with fixed selected features and train-median imputation\n",
    "        ds_tr, imp = build_ds_from_cols(etf, train_start, train_end, SELECTED_SUFFIXES, SELECTED_MACRO_COLS,\n",
    "                                        horizon=FWD_H_ETF, risk_adj=USE_RISK_ADJ_ETF,\n",
    "                                        imputer=None, fit_imputer=True)\n",
    "        ds_va, _   = build_ds_from_cols(etf, valid_start, valid_end, SELECTED_SUFFIXES, SELECTED_MACRO_COLS,\n",
    "                                        horizon=FWD_H_ETF, risk_adj=USE_RISK_ADJ_ETF,\n",
    "                                        imputer=imp, fit_imputer=False)\n",
    "        ds_te, _   = build_ds_from_cols(etf, test_start,  test_end,  SELECTED_SUFFIXES, SELECTED_MACRO_COLS,\n",
    "                                        horizon=FWD_H_ETF, risk_adj=USE_RISK_ADJ_ETF,\n",
    "                                        imputer=imp, fit_imputer=False)\n",
    "        \n",
    "        purge = int(FWD_H_ETF)\n",
    "        if len(ds_tr) > purge:\n",
    "            ds_tr = ds_tr.iloc[:-purge]\n",
    "        if len(ds_va) > purge:\n",
    "            ds_va = ds_va.iloc[:-purge]\n",
    "            \n",
    "        if ds_tr.empty or ds_va.empty or ds_te.empty:\n",
    "            print(f\"[{etf}][{year}] Insufficient data; skipping.\")\n",
    "            continue\n",
    "\n",
    "        feat_cols = SELECTED_SUFFIXES + SELECTED_MACRO_COLS  # fixed order everywhere\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(ds_tr[feat_cols].values); y_tr = ds_tr[\"y\"].values\n",
    "        X_va = scaler.transform(ds_va[feat_cols].values);     y_va = ds_va[\"y\"].values\n",
    "        X_te = scaler.transform(ds_te[feat_cols].values);     y_te = ds_te[\"y\"].values\n",
    "\n",
    "        # Hyperparam search: maximize validation time-series IC (tie-break RMSE)\n",
    "        best_ic, best_rmse = -np.inf, np.inf\n",
    "        best_model, best_params = None, None\n",
    "        for params in ParameterGrid(REG_PARAM_GRID):\n",
    "            for seed in SEEDS:\n",
    "                dtr = xgb.DMatrix(X_tr, label=y_tr)\n",
    "                dva = xgb.DMatrix(X_va, label=y_va)\n",
    "                xgb_params = {\n",
    "                    \"objective\": \"reg:squarederror\",\n",
    "                    \"tree_method\": XGB_TREE_METHOD,\n",
    "                    \"eval_metric\": \"rmse\",\n",
    "                    \"seed\": int(seed),\n",
    "                    \"sampling_method\": \"uniform\",\n",
    "                    \"max_depth\": int(params[\"max_depth\"]),\n",
    "                    \"eta\": float(params[\"learning_rate\"]),\n",
    "                    \"subsample\": float(params[\"subsample\"]),\n",
    "                    \"colsample_bytree\": float(params[\"colsample_bytree\"]),\n",
    "                    \"min_child_weight\": float(params[\"min_child_weight\"]),\n",
    "                    \"lambda\": float(params[\"reg_lambda\"]),\n",
    "                    \"base_score\": float(np.nanmean(y_tr)),\n",
    "                }\n",
    "                num_boost_round = int(params[\"n_estimators\"])\n",
    "                model = xgb.train(\n",
    "                    xgb_params, dtr,\n",
    "                    num_boost_round=max(200, num_boost_round),\n",
    "                    evals=[(dtr,\"train\"), (dva,\"valid\")],\n",
    "                    early_stopping_rounds=min(100, num_boost_round//3),\n",
    "                    verbose_eval=False\n",
    "                )\n",
    "\n",
    "                p_va = model.predict(dva, iteration_range=(0, (model.best_iteration or 0) + 1))\n",
    "                ic_va = _ts_ic(y_va, p_va)\n",
    "                rmse_va = float(np.sqrt(np.mean((y_va - p_va)**2)))\n",
    "                if (ic_va > best_ic) or (np.isclose(ic_va, best_ic) and rmse_va < best_rmse):\n",
    "                    best_ic, best_rmse = ic_va, rmse_va\n",
    "                    best_model, best_params = model, {\"seed\": seed, **params}\n",
    "\n",
    "        # Test predictions\n",
    "        # dte = xgb.DMatrix(X_te, label=y_te)\n",
    "        # p_te = best_model.predict(dte, iteration_range=(0, (best_model.best_iteration or 0) + 1))\n",
    "\n",
    "        # ---------------- Test prediction with valid t+1 only ----------------\n",
    "        # Next-day realized returns (compute once over the full series)\n",
    "        next_day_actual_series = returns[etf].shift(-1)\n",
    "        \n",
    "        # Restrict the test set to rows that have a valid next-day actual\n",
    "        actual_on_te = next_day_actual_series.reindex(ds_te.index)\n",
    "        valid_mask = actual_on_te.notna().values\n",
    "        if not np.all(valid_mask):\n",
    "            n_drop = int((~valid_mask).sum())\n",
    "            if n_drop > 0:\n",
    "                print(f\"[{etf}][{year}] Dropping {n_drop} test rows with missing Actual_Return (no t+1).\")\n",
    "        \n",
    "        # Filter test arrays BEFORE inference/SHAP so shapes align\n",
    "        X_te_valid = X_te[valid_mask]\n",
    "        y_te_valid = y_te[valid_mask]\n",
    "        dates_valid = ds_te.index[valid_mask]\n",
    "        actual_valid = actual_on_te.loc[dates_valid].values  # guaranteed non-NaN now\n",
    "        \n",
    "        # Predict on valid rows only\n",
    "        dte = xgb.DMatrix(X_te_valid, label=y_te_valid)\n",
    "        p_te = best_model.predict(dte, iteration_range=(0, (best_model.best_iteration or 0) + 1))\n",
    "        \n",
    "        # SHAP on valid rows only (columns = feat_cols in fixed order)\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_vals = explainer.shap_values(X_te_valid)\n",
    "        shap_df   = pd.DataFrame(shap_vals, columns=feat_cols, index=dates_valid)\n",
    "        \n",
    "        # Aggregate SHAP using the exact selected macro columns (not families)\n",
    "        shap_agg = aggregate_shap_by_cols(shap_df, SELECTED_SUFFIXES, SELECTED_MACRO_COLS)\n",
    "        exp_val  = explainer.expected_value\n",
    "        shap_agg[\"SHAP_Base\"] = float(exp_val if np.ndim(exp_val)==0 else exp_val[0])\n",
    "\n",
    "        \n",
    "        # Assemble output rows (no NaNs in Actual_Return)\n",
    "        out = pd.DataFrame({\n",
    "            \"Date\": dates_valid,\n",
    "            \"ETF\": etf,\n",
    "            \"Year\": year,\n",
    "            \"Predicted_Return\": p_te,          # raw regression prediction\n",
    "            \"Actual_Return\": actual_valid      # clean, with valid t+1 only\n",
    "        }).reset_index(drop=True)\n",
    "        \n",
    "        # Append SHAP aggregates\n",
    "        out = pd.concat([out, shap_agg.reset_index(drop=True)], axis=1)\n",
    "        all_rows.append(out)\n",
    "        \n",
    "        if not all_rows:\n",
    "            raise RuntimeError(\"No test rows produced; check data ranges and feature availability.\")\n",
    "\n",
    "        # Compute test metrics on the valid rows only\n",
    "        ic_test   = _ts_ic(y_te_valid, p_te)\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te_valid - p_te)**2)))\n",
    "        metrics_rows.append({\n",
    "            \"ETF\": etf, \"Year\": year,\n",
    "            \"IC_valid\": float(best_ic), \"RMSE_valid\": float(best_rmse),\n",
    "            \"IC_test\": float(ic_test), \"RMSE_test\": float(rmse_test),\n",
    "            \"train_range\": f\"{train_start.date()}..{train_end.date()}\",\n",
    "            \"valid_range\": f\"{valid_start.date()}..{valid_end.date()}\",\n",
    "            \"test_range\":  f\"{test_start.date()}..{test_end.date()}\",\n",
    "            \"selected_suffixes\": \",\".join(SELECTED_SUFFIXES),\n",
    "            \"selected_macro_cols\": \",\".join(SELECTED_MACRO_COLS),\n",
    "        })\n",
    "\n",
    "\n",
    "        # # SHAP on test (columns exactly = feat_cols)\n",
    "        # explainer = shap.TreeExplainer(best_model)\n",
    "        # shap_vals = explainer.shap_values(X_te)   # (n_test, n_features)\n",
    "        # shap_df   = pd.DataFrame(shap_vals, columns=feat_cols, index=ds_te.index)\n",
    "        # # Robust: ensure every expected column exists (fill 0)\n",
    "        # for c in feat_cols:\n",
    "        #     if c not in shap_df.columns:\n",
    "        #         shap_df[c] = 0.0\n",
    "        # shap_df = shap_df[feat_cols]\n",
    "        # \n",
    "        # shap_agg = aggregate_shap_fixed(shap_df, SELECTED_SUFFIXES, SELECTED_MACRO_COLS)\n",
    "        # exp_val  = explainer.expected_value\n",
    "        # shap_agg[\"SHAP_Base\"] = float(exp_val if np.ndim(exp_val)==0 else exp_val[0])\n",
    "        # \n",
    "        # # Assemble output\n",
    "        # out = pd.DataFrame({\n",
    "        #     \"Date\": ds_te.index,\n",
    "        #     \"ETF\": etf,\n",
    "        #     \"Year\": year,\n",
    "        #     \"Predicted_Return\": p_te,  # raw reg prediction\n",
    "        #     \"Actual_Return\": returns.loc[ds_te.index, etf].shift(-1).values\n",
    "        # }).reset_index(drop=True)\n",
    "        # out = pd.concat([out, shap_agg.reset_index(drop=True)], axis=1)\n",
    "        # \n",
    "        # all_rows.append(out)\n",
    "        # \n",
    "        # # Metrics\n",
    "        # ic_test   = _ts_ic(y_te, p_te)\n",
    "        # rmse_test = float(np.sqrt(np.mean((y_te - p_te)**2)))\n",
    "        # metrics_rows.append({\n",
    "        #     \"ETF\": etf, \"Year\": year,\n",
    "        #     \"IC_valid\": float(best_ic), \"RMSE_valid\": float(best_rmse),\n",
    "        #     \"IC_test\": float(ic_test), \"RMSE_test\": float(rmse_test),\n",
    "        #     \"train_range\": f\"{train_start.date()}..{train_end.date()}\",\n",
    "        #     \"valid_range\": f\"{valid_start.date()}..{valid_end.date()}\",\n",
    "        #     \"test_range\":  f\"{test_start.date()}..{test_end.date()}\",\n",
    "        #     \"selected_suffixes\": \",\".join(SELECTED_SUFFIXES),\n",
    "        #     \"selected_macro_cols\": \",\".join(SELECTED_MACRO_COLS),\n",
    "        # })\n",
    "\n",
    "        # Save artifacts per ETF/year\n",
    "        wdir = os.path.join(ART_DIR, etf, f\"year_{year}\")\n",
    "        os.makedirs(wdir, exist_ok=True)\n",
    "        best_model.save_model(os.path.join(wdir, \"xgb_regressor.json\"))\n",
    "        with open(os.path.join(wdir, \"meta.json\"), \"w\") as f:\n",
    "            json.dump({\n",
    "                \"best_params\": best_params,\n",
    "                \"ic_valid\": float(best_ic),\n",
    "                \"rmse_valid\": float(best_rmse),\n",
    "                \"feature_cols\": feat_cols,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"selected_suffixes\": SELECTED_SUFFIXES,\n",
    "                \"selected_macro_cols\": SELECTED_MACRO_COLS\n",
    "            }, f, indent=2)\n",
    "            \n",
    "        import joblib, json, os\n",
    "\n",
    "        # Save the trained model\n",
    "        model_dir = os.path.join(ART_DIR, etf, f\"year_{year}\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        best_model.save_model(os.path.join(model_dir, \"xgb_regressor.json\"))\n",
    "        \n",
    "        # Save scaler and imputer used for this ETF/year\n",
    "        joblib.dump(scaler, os.path.join(model_dir, \"scaler.pkl\"))\n",
    "        joblib.dump(imp, os.path.join(model_dir, \"imputer.pkl\"))\n",
    "        \n",
    "        # Save metadata\n",
    "        meta = {\n",
    "            \"best_params\": best_params,\n",
    "            \"ic_valid\": float(best_ic),\n",
    "            \"rmse_valid\": float(best_rmse),\n",
    "            \"ic_test\": float(ic_test),\n",
    "            \"rmse_test\": float(rmse_test),\n",
    "            \"train_range\": [str(train_start.date()), str(train_end.date())],\n",
    "            \"valid_range\": [str(valid_start.date()), str(valid_end.date())],\n",
    "            \"test_range\":  [str(test_start.date()),  str(test_end.date())],\n",
    "            \"selected_suffixes\": SELECTED_SUFFIXES,\n",
    "            \"selected_macro_cols\": SELECTED_MACRO_COLS,\n",
    "            \"feature_cols_order\": feat_cols\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(model_dir, \"meta.json\"), \"w\") as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(f\"Window {year} done in {time.time()-t0:.2f}s\")\n",
    "    year += retrain_frequency\n",
    "\n",
    "# ---------------- Combine & finalize for Stage‑2 ----------------\n",
    "final = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Cross‑sectional daily rank score in [-0.5, 0.5]\n",
    "final[\"Predicted_Score\"] = final.groupby(\"Date\")[\"Predicted_Return\"].transform(lambda s: s.rank(pct=True) - 0.5)\n",
    "if EMA_SMOOTH_SPAN and EMA_SMOOTH_SPAN > 1:\n",
    "    final.sort_values([\"ETF\",\"Date\"], inplace=True)\n",
    "    final[\"Predicted_Score\"] = (\n",
    "        final.groupby(\"ETF\")[\"Predicted_Score\"]\n",
    "             .apply(lambda s: s.ewm(span=EMA_SMOOTH_SPAN, adjust=False).mean())\n",
    "             .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# REL SHAP for suffixes (demean within date); only for selected suffixes\n",
    "suffix_shap_cols = [f\"SHAP_{s}\" for s in SELECTED_SUFFIXES if f\"SHAP_{s}\" in final.columns]\n",
    "if suffix_shap_cols:\n",
    "    rel = final.groupby(\"Date\")[suffix_shap_cols].transform(lambda x: x.fillna(0.0) - x.fillna(0.0).mean())\n",
    "    rel.columns = [c + \"_REL\" for c in rel.columns]\n",
    "    final = pd.concat([final, rel], axis=1)\n",
    "\n",
    "# Order: macro families (selected only) + suffix SHAPs + base/total + RELs\n",
    "macro_shap_cols = [f\"SHAP_{fam}\" for fam in SELECTED_MACRO_COLS if f\"SHAP_{fam}\" in final.columns]\n",
    "if macro_shap_cols:\n",
    "    rel_macro = final.groupby(\"Date\")[macro_shap_cols].transform(lambda x: x.fillna(0.0) - x.fillna(0.0).mean())\n",
    "    rel_macro.columns = [c + \"_REL\" for c in rel_macro.columns]\n",
    "    final = pd.concat([final, rel_macro], axis=1)\n",
    "\n",
    "suffix_shap_cols = [f\"SHAP_{s}\" for s in SELECTED_SUFFIXES if f\"SHAP_{s}\" in final.columns]\n",
    "base_total_cols = [c for c in [\"SHAP_Base\",\"SHAP_Total\"] if c in final.columns]\n",
    "rel_cols = [c for c in final.columns if c.startswith(\"SHAP_\") and c.endswith(\"_REL\")]\n",
    "\n",
    "col_order = [\"Date\",\"ETF\",\"Year\",\"Actual_Return\",\"Predicted_Return\",\"Predicted_Score\"] \\\n",
    "            + macro_shap_cols + suffix_shap_cols + base_total_cols + rel_cols\n",
    "\n",
    "final = final[col_order].sort_values([\"Date\",\"ETF\"])\n",
    "\n",
    "# Final sanity: ensure no NaNs in Actual_Return\n",
    "dropped = int(final[\"Actual_Return\"].isna().sum())\n",
    "if dropped > 0:\n",
    "    print(f\"[WARN] Found {dropped} NaNs in Actual_Return; dropping those rows.\")\n",
    "    final = final.dropna(subset=[\"Actual_Return\"])\n",
    "\n",
    "final.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n",
    "pd.DataFrame(metrics_rows).to_csv(\"stage1_unified_gate_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Stage‑1 with unified SHAP gate complete. Wrote:\")\n",
    "print(\"  - stage1_predictions_with_shap_10ETFs.csv\")\n",
    "print(\"  - stage1_unified_gate_metrics.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:08.849525Z",
     "start_time": "2025-08-10T03:49:10.424991Z"
    }
   },
   "id": "dc1db3f3f7a8a3d8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:08.865539Z",
     "start_time": "2025-08-10T05:42:08.851526Z"
    }
   },
   "id": "6208a6b79cd00da7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage-2 observations written: stage2_rl_observations_optimized_DIA_ETF.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Build Stage-2 daily observations (same structure)\n",
    "# ================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "stage1_df = pd.read_csv(\"stage1_predictions_with_shap_10ETFs.csv\", parse_dates=[\"Date\"])\n",
    "etfs = sorted(stage1_df[\"ETF\"].unique())\n",
    "\n",
    "# 1) Pivot to daily matrices\n",
    "pred_pivot  = stage1_df.pivot(index=\"Date\", columns=\"ETF\", values=\"Predicted_Return\").sort_index()\n",
    "actual_pivot= stage1_df.pivot(index=\"Date\", columns=\"ETF\", values=\"Actual_Return\").sort_index()\n",
    "\n",
    "# 2) (Optional) standardize scores cross-sectionally per day for stability\n",
    "pred_z = (pred_pivot - pred_pivot.mean(axis=1).values[:,None]) / (pred_pivot.std(axis=1).values[:,None] + 1e-8)\n",
    "\n",
    "# 3) Volatility features from realized returns\n",
    "vol_5 = actual_pivot.rolling(5).std()\n",
    "\n",
    "# 4) Daily frame with required columns\n",
    "dates = pred_pivot.index\n",
    "agg = pd.DataFrame({\"Date\": dates})\n",
    "\n",
    "for etf in etfs:\n",
    "    agg[f\"Predicted_Return_{etf}\"] = pred_z[etf].values       # score (z-scored)\n",
    "    agg[f\"Actual_Return_{etf}\"]    = actual_pivot[etf].values  # next-day realized\n",
    "    agg[f\"Volatility_{etf}\"]       = vol_5[etf].values\n",
    "\n",
    "# 5) SHAP aggregation — average & std across ETFs per feature name\n",
    "#    We detect available SHAP_* columns automatically.\n",
    "shap_cols = [c for c in stage1_df.columns if c.startswith(\"SHAP_\")]\n",
    "if shap_cols:\n",
    "    # Melt to long then aggregate by Date and feature suffix\n",
    "    long_shap = stage1_df[[\"Date\"] + shap_cols].copy()\n",
    "    long_shap = long_shap.melt(id_vars=\"Date\", var_name=\"feat\", value_name=\"shap\")\n",
    "    long_shap[\"suffix\"] = long_shap[\"feat\"].str.replace(\"^SHAP_\", \"\", regex=True)\n",
    "    shap_agg = (long_shap.groupby([\"Date\",\"suffix\"])[\"shap\"]\n",
    "                        .agg([\"mean\",\"std\"])\n",
    "                        .reset_index())\n",
    "    shap_mean = shap_agg.pivot(index=\"Date\", columns=\"suffix\", values=\"mean\")\n",
    "    shap_std  = shap_agg.pivot(index=\"Date\", columns=\"suffix\", values=\"std\")\n",
    "    shap_mean.columns = [f\"Avg_SHAP_{c}\" for c in shap_mean.columns]\n",
    "    shap_std.columns  = [f\"Std_SHAP_{c}\" for c in shap_std.columns]\n",
    "    shap_df = pd.concat([shap_mean, shap_std], axis=1).reindex(dates).ffill()\n",
    "    agg = agg.merge(shap_df.reset_index(), on=\"Date\", how=\"left\")\n",
    "\n",
    "# 6) Cross-sectional context features (as you had)\n",
    "agg[\"CrossSec_Mean_PredRet\"] = pred_z.mean(axis=1).values\n",
    "agg[\"CrossSec_Std_PredRet\"]  = pred_z.std(axis=1).values\n",
    "agg[\"CrossSec_Mean_Volatility\"] = vol_5.mean(axis=1).values\n",
    "\n",
    "# 7) Per-ETF percentile ranks of the daily score\n",
    "ranks = pred_z.rank(axis=1, pct=True)\n",
    "for etf in etfs:\n",
    "    agg[f\"Rank_PredRet_{etf}\"] = ranks[etf].values\n",
    "\n",
    "# 8) Clean NA\n",
    "vol_cols = [f\"Volatility_{e}\" for e in etfs]\n",
    "agg[vol_cols] = agg[vol_cols].ffill()\n",
    "agg.dropna(subset=vol_cols, inplace=True)\n",
    "\n",
    "# 9) Save for Stage-2\n",
    "agg.to_csv(\"stage2_rl_observations_optimized_10ETFs.csv\", index=False)\n",
    "print(\"Stage-2 observations written: stage2_rl_observations_optimized_10ETFs.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T12:37:58.469488Z",
     "start_time": "2025-08-10T12:37:54.249954Z"
    }
   },
   "id": "d5b08e5ba1a0c5d1",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # ================================================\n",
    "# # STAGE 1 — Panel ranker (keeps Stage-2 interface)\n",
    "# # ================================================\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import shap\n",
    "# from sklearn.model_selection import ParameterGrid\n",
    "# from scipy.stats import spearmanr\n",
    "# import time\n",
    "# import joblib\n",
    "# import os, json, hashlib\n",
    "# # -------- Controls --------\n",
    "# FWD_HORIZON = 21          # ≈ one trading month forward\n",
    "# USE_RISK_ADJ = True       # label = fwd_return / vol_20  (stabilizes ranks)\n",
    "# EMA_SMOOTH_SPAN = 0       # smooth predictions per ETF (days); set 0 to disable\n",
    "# SEEDS = [42, 202, 909]    # small bag for stability\n",
    "# \n",
    "# # If you want *strict* determinism, prefer CPU hist. GPU can be slightly non-deterministic.\n",
    "# USE_GPU = False  # set True only if you accept tiny non-determinism\n",
    "# XGB_TREE_METHOD = \"hist\"\n",
    "# XGB_DEVICE = \"cuda\" if USE_GPU else \"cpu\"\n",
    "# \n",
    "# # Make a folder to keep all artifacts\n",
    "# ART_DIR = \"stage1_models\"\n",
    "# os.makedirs(ART_DIR, exist_ok=True)\n",
    "#     \n",
    "# RANK_PARAM_GRID = {\n",
    "#     \"max_depth\": [4, 5],\n",
    "#     \"learning_rate\": [0.05, 0.1],\n",
    "#     \"n_estimators\": [600, 1000],\n",
    "#     \"subsample\": [0.8, 0.9],\n",
    "#     \"colsample_bytree\": [0.7, 0.9],\n",
    "# }\n",
    "# \n",
    "# TOP_N_FEATURES = 10      # total budget (informational)\n",
    "# MIN_SUFFIXES   = 6       # ensure cross-sectional info\n",
    "# MAX_GLOBALS    = 4       # macro families allowed\n",
    "# \n",
    "# ETF_SUFFIXES, GLOBAL_FACTORS, shap_rank_table = run_shap_gate_select_topN(\n",
    "#     features_df=features,\n",
    "#     returns_df=returns,\n",
    "#     etfs=etf_list,\n",
    "#     start_year=start_year,\n",
    "#     train_years=train_years,\n",
    "#     valid_years=valid_years,\n",
    "#     forward_h=FWD_HORIZON,\n",
    "#     use_risk_adj=USE_RISK_ADJ,\n",
    "#     top_n=TOP_N_FEATURES,\n",
    "#     min_suffixes=MIN_SUFFIXES,\n",
    "#     max_globals=MAX_GLOBALS,\n",
    "#     seed=42\n",
    "# )\n",
    "# print(\"Gate chose ETF suffixes:\", ETF_SUFFIXES)\n",
    "# print(\"Gate chose GLOBAL_FACTORS:\", GLOBAL_FACTORS)\n",
    "# shap_rank_table.to_csv(\"gate_shap_ranking_full.csv\")\n",
    "# \n",
    "# # ETF-specific feature suffixes you already engineered\n",
    "# \n",
    "# INCLUDE_VIX = False  # constant within day; not useful for within-day ranking\n",
    "# pd.Series(ETF_SUFFIXES, name=\"ETF_SUFFIXES\").to_csv(\"gate_selected_etf_suffixes.csv\", index=False)\n",
    "# pd.Series(GLOBAL_FACTORS, name=\"GLOBAL_FACTORS\").to_csv(\"gate_selected_global_factors.csv\", index=False)\n",
    "# shap_rank_table.to_csv(\"gate_shap_ranking_full.csv\")\n",
    "# \n",
    "# def quick_hash(df: pd.DataFrame) -> str:\n",
    "#     import hashlib\n",
    "#     import numpy as np\n",
    "# \n",
    "#     m = hashlib.md5()\n",
    "# \n",
    "#     # index\n",
    "#     idx = np.asarray(df.index.values)\n",
    "#     m.update(idx.tobytes())\n",
    "# \n",
    "#     # columns (as strings)\n",
    "#     cols = np.asarray(df.columns.astype(str))\n",
    "#     m.update(cols.tobytes())\n",
    "# \n",
    "#     # values (force stable dtype)\n",
    "#     vals = np.asarray(df.values, dtype=np.float64)\n",
    "#     m.update(vals.tobytes())\n",
    "# \n",
    "#     return m.hexdigest()[:10]\n",
    "# \n",
    "# def save_window_artifacts(year: int,\n",
    "#                           model: xgb.Booster,\n",
    "#                           feat_cols: list,\n",
    "#                           best_params: dict,\n",
    "#                           ic_valid: float,\n",
    "#                           date_ranges: dict,\n",
    "#                           panel_hashes: dict) -> None:\n",
    "#     win_dir = os.path.join(ART_DIR, f\"year_{year}\")\n",
    "#     os.makedirs(win_dir, exist_ok=True)\n",
    "# \n",
    "#     # Native XGB format (portable & stable)\n",
    "#     model.save_model(os.path.join(win_dir, \"xgb_ranker.json\"))\n",
    "# \n",
    "#     # Also save as binary booster if you ever want joblib\n",
    "#     joblib.dump(model, os.path.join(win_dir, \"xgb_ranker.booster\"))\n",
    "# \n",
    "#     meta = {\n",
    "#         \"best_params\": best_params,\n",
    "#         \"ic_valid\": float(ic_valid),\n",
    "#         \"feature_cols\": list(feat_cols),\n",
    "#         \"date_ranges\": date_ranges,\n",
    "#         \"panel_hashes\": panel_hashes,\n",
    "#         \"xgb_tree_method\": XGB_TREE_METHOD,\n",
    "#         \"xgb_device\": XGB_DEVICE,\n",
    "#         \"seeded_bag\": SEEDS,\n",
    "#         \"controls\": {\n",
    "#             \"FWD_HORIZON\": FWD_HORIZON,\n",
    "#             \"USE_RISK_ADJ\": USE_RISK_ADJ,\n",
    "#             \"EMA_SMOOTH_SPAN\": EMA_SMOOTH_SPAN\n",
    "#         }\n",
    "#     }\n",
    "#     with open(os.path.join(win_dir, \"meta.json\"), \"w\") as f:\n",
    "#         json.dump(meta, f, indent=2)\n",
    "# \n",
    "# \n",
    "# def make_forward_returns(daily_ret_df: pd.DataFrame, horizon=21, method=\"compound\"):\n",
    "#     if method == \"compound\":\n",
    "#         cum = (1.0 + daily_ret_df).cumprod()\n",
    "#         return cum.shift(-horizon) / cum - 1.0\n",
    "#     else:\n",
    "#         return daily_ret_df.rolling(horizon).sum().shift(-horizon)\n",
    "# \n",
    "# def build_panel(features_df: pd.DataFrame,\n",
    "#                 returns_df: pd.DataFrame,\n",
    "#                 etfs: list,\n",
    "#                 start: pd.Timestamp,\n",
    "#                 end: pd.Timestamp,\n",
    "#                 forward_h=21,\n",
    "#                 use_risk_adj=True,\n",
    "#                 include_vix=False) -> pd.DataFrame:\n",
    "#     \"\"\"Rows = (Date, ETF).\n",
    "#        Columns: selected ETF-specific generic columns + selected global factors.\n",
    "#        Target y = forward_h return (optionally / vol_20).\n",
    "#     \"\"\"\n",
    "#     feat = features_df.loc[start:end].copy()\n",
    "#     rets = returns_df.loc[start:end].copy()\n",
    "# \n",
    "#     fwd = _make_forward_returns(rets, horizon=forward_h, method=\"compound\")\n",
    "#     vol20 = rets.rolling(20).std()\n",
    "# \n",
    "#     rows = []\n",
    "#     for dt in feat.index:\n",
    "#         if dt not in fwd.index:\n",
    "#             continue\n",
    "#         for etf in etfs:\n",
    "#             row = {\"Date\": dt, \"ETF\": etf}\n",
    "#             # ETF-specific (generic names, pull from per-ETF columns)\n",
    "#             for suf in ETF_SUFFIXES:\n",
    "#                 col = f\"{etf}_{suf}\"\n",
    "#                 if col in feat.columns:\n",
    "#                     row[suf] = feat.at[dt, col]\n",
    "#             # Global macro\n",
    "#             for gf in GLOBAL_FACTORS:\n",
    "#                 if gf in feat.columns:\n",
    "#                     row[gf] = feat.at[dt, gf]\n",
    "#             if include_vix and \"VIX\" in feat.columns:\n",
    "#                 row[\"VIX\"] = feat.at[dt, \"VIX\"]\n",
    "# \n",
    "#             yy = fwd.at[dt, etf] if pd.notna(fwd.at[dt, etf]) else np.nan\n",
    "#             if use_risk_adj:\n",
    "#                 vv = vol20.at[dt, etf]\n",
    "#                 yy = np.nan if (pd.isna(yy) or pd.isna(vv)) else (yy / max(vv, 1e-6))\n",
    "#             row[\"y\"] = yy\n",
    "#             # inside the per-ETF loop in build_panel, before appending row:\n",
    "#             missing = [f\"{etf}_{s}\" for s in ETF_SUFFIXES if f\"{etf}_{s}\" not in feat.columns]\n",
    "#             if missing:\n",
    "#                 raise RuntimeError(f\"Missing ETF-specific columns for {etf}: {missing[:3]} ...\")\n",
    "#             rows.append(row)\n",
    "# \n",
    "#     panel = pd.DataFrame(rows).dropna()\n",
    "#     if panel.empty:\n",
    "#         raise ValueError(\"Panel dataset is empty; check date ranges or gate selection.\")\n",
    "# \n",
    "#     feat_cols = [c for c in panel.columns if c not in [\"Date\",\"ETF\",\"y\"]]\n",
    "#     # Only z-score ETF-specific cols (not global):\n",
    "#     cs_cols = [c for c in feat_cols if c not in GLOBAL_FACTORS and c != \"VIX\"]\n",
    "#     panel[cs_cols] = (\n",
    "#         panel.groupby(\"Date\")[cs_cols]\n",
    "#              .transform(lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-4))\n",
    "#     )\n",
    "# \n",
    "#     # Mild winsorization of ETF-specific cols\n",
    "#     for c in cs_cols:\n",
    "#         q1, q99 = panel[c].quantile([0.01, 0.99])\n",
    "#         panel[c] = panel[c].clip(q1, q99)\n",
    "# \n",
    "#     panel.sort_values([\"Date\",\"ETF\"], inplace=True)\n",
    "#     panel.reset_index(drop=True, inplace=True)\n",
    "#     return panel\n",
    "# \n",
    "# \n",
    "# def groups_from_dates(date_series: pd.Series) -> np.ndarray:\n",
    "#     # XGB ranker groups = items per date\n",
    "#     return date_series.value_counts().sort_index().values.astype(int)\n",
    "# \n",
    "# # --------- Rolling training as REGRESSOR; write daily outputs + SHAP ----------\n",
    "# \n",
    "# from scipy.stats import spearmanr\n",
    "# \n",
    "# # Keep your mean_daily_ic helper\n",
    "# def mean_daily_ic(dates: np.ndarray, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     df = pd.DataFrame({\"Date\": dates, \"y\": y_true, \"p\": y_pred})\n",
    "#     vals = []\n",
    "#     for dt, g in df.groupby(\"Date\"):\n",
    "#         yv = g[\"y\"].values\n",
    "#         pv = g[\"p\"].values\n",
    "#         m = np.isfinite(yv) & np.isfinite(pv)\n",
    "#         yv, pv = yv[m], pv[m]\n",
    "#         if len(yv) >= 3:\n",
    "#             # skip days where either side is constant\n",
    "#             if np.std(yv) < 1e-12 or np.std(pv) < 1e-12:\n",
    "#                 continue\n",
    "#             ic, _ = spearmanr(yv, pv)\n",
    "#             if np.isfinite(ic): vals.append(ic)\n",
    "#     return float(np.mean(vals)) if vals else np.nan\n",
    "# \n",
    "# \n",
    "# # Small param grid for regression (you can tune more later)\n",
    "# REG_PARAM_GRID = {\n",
    "#     \"max_depth\": [4, 5],\n",
    "#     \"learning_rate\": [0.05, 0.1],\n",
    "#     \"n_estimators\": [600, 1000],\n",
    "#     \"subsample\": [0.8, 0.9],\n",
    "#     \"colsample_bytree\": [0.7, 0.9],\n",
    "#     \"min_child_weight\": [1.0],\n",
    "#     \"reg_lambda\": [1.0],\n",
    "# }\n",
    "# \n",
    "# # Map global macro columns into factor families for SHAP aggregation\n",
    "# FACTOR_FAMILY_MAP = {\n",
    "#     \"MKT\": [\"Mkt-RF\", \"Mkt-RF_lag_1\", \"Mkt-RF_lag_2\", \"Mkt-RF_lag_3\"],\n",
    "#     \"SMB\": [\"SMB\", \"SMB_lag_1\", \"SMB_lag_2\", \"SMB_lag_3\"],\n",
    "#     \"HML\": [\"HML\", \"HML_lag_1\", \"HML_lag_2\", \"HML_lag_3\"],\n",
    "#     \"RMW\": [\"RMW\", \"RMW_lag_1\", \"RMW_lag_2\", \"RMW_lag_3\"],\n",
    "#     \"CMA\": [\"CMA\", \"CMA_lag_1\", \"CMA_lag_2\", \"CMA_lag_3\"],\n",
    "#     # If you included VIX in features, this will be aggregated alone\n",
    "#     \"VIX\": [\"VIX\"]\n",
    "# }\n",
    "# \n",
    "# def aggregate_shap_df(shap_df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Return a DataFrame with SHAP_MKT/SMB/... + SHAP_<ETF suffix> columns.\"\"\"\n",
    "#     out = pd.DataFrame(index=shap_df.index)\n",
    "# \n",
    "#     # Macro families (sum across available lag columns)\n",
    "#     for fam, cols in FACTOR_FAMILY_MAP.items():\n",
    "#         use = [c for c in cols if c in shap_df.columns]\n",
    "#         if len(use) > 0:\n",
    "#             out[f\"SHAP_{fam}\"] = shap_df[use].sum(axis=1)\n",
    "# \n",
    "#     # ETF‑specific engineered suffixes (keep them one by one)\n",
    "#     for suf in ETF_SUFFIXES:\n",
    "#         if suf in shap_df.columns:\n",
    "#             out[f\"SHAP_{suf}\"] = shap_df[suf]\n",
    "# \n",
    "#     # Total additivity check helper (optional but nice to have)\n",
    "#     out[\"SHAP_Total\"] = shap_df.sum(axis=1)\n",
    "#     return out\n",
    "# \n",
    "# # ------------- rolling windows -------------\n",
    "# all_predictions = []\n",
    "# metrics_log = []\n",
    "# \n",
    "# year = start_year\n",
    "# while year <= end_year - test_years + 1:\n",
    "#     print(f\"\\n=== Stage‑1 panel REGRESSOR | window starting {year} ===\")\n",
    "#     t0 = time.time()\n",
    "# \n",
    "#     train_start = pd.Timestamp(year - train_years, 1, 1)\n",
    "#     train_end   = pd.Timestamp(year - valid_years - 1, 12, 31)\n",
    "#     valid_start = pd.Timestamp(year - valid_years, 1, 1)\n",
    "#     valid_end   = pd.Timestamp(year - 1, 12, 31)\n",
    "#     test_start  = pd.Timestamp(year, 1, 1)\n",
    "#     test_end    = pd.Timestamp(year + test_years - 1, 12, 31)\n",
    "# \n",
    "#     # Build panels (same as before)\n",
    "#     panel_tr = build_panel(features, returns, etf_list, train_start, train_end,\n",
    "#                            forward_h=FWD_HORIZON, use_risk_adj=USE_RISK_ADJ, include_vix=INCLUDE_VIX)\n",
    "#     panel_va = build_panel(features, returns, etf_list, valid_start, valid_end,\n",
    "#                            forward_h=FWD_HORIZON, use_risk_adj=USE_RISK_ADJ, include_vix=INCLUDE_VIX)\n",
    "#     panel_te = build_panel(features, returns, etf_list, test_start,  test_end,\n",
    "#                            forward_h=FWD_HORIZON, use_risk_adj=USE_RISK_ADJ, include_vix=INCLUDE_VIX)\n",
    "# \n",
    "#     feat_cols = [c for c in panel_tr.columns if c not in [\"Date\",\"ETF\",\"y\"]]\n",
    "# \n",
    "#     X_tr, y_tr = panel_tr[feat_cols].values, panel_tr[\"y\"].values\n",
    "#     X_va, y_va = panel_va[feat_cols].values, panel_va[\"y\"].values\n",
    "#     X_te, y_te = panel_te[feat_cols].values, panel_te[\"y\"].values\n",
    "# \n",
    "#     # ----- model selection: maximize validation IC, tie‑break with RMSE -----\n",
    "#     best_ic, best_rmse = -np.inf, np.inf\n",
    "#     best_model, best_params = None, None\n",
    "# \n",
    "#     for params in ParameterGrid(REG_PARAM_GRID):\n",
    "#         for seed in SEEDS:\n",
    "#             dtr, dva = xgb.DMatrix(X_tr, label=y_tr), xgb.DMatrix(X_va, label=y_va)\n",
    "# \n",
    "#             num_boost_round = int(params[\"n_estimators\"])\n",
    "#             xgb_params = {\n",
    "#                 \"objective\": \"reg:squarederror\",\n",
    "#                 \"tree_method\": XGB_TREE_METHOD,\n",
    "#                 \"eval_metric\": \"rmse\",\n",
    "#                 \"seed\": int(seed),\n",
    "#                 \"sampling_method\": \"uniform\",\n",
    "#                 \"max_depth\": int(params[\"max_depth\"]),\n",
    "#                 \"eta\": float(params[\"learning_rate\"]),\n",
    "#                 \"subsample\": float(params[\"subsample\"]),\n",
    "#                 \"colsample_bytree\": float(params[\"colsample_bytree\"]),\n",
    "#                 \"min_child_weight\": float(params[\"min_child_weight\"]),\n",
    "#                 \"lambda\": float(params.get(\"reg_lambda\", 1.0)),\n",
    "#                 \"base_score\": float(np.nanmean(y_tr)),\n",
    "#             }\n",
    "# \n",
    "#             model = xgb.train(\n",
    "#                 xgb_params,\n",
    "#                 dtr,\n",
    "#                 num_boost_round=max(200, num_boost_round),\n",
    "#                 evals=[(dtr, \"train\"), (dva, \"valid\")],\n",
    "#                 early_stopping_rounds=min(100, num_boost_round // 3),\n",
    "#                 verbose_eval=False\n",
    "#             )\n",
    "# \n",
    "#             # Validation prediction\n",
    "#             p_va = model.predict(dva, iteration_range=(0, (model.best_iteration or 0) + 1))\n",
    "#             ic_va = mean_daily_ic(panel_va[\"Date\"].values, y_va, p_va)\n",
    "#             rmse_va = float(np.sqrt(np.mean((y_va - p_va) ** 2)))\n",
    "# \n",
    "#             better = (ic_va > best_ic) or (np.isclose(ic_va, best_ic) and rmse_va < best_rmse)\n",
    "#             if better:\n",
    "#                 best_ic, best_rmse = ic_va, rmse_va\n",
    "#                 best_model = model\n",
    "#                 best_params = {\n",
    "#                     \"seed\": int(seed),\n",
    "#                     \"n_estimators\": int(num_boost_round),\n",
    "#                     \"max_depth\": int(params[\"max_depth\"]),\n",
    "#                     \"learning_rate\": float(params[\"learning_rate\"]),\n",
    "#                     \"subsample\": float(params[\"subsample\"]),\n",
    "#                     \"colsample_bytree\": float(params[\"colsample_bytree\"]),\n",
    "#                     \"min_child_weight\": float(params[\"min_child_weight\"]),\n",
    "#                     \"reg_lambda\": float(params.get(\"reg_lambda\", 1.0)),\n",
    "#                 }\n",
    "# \n",
    "#     print(f\"Best validation IC = {best_ic:.3f} | RMSE = {best_rmse:.5f} with {best_params}\")\n",
    "# \n",
    "#     # --- Predict on TEST (raw regression + daily ranks) ---\n",
    "#     dte = xgb.DMatrix(X_te)\n",
    "#     p_te = best_model.predict(dte, iteration_range=(0, (best_model.best_iteration or 0) + 1))\n",
    "# \n",
    "#     # Raw predicted forward (risk‑adjusted) return\n",
    "#     test_preds = panel_te[[\"Date\",\"ETF\"]].copy()\n",
    "#     test_preds[\"Predicted_FwdRet\"] = p_te\n",
    "# \n",
    "#     # Cross‑sectional score per date (ranked to [-0.5, 0.5])\n",
    "#     test_preds[\"Predicted_Score\"] = (\n",
    "#         test_preds.groupby(\"Date\")[\"Predicted_FwdRet\"]\n",
    "#                   .transform(lambda s: s.rank(pct=True) - 0.5)\n",
    "#     )\n",
    "# \n",
    "#     # Optional smoothing within ETF (no leakage within test)\n",
    "#     if EMA_SMOOTH_SPAN and EMA_SMOOTH_SPAN > 1:\n",
    "#         test_preds[\"Predicted_Score\"] = (\n",
    "#             test_preds.groupby(\"ETF\")[\"Predicted_Score\"]\n",
    "#                       .apply(lambda s: s.ewm(span=EMA_SMOOTH_SPAN, adjust=False).mean())\n",
    "#                       .reset_index(level=0, drop=True)\n",
    "#         )\n",
    "# \n",
    "#     # --- Compute SHAP on TEST set ---\n",
    "#     # IMPORTANT: SHAP works now because we trained a regression model.\n",
    "#     explainer = shap.TreeExplainer(best_model)\n",
    "#     shap_values_te = explainer.shap_values(X_te)              # (n_test, n_features)\n",
    "#     expected_value = explainer.expected_value                  # scalar for regression\n",
    "#     if np.ndim(expected_value) == 0:\n",
    "#         expected_value = float(expected_value)\n",
    "#         base_vec = np.full(len(panel_te), expected_value, dtype=float)\n",
    "#     else:\n",
    "#         base_vec = np.full(len(panel_te), float(expected_value[0]), dtype=float)\n",
    "# \n",
    "#     shap_df_te = pd.DataFrame(shap_values_te, columns=feat_cols, index=panel_te.index)\n",
    "#     shap_agg_te = aggregate_shap_df(shap_df_te)\n",
    "#     shap_agg_te[\"SHAP_Base\"] = base_vec\n",
    "# \n",
    "#     suf_cols = [f\"SHAP_{s}\" for s in ETF_SUFFIXES if f\"SHAP_{s}\" in shap_agg_te.columns]\n",
    "#     if suf_cols:\n",
    "#         shap_rel = shap_agg_te[suf_cols].copy()\n",
    "#         shap_rel = shap_rel.groupby(panel_te[\"Date\"]).transform(lambda x: x - x.mean())\n",
    "#         shap_rel.columns = [c + \"_REL\" for c in shap_rel.columns]\n",
    "#         shap_agg_te = pd.concat([shap_agg_te, shap_rel], axis=1)\n",
    "#     \n",
    "#     # --- Prepare Stage‑2 schema (+ keep raw regression pred for analysis) ---\n",
    "#     test_out = test_preds[[\"Date\",\"ETF\"]].copy()\n",
    "#     # Keep Stage‑2 compatibility: Predicted_Return = cross‑sectional score;\n",
    "#     # also export the raw regression prediction as Predicted_FwdRet for your diagnostics.\n",
    "#     test_out[\"Predicted_Return\"] = test_preds[\"Predicted_Score\"].values\n",
    "#     test_out[\"Predicted_FwdRet\"] = test_preds[\"Predicted_FwdRet\"].values\n",
    "# \n",
    "#     # Actual next‑day (unchanged)\n",
    "#     next_day_actual = returns.shift(-1)\n",
    "#     test_out[\"Actual_Return\"] = [\n",
    "#         next_day_actual.at[dt, etf] for dt, etf in zip(test_out[\"Date\"], test_out[\"ETF\"])\n",
    "#     ]\n",
    "#     test_out[\"Year\"] = year\n",
    "# \n",
    "#     # Attach SHAP aggregates\n",
    "#     test_out = pd.concat([test_out, shap_agg_te.reset_index(drop=True)], axis=1)\n",
    "# \n",
    "#     all_predictions.append(test_out)\n",
    "# \n",
    "#     # Log window test metrics\n",
    "#     ic_te = mean_daily_ic(panel_te[\"Date\"].values, y_te, p_te)\n",
    "#     rmse_te = float(np.sqrt(np.mean((y_te - p_te) ** 2)))\n",
    "#     metrics_log.append({\n",
    "#         \"Year\": year, \"IC_valid\": float(best_ic), \"RMSE_valid\": float(best_rmse),\n",
    "#         \"IC_test\": float(ic_te), \"RMSE_test\": float(rmse_te),\n",
    "#         \"train_range\": f\"{train_start.date()}..{train_end.date()}\",\n",
    "#         \"valid_range\": f\"{valid_start.date()}..{valid_end.date()}\",\n",
    "#         \"test_range\":  f\"{test_start.date()}..{test_end.date()}\"\n",
    "#     })\n",
    "# \n",
    "#     # Save artifacts (unchanged helper)\n",
    "#     save_window_artifacts(\n",
    "#         year=year,\n",
    "#         model=best_model,\n",
    "#         feat_cols=feat_cols,\n",
    "#         best_params=best_params,\n",
    "#         ic_valid=best_ic,\n",
    "#         date_ranges={\n",
    "#             \"train\": [str(train_start.date()), str(train_end.date())],\n",
    "#             \"valid\": [str(valid_start.date()), str(valid_end.date())],\n",
    "#             \"test\":  [str(test_start.date()),  str(test_end.date())],\n",
    "#         },\n",
    "#         panel_hashes={\n",
    "#             \"train\": quick_hash(panel_tr[feat_cols]),\n",
    "#             \"valid\": quick_hash(panel_va[feat_cols]),\n",
    "#             \"test\":  quick_hash(panel_te[feat_cols]),\n",
    "#         }\n",
    "#     )\n",
    "# \n",
    "#     print(f\"Window processed in {(time.time()-t0):.2f}s | Test IC={ic_te:.3f} RMSE={rmse_te:.5f}\")\n",
    "#     year += retrain_frequency\n",
    "# \n",
    "# # ---- Final save (now includes SHAP_* and the raw regression prediction) ----\n",
    "# final_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "# \n",
    "# # Put SHAP columns at the end\n",
    "# shap_cols = [c for c in final_predictions_df.columns if c.startswith(\"SHAP_\")]\n",
    "# col_order = [\"Date\",\"ETF\",\"Year\",\"Actual_Return\",\"Predicted_Return\",\"Predicted_FwdRet\"] + shap_cols\n",
    "# final_predictions_df = final_predictions_df[col_order]\n",
    "# final_predictions_df.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n",
    "# \n",
    "# pd.DataFrame(metrics_log).to_csv(\"stage1_regression_window_metrics.csv\", index=False)\n",
    "# print(\"Stage 1 (panel regressor) completed and data saved for Stage 2.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:12.480682Z",
     "start_time": "2025-08-10T05:42:12.450609Z"
    }
   },
   "id": "30bc5fedb0764ec8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:12.496694Z",
     "start_time": "2025-08-10T05:42:12.481682Z"
    }
   },
   "id": "4cf624040da84fce",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:12.512698Z",
     "start_time": "2025-08-10T05:42:12.497686Z"
    }
   },
   "id": "82cdf537be43bf41",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:12.528702Z",
     "start_time": "2025-08-10T05:42:12.513690Z"
    }
   },
   "id": "8d08de983f4b7df6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T05:42:12.544705Z",
     "start_time": "2025-08-10T05:42:12.529693Z"
    }
   },
   "id": "dd601dd7d1333f0e",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
