{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "895e7096145459d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "adb5bfdfc9c419d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f0500c59fdc3167",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP for ETF: XLB\n",
      "Computing SHAP for ETF: XLE\n",
      "Computing SHAP for ETF: XLF\n",
      "Computing SHAP for ETF: XLI\n",
      "Computing SHAP for ETF: XLK\n",
      "Computing SHAP for ETF: XLP\n",
      "Computing SHAP for ETF: XLY\n",
      "Computing SHAP for ETF: XLV\n",
      "Computing SHAP for ETF: XLU\n",
      "Top SHAP features: ['RMW_lag_3', 'RMW', 'SMB_lag_2', 'RMW_lag_2', 'LagReturn_3', 'LagReturn_2', 'Volatility_5', 'SMB_lag_1', 'SMB', 'RSI_7']\n",
      "Processing ETF: XLB\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 44.44%, ROC-AUC: 0.4564\n",
      "Elapsed time: 14.1077 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5357\n",
      "Elapsed time: 10.7268 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 52.78%, ROC-AUC: 0.5061\n",
      "Elapsed time: 11.3787 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 50.40%, ROC-AUC: 0.5240\n",
      "Elapsed time: 11.3108 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5123\n",
      "Elapsed time: 11.2812 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 51.98%, ROC-AUC: 0.5327\n",
      "Elapsed time: 11.1530 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 51.98%, ROC-AUC: 0.4843\n",
      "Elapsed time: 10.9965 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 50.00%, ROC-AUC: 0.4962\n",
      "Elapsed time: 10.8564 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 54.58%, ROC-AUC: 0.5283\n",
      "Elapsed time: 10.8370 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 46.22%, ROC-AUC: 0.4640\n",
      "Elapsed time: 11.1797 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 50.40%, ROC-AUC: 0.5405\n",
      "Elapsed time: 10.7753 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 45.45%, ROC-AUC: 0.4473\n",
      "Elapsed time: 11.0989 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 49.21%, ROC-AUC: 0.4872\n",
      "Elapsed time: 11.2101 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 46.22%, ROC-AUC: 0.4689\n",
      "Elapsed time: 11.2657 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 52.80%, ROC-AUC: 0.5361\n",
      "Elapsed time: 11.0997 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 51.74%, ROC-AUC: 0.5252\n",
      "Elapsed time: 11.1066 seconds\n",
      "Processing ETF: XLE\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5191\n",
      "Elapsed time: 11.2297 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 57.54%, ROC-AUC: 0.5874\n",
      "Elapsed time: 11.0625 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 46.03%, ROC-AUC: 0.5082\n",
      "Elapsed time: 11.2001 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 48.80%, ROC-AUC: 0.5265\n",
      "Elapsed time: 11.0673 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 53.97%, ROC-AUC: 0.5529\n",
      "Elapsed time: 11.0830 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 49.60%, ROC-AUC: 0.4813\n",
      "Elapsed time: 10.8431 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 53.97%, ROC-AUC: 0.5480\n",
      "Elapsed time: 11.2543 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 55.56%, ROC-AUC: 0.5370\n",
      "Elapsed time: 11.0160 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 47.81%, ROC-AUC: 0.4681\n",
      "Elapsed time: 10.9137 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 48.61%, ROC-AUC: 0.4677\n",
      "Elapsed time: 11.3099 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 47.22%, ROC-AUC: 0.4997\n",
      "Elapsed time: 10.9602 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 47.43%, ROC-AUC: 0.4676\n",
      "Elapsed time: 10.7989 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 50.00%, ROC-AUC: 0.5290\n",
      "Elapsed time: 10.9875 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 53.39%, ROC-AUC: 0.5214\n",
      "Elapsed time: 10.8516 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 44.80%, ROC-AUC: 0.4427\n",
      "Elapsed time: 10.8718 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 47.39%, ROC-AUC: 0.4622\n",
      "Elapsed time: 11.1870 seconds\n",
      "Processing ETF: XLF\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 51.98%, ROC-AUC: 0.5083\n",
      "Elapsed time: 10.9243 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 48.02%, ROC-AUC: 0.4980\n",
      "Elapsed time: 11.0271 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5347\n",
      "Elapsed time: 11.2017 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 52.80%, ROC-AUC: 0.5190\n",
      "Elapsed time: 10.9319 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 52.78%, ROC-AUC: 0.5706\n",
      "Elapsed time: 11.2989 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 44.05%, ROC-AUC: 0.4862\n",
      "Elapsed time: 11.3300 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 51.19%, ROC-AUC: 0.5527\n",
      "Elapsed time: 10.8001 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 51.98%, ROC-AUC: 0.5318\n",
      "Elapsed time: 11.0097 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 51.00%, ROC-AUC: 0.5142\n",
      "Elapsed time: 10.8044 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 47.01%, ROC-AUC: 0.4720\n",
      "Elapsed time: 11.2319 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 47.22%, ROC-AUC: 0.5006\n",
      "Elapsed time: 11.2401 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 49.80%, ROC-AUC: 0.4728\n",
      "Elapsed time: 11.2097 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 50.40%, ROC-AUC: 0.5130\n",
      "Elapsed time: 11.2324 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 45.42%, ROC-AUC: 0.4994\n",
      "Elapsed time: 11.1003 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 46.80%, ROC-AUC: 0.4652\n",
      "Elapsed time: 11.1606 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 49.13%, ROC-AUC: 0.5414\n",
      "Elapsed time: 11.0880 seconds\n",
      "Processing ETF: XLI\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 55.16%, ROC-AUC: 0.5408\n",
      "Elapsed time: 10.9438 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 48.02%, ROC-AUC: 0.4789\n",
      "Elapsed time: 11.2517 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 51.19%, ROC-AUC: 0.5232\n",
      "Elapsed time: 11.0626 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 44.80%, ROC-AUC: 0.4552\n",
      "Elapsed time: 11.3863 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 51.59%, ROC-AUC: 0.5333\n",
      "Elapsed time: 11.3446 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 50.00%, ROC-AUC: 0.5222\n",
      "Elapsed time: 11.0599 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 53.57%, ROC-AUC: 0.5431\n",
      "Elapsed time: 10.7826 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 48.81%, ROC-AUC: 0.4783\n",
      "Elapsed time: 10.9729 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 48.21%, ROC-AUC: 0.5123\n",
      "Elapsed time: 10.9606 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 48.21%, ROC-AUC: 0.4760\n",
      "Elapsed time: 10.8610 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 55.16%, ROC-AUC: 0.5737\n",
      "Elapsed time: 11.0253 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 43.48%, ROC-AUC: 0.4186\n",
      "Elapsed time: 11.4866 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 46.43%, ROC-AUC: 0.4919\n",
      "Elapsed time: 11.2942 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 44.22%, ROC-AUC: 0.4307\n",
      "Elapsed time: 11.1399 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 53.20%, ROC-AUC: 0.5343\n",
      "Elapsed time: 10.9361 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 45.65%, ROC-AUC: 0.4731\n",
      "Elapsed time: 10.9966 seconds\n",
      "Processing ETF: XLK\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 49.60%, ROC-AUC: 0.5185\n",
      "Elapsed time: 11.2162 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 52.78%, ROC-AUC: 0.4892\n",
      "Elapsed time: 11.1913 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 49.21%, ROC-AUC: 0.4916\n",
      "Elapsed time: 11.2871 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 45.60%, ROC-AUC: 0.4280\n",
      "Elapsed time: 11.1296 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 52.38%, ROC-AUC: 0.5238\n",
      "Elapsed time: 11.0821 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 51.98%, ROC-AUC: 0.4648\n",
      "Elapsed time: 10.9921 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 48.81%, ROC-AUC: 0.4809\n",
      "Elapsed time: 10.8160 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 48.41%, ROC-AUC: 0.4827\n",
      "Elapsed time: 10.7913 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 50.20%, ROC-AUC: 0.5163\n",
      "Elapsed time: 11.0469 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 49.40%, ROC-AUC: 0.4806\n",
      "Elapsed time: 10.9751 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 51.59%, ROC-AUC: 0.5512\n",
      "Elapsed time: 10.7118 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 50.20%, ROC-AUC: 0.4858\n",
      "Elapsed time: 11.0630 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 45.24%, ROC-AUC: 0.4443\n",
      "Elapsed time: 11.1720 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 51.39%, ROC-AUC: 0.4886\n",
      "Elapsed time: 11.1995 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 55.20%, ROC-AUC: 0.5428\n",
      "Elapsed time: 11.0166 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 48.26%, ROC-AUC: 0.4913\n",
      "Elapsed time: 11.2559 seconds\n",
      "Processing ETF: XLP\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 51.19%, ROC-AUC: 0.5577\n",
      "Elapsed time: 11.3902 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 50.79%, ROC-AUC: 0.5194\n",
      "Elapsed time: 11.3729 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 52.78%, ROC-AUC: 0.5152\n",
      "Elapsed time: 11.1145 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 52.00%, ROC-AUC: 0.5311\n",
      "Elapsed time: 11.2256 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5427\n",
      "Elapsed time: 11.1465 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 49.60%, ROC-AUC: 0.4878\n",
      "Elapsed time: 11.1717 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 47.62%, ROC-AUC: 0.4843\n",
      "Elapsed time: 10.9776 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 54.76%, ROC-AUC: 0.5261\n",
      "Elapsed time: 10.8008 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 53.39%, ROC-AUC: 0.5325\n",
      "Elapsed time: 10.8305 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 47.81%, ROC-AUC: 0.4947\n",
      "Elapsed time: 11.2173 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 44.84%, ROC-AUC: 0.4604\n",
      "Elapsed time: 10.7973 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 47.43%, ROC-AUC: 0.4809\n",
      "Elapsed time: 10.7624 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 57.14%, ROC-AUC: 0.5778\n",
      "Elapsed time: 11.1780 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 54.58%, ROC-AUC: 0.5399\n",
      "Elapsed time: 11.2846 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 41.60%, ROC-AUC: 0.4305\n",
      "Elapsed time: 11.1293 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 49.57%, ROC-AUC: 0.4923\n",
      "Elapsed time: 10.8955 seconds\n",
      "Processing ETF: XLY\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 53.97%, ROC-AUC: 0.5342\n",
      "Elapsed time: 11.1007 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 46.43%, ROC-AUC: 0.4838\n",
      "Elapsed time: 11.0835 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 51.59%, ROC-AUC: 0.5270\n",
      "Elapsed time: 11.5322 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 54.00%, ROC-AUC: 0.5343\n",
      "Elapsed time: 11.1897 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 53.57%, ROC-AUC: 0.5428\n",
      "Elapsed time: 10.8516 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 48.81%, ROC-AUC: 0.4999\n",
      "Elapsed time: 10.9768 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 47.22%, ROC-AUC: 0.4734\n",
      "Elapsed time: 10.9551 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 54.37%, ROC-AUC: 0.4938\n",
      "Elapsed time: 11.0856 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 49.80%, ROC-AUC: 0.5135\n",
      "Elapsed time: 11.1294 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 46.61%, ROC-AUC: 0.4828\n",
      "Elapsed time: 10.9143 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 51.59%, ROC-AUC: 0.4929\n",
      "Elapsed time: 11.3549 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 50.20%, ROC-AUC: 0.4997\n",
      "Elapsed time: 10.8826 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 53.57%, ROC-AUC: 0.5320\n",
      "Elapsed time: 10.9700 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 48.61%, ROC-AUC: 0.4939\n",
      "Elapsed time: 10.7898 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 56.80%, ROC-AUC: 0.5201\n",
      "Elapsed time: 11.1403 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 50.87%, ROC-AUC: 0.5231\n",
      "Elapsed time: 11.2329 seconds\n",
      "Processing ETF: XLV\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 58.33%, ROC-AUC: 0.5734\n",
      "Elapsed time: 10.7776 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5418\n",
      "Elapsed time: 10.8283 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 52.78%, ROC-AUC: 0.5277\n",
      "Elapsed time: 10.9572 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 54.40%, ROC-AUC: 0.5578\n",
      "Elapsed time: 11.3594 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 49.21%, ROC-AUC: 0.5449\n",
      "Elapsed time: 10.8984 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5459\n",
      "Elapsed time: 10.7460 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 46.43%, ROC-AUC: 0.4920\n",
      "Elapsed time: 11.0598 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 51.59%, ROC-AUC: 0.5365\n",
      "Elapsed time: 10.9406 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 48.61%, ROC-AUC: 0.4608\n",
      "Elapsed time: 10.8878 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 44.22%, ROC-AUC: 0.4597\n",
      "Elapsed time: 10.8495 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 53.17%, ROC-AUC: 0.5734\n",
      "Elapsed time: 11.1349 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 48.22%, ROC-AUC: 0.4956\n",
      "Elapsed time: 10.8671 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 46.03%, ROC-AUC: 0.4376\n",
      "Elapsed time: 10.7167 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 50.20%, ROC-AUC: 0.5272\n",
      "Elapsed time: 10.7077 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 49.20%, ROC-AUC: 0.4902\n",
      "Elapsed time: 10.8919 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 46.96%, ROC-AUC: 0.5056\n",
      "Elapsed time: 10.9179 seconds\n",
      "Processing ETF: XLU\n",
      "\n",
      "Training window starting year: 2009\n",
      "Accuracy: 46.43%, ROC-AUC: 0.4875\n",
      "Elapsed time: 10.9614 seconds\n",
      "\n",
      "Training window starting year: 2010\n",
      "Accuracy: 50.00%, ROC-AUC: 0.5162\n",
      "Elapsed time: 11.1319 seconds\n",
      "\n",
      "Training window starting year: 2011\n",
      "Accuracy: 42.46%, ROC-AUC: 0.4180\n",
      "Elapsed time: 10.9143 seconds\n",
      "\n",
      "Training window starting year: 2012\n",
      "Accuracy: 55.60%, ROC-AUC: 0.5701\n",
      "Elapsed time: 10.8687 seconds\n",
      "\n",
      "Training window starting year: 2013\n",
      "Accuracy: 52.38%, ROC-AUC: 0.5501\n",
      "Elapsed time: 10.7265 seconds\n",
      "\n",
      "Training window starting year: 2014\n",
      "Accuracy: 55.56%, ROC-AUC: 0.5542\n",
      "Elapsed time: 10.7500 seconds\n",
      "\n",
      "Training window starting year: 2015\n",
      "Accuracy: 58.73%, ROC-AUC: 0.5579\n",
      "Elapsed time: 10.7752 seconds\n",
      "\n",
      "Training window starting year: 2016\n",
      "Accuracy: 46.83%, ROC-AUC: 0.4593\n",
      "Elapsed time: 10.9342 seconds\n",
      "\n",
      "Training window starting year: 2017\n",
      "Accuracy: 51.00%, ROC-AUC: 0.4883\n",
      "Elapsed time: 10.7052 seconds\n",
      "\n",
      "Training window starting year: 2018\n",
      "Accuracy: 50.60%, ROC-AUC: 0.5346\n",
      "Elapsed time: 10.7531 seconds\n",
      "\n",
      "Training window starting year: 2019\n",
      "Accuracy: 55.16%, ROC-AUC: 0.5434\n",
      "Elapsed time: 10.7313 seconds\n",
      "\n",
      "Training window starting year: 2020\n",
      "Accuracy: 45.06%, ROC-AUC: 0.4411\n",
      "Elapsed time: 10.8306 seconds\n",
      "\n",
      "Training window starting year: 2021\n",
      "Accuracy: 52.78%, ROC-AUC: 0.5397\n",
      "Elapsed time: 10.9358 seconds\n",
      "\n",
      "Training window starting year: 2022\n",
      "Accuracy: 52.19%, ROC-AUC: 0.5067\n",
      "Elapsed time: 10.8871 seconds\n",
      "\n",
      "Training window starting year: 2023\n",
      "Accuracy: 50.40%, ROC-AUC: 0.4996\n",
      "Elapsed time: 11.0978 seconds\n",
      "\n",
      "Training window starting year: 2024\n",
      "Accuracy: 44.78%, ROC-AUC: 0.4471\n",
      "Elapsed time: 10.7536 seconds\n",
      "Stage 1 completed and data saved for Stage 2.\n"
     ]
    }
   ],
   "source": [
    "# stage 1 training and prediction \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import ta\n",
    "import joblib\n",
    "import gc\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "# Load data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "factors = pd.read_csv(\"aligned_factors.csv\", index_col=0, parse_dates=True)\n",
    "returns = pd.read_csv(\"daily_returns_10ETFs.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align dates\n",
    "dates = factors.index.intersection(returns.index)\n",
    "factors = factors.loc[dates]\n",
    "returns = returns.loc[dates]\n",
    "\n",
    "# Compute expanded generic technical indicators\n",
    "all_tech_features = []\n",
    "\n",
    "for etf in returns.columns:\n",
    "    close = (1 + returns[etf]).cumprod()\n",
    "    etf_tech_features = pd.DataFrame(index=returns.index)\n",
    "\n",
    "    etf_tech_features[f'{etf}_SMA_5'] = ta.trend.sma_indicator(close, window=5)\n",
    "    # etf_tech_features[f'{etf}_SMA_20'] = ta.trend.sma_indicator(close, window=20)\n",
    "    # etf_tech_features[f'{etf}_SMA_50'] = ta.trend.sma_indicator(close, window=50)\n",
    "    etf_tech_features[f'{etf}_EMA_12'] = ta.trend.ema_indicator(close, window=12)\n",
    "    # etf_tech_features[f'{etf}_EMA_26'] = ta.trend.ema_indicator(close, window=26)\n",
    "    # etf_tech_features[f'{etf}_EMA_50'] = ta.trend.ema_indicator(close, window=50)\n",
    "    etf_tech_features[f'{etf}_RSI_7'] = ta.momentum.rsi(close, window=7)\n",
    "    # etf_tech_features[f'{etf}_RSI_14'] = ta.momentum.rsi(close, window=14)\n",
    "    etf_tech_features[f'{etf}_MACD'] = ta.trend.macd_diff(close)\n",
    "    etf_tech_features[f'{etf}_ATR'] = ta.volatility.average_true_range(high=close*1.01, low=close*0.99, close=close, window=10)\n",
    "    etf_tech_features[f'{etf}_Volatility_5'] = returns[etf].rolling(window=5).std()\n",
    "    # etf_tech_features[f'{etf}_Volatility_20'] = returns[etf].rolling(window=20).std()\n",
    "    # etf_tech_features[f'{etf}_Volatility_50'] = returns[etf].rolling(window=50).std()\n",
    "    etf_tech_features[f'{etf}_Momentum_3'] = returns[etf].rolling(window=3).mean()\n",
    "    # etf_tech_features[f'{etf}_Momentum_10'] = returns[etf].rolling(window=10).mean()\n",
    "    \n",
    "    # Add lagged returns explicitly\n",
    "    for lag in [1, 2, 3]:\n",
    "        etf_tech_features[f'{etf}_LagReturn_{lag}'] = returns[etf].shift(lag)\n",
    "\n",
    "    all_tech_features.append(etf_tech_features)\n",
    "    \n",
    "# Concatenate all ETF technical features at once to prevent DataFrame fragmentation\n",
    "technical_features = pd.concat(all_tech_features, axis=1)\n",
    "\n",
    "for factor in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']:\n",
    "    for lag in [1, 2, 3]:\n",
    "        factors[f'{factor}_lag_{lag}'] = factors[factor].shift(lag)\n",
    "\n",
    "factors = factors.dropna()\n",
    "\n",
    "# Combine original factors with technical indicators\n",
    "features = pd.concat([factors, technical_features], axis=1).dropna()\n",
    "vix = pd.read_csv(\"VIX_History.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align dates explicitly with forward-fill to ensure no intermediate NA\n",
    "vix_aligned = vix['CLOSE'].reindex(features.index).ffill()\n",
    "\n",
    "# Compute VIX daily pct_change explicitly without implicit filling\n",
    "features['VIX'] = vix_aligned.pct_change(fill_method=None).shift(1)\n",
    "\n",
    "# Explicitly fill any remaining leading NA values after pct_change\n",
    "features['VIX'] = features['VIX'].fillna(0)\n",
    "\n",
    "# Binary target: 1 if next-day return > 0, else 0\n",
    "target_binary = (returns.shift(-1) > 0).astype(int).loc[features.index].dropna()\n",
    "\n",
    "features = features.loc[target_binary.index]\n",
    "\n",
    "# Define rolling window parameters\n",
    "train_years = 10         # Length of training data in years\n",
    "valid_years = 2           # Length of validation data in years\n",
    "test_years = 1            # Length of testing/prediction data in years (configurable)\n",
    "retrain_frequency = 1     # Retrain model every N years (configurable)\n",
    "start_year = 2009\n",
    "end_year = 2024\n",
    "\n",
    "# Step 1: Determine top N generic important features using aggregated SHAP\n",
    "all_generic_features = [\n",
    "    'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA',\n",
    "    'Mkt-RF_lag_1', 'Mkt-RF_lag_2', 'Mkt-RF_lag_3',\n",
    "    'SMB_lag_1', 'SMB_lag_2', 'SMB_lag_3',\n",
    "    'HML_lag_1', 'HML_lag_2', 'HML_lag_3',\n",
    "    'RMW_lag_1', 'RMW_lag_2', 'RMW_lag_3',\n",
    "    'CMA_lag_1', 'CMA_lag_2', 'CMA_lag_3',\n",
    "    'SMA_5', 'EMA_12', 'RSI_7', 'MACD',\n",
    "    'Volatility_5', 'Momentum_3',\n",
    "    'LagReturn_1', 'LagReturn_2', 'LagReturn_3', 'VIX'\n",
    "]\n",
    "\n",
    "shap_importances = pd.DataFrame(0.0, index=all_generic_features, columns=['SHAP_Value'])\n",
    "\n",
    "for etf in returns.columns:\n",
    "    print(f\"Computing SHAP for ETF: {etf}\")\n",
    "    train_start = pd.Timestamp(2009 - train_years, 1, 1)\n",
    "    train_end = pd.Timestamp(2009 - valid_years - 1, 12, 31)\n",
    "\n",
    "    etf_features = [\n",
    "        col for col in features.columns\n",
    "        if (etf in col and any(gen_feat in col for gen_feat in ['SMA_5', 'EMA_12', 'RSI_7', 'MACD',\n",
    "                                                                'Volatility_5', 'Momentum_3',\n",
    "                                                                'LagReturn_1', 'LagReturn_2', 'LagReturn_3']))\n",
    "        or col in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA',\n",
    "                   'Mkt-RF_lag_1', 'Mkt-RF_lag_2', 'Mkt-RF_lag_3',\n",
    "                   'SMB_lag_1', 'SMB_lag_2', 'SMB_lag_3',\n",
    "                   'HML_lag_1', 'HML_lag_2', 'HML_lag_3',\n",
    "                   'RMW_lag_1', 'RMW_lag_2', 'RMW_lag_3',\n",
    "                   'CMA_lag_1', 'CMA_lag_2', 'CMA_lag_3']\n",
    "    ]\n",
    "    X_train = features.loc[train_start:train_end, etf_features]\n",
    "    y_train = target_binary[etf].loc[train_start:train_end]\n",
    "\n",
    "    model = xgb.XGBClassifier(tree_method='hist', device='cuda').fit(X_train, y_train)\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_train)\n",
    "\n",
    "    for generic in all_generic_features:\n",
    "        cols = [col for col in X_train.columns if generic in col]\n",
    "        if cols:\n",
    "            idx = [X_train.columns.get_loc(c) for c in cols]\n",
    "            shap_importances.loc[generic] += np.mean(np.abs(shap_values.values[:, idx]))\n",
    "\n",
    "shap_importances /= len(returns.columns)\n",
    "common_generic_features = shap_importances.sort_values('SHAP_Value', ascending=False).head(10).index.tolist()\n",
    "\n",
    "print(\"Top SHAP features:\", common_generic_features)\n",
    "\n",
    "# Step 2: Retrain models using selected top generic important features\n",
    "all_predictions = []\n",
    "for etf in returns.columns:  # Adjust this slice for all ETFs\n",
    "    \n",
    "    print(f\"Processing ETF: {etf}\")\n",
    "    selected_features = [f for f in features.columns if any(generic in f for generic in common_generic_features) or f in factors.columns]\n",
    "\n",
    "    # for year in range(2009, 2010):  # Adjust range for all years\n",
    "    year = start_year\n",
    "    while year <= end_year - test_years + 1:\n",
    "        print(f\"\\nTraining window starting year: {year}\")\n",
    "        start_time = time.time()\n",
    "        train_start = pd.Timestamp(year - train_years, 1, 1)\n",
    "        train_end = pd.Timestamp(year - valid_years - 1, 12, 31)\n",
    "        valid_start = pd.Timestamp(year - valid_years, 1, 1)\n",
    "        valid_end = pd.Timestamp(year - 1, 12, 31)\n",
    "        test_start = pd.Timestamp(year, 1, 1)\n",
    "        test_end = pd.Timestamp(year + test_years - 1, 12, 31)\n",
    "\n",
    "        X_train = features.loc[train_start:train_end, selected_features]\n",
    "        y_train = target_binary[etf].loc[train_start:train_end]\n",
    "\n",
    "        X_valid = features.loc[valid_start:valid_end, selected_features]\n",
    "        y_valid = target_binary[etf].loc[valid_start:valid_end]\n",
    "\n",
    "        X_test = features.loc[test_start:test_end, selected_features]\n",
    "        y_test = target_binary[etf].loc[test_start:test_end]\n",
    "\n",
    "        scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "        \n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            tree_method='hist',\n",
    "            device='cuda',\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 4],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'subsample': [0.8],\n",
    "            'colsample_bytree': [0.8]\n",
    "        }\n",
    "\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            model,\n",
    "            params,\n",
    "            cv=TimeSeriesSplit(3),\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=4\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearch explicitly without early stopping\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        # Retrain explicitly with early stopping using best params\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        \n",
    "        # Parameters explicitly from grid search\n",
    "        best_params = grid.best_params_\n",
    "        \n",
    "        # Extract and remove n_estimators explicitly\n",
    "        num_boost_round = best_params.pop('n_estimators', 200)\n",
    "        \n",
    "        # Update params explicitly for native XGBoost training\n",
    "        best_params.update({\n",
    "            'objective': 'binary:logistic',\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'eval_metric': 'auc',\n",
    "            'max_bin': 128  # explicitly reduces GPU memory usage\n",
    "        })\n",
    "        \n",
    "        evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "        \n",
    "        best_model = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=min(100, num_boost_round),  # explicitly limit rounds\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        gc.collect()\n",
    "        # Explicit predictions\n",
    "        preds_proba = best_model.predict(dtest)\n",
    "        preds = (preds_proba >= 0.5).astype(int)\n",
    "        \n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        roc_auc = roc_auc_score(y_test, preds_proba)\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.2%}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        joblib.dump(best_model, f\"best_model_{etf}_{year}.joblib\")\n",
    "        \n",
    "        # Daily aligned DataFrame (no more -4 adjustment)\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'Date': X_test.index,\n",
    "            'ETF': etf,\n",
    "            'Year': year,\n",
    "            'Actual_Return': returns[etf].loc[X_test.index].values,\n",
    "            'Actual_Direction': y_test.values.flatten(),\n",
    "            'Predicted_Direction': preds,\n",
    "            'Predicted_Prob': preds_proba\n",
    "        })\n",
    "        \n",
    "        # SHAP daily values explicitly aligned\n",
    "        explainer_test = shap.Explainer(best_model)\n",
    "        shap_values_test = explainer_test(X_test)\n",
    "\n",
    "        \n",
    "        shap_df = pd.DataFrame(\n",
    "            shap_values_test.values,\n",
    "            columns=[f'SHAP_{col}' for col in X_test.columns],\n",
    "            index=X_test.index\n",
    "        ).reset_index().rename(columns={'index': 'Date'})\n",
    "        \n",
    "        # Merge explicitly by 'Date'\n",
    "        predictions_df = pd.merge(predictions_df, shap_df, on='Date', how='left')\n",
    "\n",
    "        # Append explicitly for each ETF-year combination\n",
    "        all_predictions.append(predictions_df)\n",
    "        year += retrain_frequency\n",
    "        end_time = time.time()\n",
    "        print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "final_predictions_df = pd.concat(all_predictions).reset_index(drop=True)\n",
    "final_predictions_df.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n",
    "\n",
    "print(\"Stage 1 completed and data saved for Stage 2.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-23T01:09:39.047826Z",
     "start_time": "2025-07-23T00:42:57.414866Z"
    }
   },
   "id": "110622934baf18b4",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_predictions_df.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b78da84c64b4932",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f06710a3ecfb81c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6efb3e1a4faf0b68",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(common_generic_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2eb4c9f8c79bcf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "125b6d6efc751134",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "common_generic_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85336205218912a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load stage 1 data explicitly\n",
    "stage1_df = pd.read_csv(\"stage1_predictions_with_shap_10ETFs.csv\", parse_dates=['Date'])\n",
    "# stage1_df = pd.read_csv(\"stage1_predictions_with_shap.csv\", parse_dates=['Date'])\n",
    "etfs = stage1_df['ETF'].unique()\n",
    "\n",
    "# Initialize DataFrame for daily aggregated data explicitly\n",
    "dates = sorted(stage1_df['Date'].unique())\n",
    "aggregated_data = pd.DataFrame({'Date': dates})\n",
    "\n",
    "# ETF-specific predicted returns, actual returns, and volatility\n",
    "for etf in etfs:\n",
    "    etf_data = stage1_df[stage1_df['ETF'] == etf].set_index('Date').sort_index()\n",
    "\n",
    "    aggregated_data[f'Predicted_Return_{etf}'] = aggregated_data['Date'].map(etf_data['Predicted_Return'])\n",
    "    aggregated_data[f'Actual_Return_{etf}'] = aggregated_data['Date'].map(etf_data['Actual_Return'])\n",
    "\n",
    "    # Explicit rolling 5-day volatility calculation\n",
    "    volatility = etf_data['Actual_Return'].rolling(window=5).std()\n",
    "    aggregated_data[f'Volatility_{etf}'] = aggregated_data['Date'].map(volatility)\n",
    "\n",
    "# Define explicitly generic SHAP features to aggregate across ETFs\n",
    "# generic_shap_features = [\n",
    "#     'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', \n",
    "#     'SMA_5', 'SMA_20', 'SMA_50',\n",
    "#     'EMA_12', 'EMA_26', 'EMA_50',\n",
    "#     'RSI_7', 'RSI_14', 'MACD', 'ATR',\n",
    "#     'Volatility_5', 'Volatility_20', 'Volatility_50',\n",
    "#     'Momentum_3', 'Momentum_10'\n",
    "# ]\n",
    "# generic_shap_features = ['Mkt-RF',\n",
    "#  'Volatility_50',\n",
    "#  'HML',\n",
    "#  'Momentum_3',\n",
    "#  'Volatility_5',\n",
    "#  'Volatility_20',\n",
    "#  'RMW',\n",
    "#  'SMB',\n",
    "#  'CMA',\n",
    "#  'RSI_7']\n",
    "generic_shap_features = [\n",
    "    'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA',\n",
    "    'Mkt-RF_lag_1', 'Mkt-RF_lag_2', 'Mkt-RF_lag_3',\n",
    "    'SMB_lag_1', 'SMB_lag_2', 'SMB_lag_3',\n",
    "    'HML_lag_1', 'HML_lag_2', 'HML_lag_3',\n",
    "    'RMW_lag_1', 'RMW_lag_2', 'RMW_lag_3',\n",
    "    'CMA_lag_1', 'CMA_lag_2', 'CMA_lag_3',\n",
    "    'SMA_5', 'EMA_12', 'RSI_7', 'MACD',\n",
    "    'Volatility_5', 'Momentum_3',\n",
    "    'LagReturn_1', 'LagReturn_2', 'LagReturn_3'\n",
    "]\n",
    "\n",
    "# Aggregate SHAP values explicitly across ETFs by generic feature\n",
    "shap_aggregated = {'Date': dates}\n",
    "shap_df_list = []\n",
    "\n",
    "for feature in generic_shap_features:\n",
    "    # Adjust matching explicitly for 'SHAP_{ETF}_{feature}' format\n",
    "    matching_shap_cols = [col for col in stage1_df.columns if col.startswith('SHAP_') and col.endswith(f'_{feature}')]\n",
    "    \n",
    "    if matching_shap_cols:\n",
    "        # Compute daily mean explicitly across selected SHAP columns\n",
    "        daily_shap_mean = stage1_df.groupby('Date')[matching_shap_cols].mean().mean(axis=1)\n",
    "        shap_df_list.append(daily_shap_mean.rename(f'Avg_SHAP_{feature}'))\n",
    "    else:\n",
    "        print(f\"Warning: No matches found explicitly for feature: {feature}\")\n",
    "\n",
    "# Concatenate aggregated SHAP features explicitly, ensuring alignment\n",
    "shap_aggregated_df = pd.concat(shap_df_list, axis=1).reset_index()\n",
    "\n",
    "# Explicit merge with ETF-specific metrics on Date to ensure alignment\n",
    "aggregated_data = pd.merge(aggregated_data, shap_aggregated_df, on='Date', how='left')\n",
    "\n",
    "# Explicit handling of missing values\n",
    "aggregated_data.sort_values('Date', inplace=True)\n",
    "aggregated_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Remove rows explicitly if initial volatility calculations have NaNs\n",
    "vol_cols = [f'Volatility_{etf}' for etf in etfs]\n",
    "aggregated_data.dropna(subset=vol_cols, inplace=True)\n",
    "\n",
    "# Check if aggregated_data is empty before saving explicitly\n",
    "if aggregated_data.empty:\n",
    "    print(\"Warning: aggregated_data is empty after processing. Please verify input data and alignment explicitly.\")\n",
    "else:\n",
    "    aggregated_data.to_csv(\"stage2_rl_observations_optimized_10ETFs.csv\", index=False)\n",
    "    print(f\"Optimized Stage 2 RL dataset created with shape: {aggregated_data.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "626373434f64d0c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f3f0813e659ead",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# start of stage 2 training\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar', risk_coefficient=0.5, rebalance_period=21, lookback_period=21):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(etf_list),), dtype=np.float32)\n",
    "\n",
    "        # Explicitly select feature columns (excluding Date and returns used only for calculating reward)\n",
    "        self.feature_cols = [col for col in data.columns if col not in ['Date'] and not col.startswith('Actual_Return')]\n",
    "        self.num_features_per_day = len(self.feature_cols)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.num_features_per_day * self.lookback_period,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(etf_list)] * len(etf_list))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(self.etf_list)] * len(self.etf_list))\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        next_step = self.current_step + 1\n",
    "\n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            # v2 long short\n",
    "            desired_long = 1.20  # 120% long exposure explicitly\n",
    "            desired_short = 0.20  # 20% short exposure explicitly\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                # Normal 120/20 explicitly0\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                # Only long explicitly: default realistically to 100% long\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                # Only short explicitly (unrealistic), fallback clearly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                # All zeros explicitly: fallback explicitly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            # Apply explicit clipping\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate explicitly after clipping\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            # Final explicit normalization after clipping\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)  # exactly 100% long\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                # Realistic fallback explicitly: equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "            self.current_weights = final_weights\n",
    "            \n",
    "            # v1 softmax normalization\n",
    "            \n",
    "            # temperature = 0.5  # Explicitly lower for higher concentration (try 0.2 to 0.8)\n",
    "            # scaled_action = action / temperature\n",
    "            # self.current_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "\n",
    "        else:\n",
    "            returns_today = np.array([self.data.loc[self.current_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            self.current_weights *= (1 + returns_today)\n",
    "            self.current_weights /= np.sum(self.current_weights)\n",
    "\n",
    "        if next_step >= len(self.data):\n",
    "            terminated = True\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            returns = np.array([self.data.loc[next_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            portfolio_return = np.dot(self.current_weights, returns)\n",
    "            self.cumulative_wealth *= (1 + portfolio_return)\n",
    "            reward = self.calculate_reward(portfolio_return, returns)\n",
    "            terminated = next_step >= len(self.data) - 1\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "        # def _get_obs(self):\n",
    "        #     obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        #     obs_window = obs_window.drop(columns=['Date']).values.flatten().astype(np.float32)\n",
    "        #     return obs_window\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        obs_window = obs_window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "        return obs_window\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns):\n",
    "        if self.reward_type == 'cumulative_return':\n",
    "            return self.cumulative_wealth - 1.0\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            return np.log(self.cumulative_wealth)\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            return portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100 * alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            return portfolio_return - self.risk_coefficient * cvar\n",
    "        else:\n",
    "            raise ValueError('Invalid reward type')\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_stable_features(df, etf_list):\n",
    "    data = df.copy()\n",
    "\n",
    "    for etf in etf_list:\n",
    "        price_col = f'Price_{etf}'\n",
    "\n",
    "        # Volatility (20-day)\n",
    "        data[f'Volatility_{etf}'] = data[price_col].pct_change().rolling(20).std()\n",
    "\n",
    "        # Momentum indicators (returns over 5, 10, 20 days)\n",
    "        data[f'Momentum_5d_{etf}'] = data[price_col].pct_change(periods=5)\n",
    "        data[f'Momentum_10d_{etf}'] = data[price_col].pct_change(periods=10)\n",
    "        data[f'Momentum_20d_{etf}'] = data[price_col].pct_change(periods=20)\n",
    "\n",
    "        # Moving averages (5-day and 20-day)\n",
    "        data[f'MA_5d_{etf}'] = data[price_col].rolling(5).mean()\n",
    "        data[f'MA_20d_{etf}'] = data[price_col].rolling(20).mean()\n",
    "\n",
    "        # Moving average crossover (5-day MA - 20-day MA)\n",
    "        data[f'MA_Crossover_{etf}'] = data[f'MA_5d_{etf}'] - data[f'MA_20d_{etf}']\n",
    "\n",
    "    # Drop NaN values due to rolling calculations\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def filter_features(df, include_predicted_returns=True, include_shap_metrics=True):\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Explicit patterns to identify columns\n",
    "    predicted_return_pattern = 'Predicted_Return'\n",
    "    shap_metric_pattern = 'SHAP'\n",
    "\n",
    "    # Exclude Predicted Returns explicitly if requested\n",
    "    if not include_predicted_returns:\n",
    "        predicted_cols = [col for col in df_filtered.columns if predicted_return_pattern in col]\n",
    "        df_filtered.drop(columns=predicted_cols, inplace=True)\n",
    "        print(f\"Excluded predicted return columns: {predicted_cols}\")\n",
    "\n",
    "    # Exclude SHAP-related metrics explicitly if requested\n",
    "    if not include_shap_metrics:\n",
    "        shap_cols = [col for col in df_filtered.columns if shap_metric_pattern in col]\n",
    "        df_filtered.drop(columns=shap_cols, inplace=True)\n",
    "        print(f\"Excluded SHAP-related columns: {shap_cols}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# ETFs\n",
    "etf_list = ['XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLY', 'XLV', 'XLU']\n",
    "\n",
    "# etf_list = ['BA',\n",
    "# 'AMGN',\n",
    "# 'DIS',\n",
    "# 'NKE',\n",
    "# 'HON',\n",
    "# 'MMM',\n",
    "# 'CAT',\n",
    "# 'KO',\n",
    "# 'PG',\n",
    "# 'AXP',\n",
    "# 'JPM',\n",
    "# 'MCD',\n",
    "# 'HD',\n",
    "# 'AAPL',\n",
    "# 'CSCO',\n",
    "# 'IBM',\n",
    "# 'MSFT',\n",
    "# 'TRV',\n",
    "# 'UNH',\n",
    "# 'CVX',\n",
    "# 'JNJ',\n",
    "# 'MRK',\n",
    "# 'AMZN',\n",
    "# 'WMT',\n",
    "# 'INTC',\n",
    "# 'VZ']\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-5],\n",
    "    'n_steps': [20, 40],\n",
    "    'batch_size': [5, 10],\n",
    "    'gamma': [0.98, 0.99]\n",
    "}\n",
    "consolidated_file = 'stage2_rl_observations_optimized_DIA_ETF.csv'\n",
    "reward_type = 'mean_cvar'\n",
    "# data = pd.read_csv(consolidated_file, parse_dates=['Date'])\n",
    "# data = data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "data = pd.read_csv('stage2_rl_observations_optimized_DIA_ETF.csv', parse_dates=['Date'])\n",
    "price_data = pd.read_csv('stock_prices_DIA_ETF.csv')\n",
    "# price_data = pd.read_csv('stock_prices_10ETFs.csv')\n",
    "# Convert the Date column in price data, handling the timezone correctly\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], utc=True)\n",
    "price_data['Date'] = price_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Rename price columns explicitly to 'price_{ticker}'\n",
    "price_cols = {col: f'Price_{col}' for col in price_data.columns if col != 'Date'}\n",
    "price_data.rename(columns=price_cols, inplace=True)\n",
    "\n",
    "# Merge datasets on Date\n",
    "merged_data = pd.merge(data, price_data, on='Date', how='inner')\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "# Check if merge was successful\n",
    "if len(merged_data) != len(data):\n",
    "    print(f\"Warning: Data length mismatch after merging (Original: {len(data)}, Merged: {len(merged_data)}).\")\n",
    "else:\n",
    "    print(\"Merged successfully with aligned dates.\")\n",
    "\n",
    "data_with_features_raw = add_stable_features(merged_data, etf_list)\n",
    "data_with_features_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Usage Example clearly for benchmark (only price metrics, no predicted return or SHAP):\n",
    "data_with_features = filter_features(data_with_features_raw, \n",
    "                                 include_predicted_returns=True, \n",
    "                                 include_shap_metrics=True)\n",
    "################### override data to use SHAP only\n",
    "# data_with_features = data\n",
    "################### END override \n",
    "\n",
    "# Define your rolling window lengths clearly:\n",
    "train_window_days = 252 * 7\n",
    "validation_window_days = 252\n",
    "prediction_window_days = 252\n",
    "lookback_period = 21\n",
    "rebalance_period = 21\n",
    "\n",
    "start_indices = range(0, len(data) - (train_window_days + validation_window_days + prediction_window_days), prediction_window_days)\n",
    "all_weights = []\n",
    "model_path = 'ppo_single_train_best_model_DIA_ETF.zip'\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "def validate_and_tune(train_data, val_data, reward_type, rebalance_period=10, lookback_period=10, n_iter=8, timesteps=5000):\n",
    "    best_reward, best_params = -np.inf, None\n",
    "\n",
    "    # Narrow and meaningful parameter distribution\n",
    "    param_dist = {\n",
    "        'learning_rate': [3e-4, 1e-4],\n",
    "        'n_steps': [20, 40],\n",
    "        'batch_size': [10, 20],\n",
    "        'gamma': [0.95, 0.98],\n",
    "        'risk_coefficient': [0.1, 0.5, 1.0] if reward_type in ['mean_var', 'mean_cvar'] else [0.5],\n",
    "    }\n",
    "\n",
    "    sampled_params = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "    for params in sampled_params:\n",
    "        risk_coeff = params.pop('risk_coefficient', 0.5)\n",
    "\n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "        model = PPO('MlpPolicy', env,\n",
    "                    ent_coef=0.01,    # explicitly encourages exploration\n",
    "                    clip_range=0.2,\n",
    "                    **params, verbose=0)\n",
    "        model.learn(total_timesteps=timesteps)\n",
    "\n",
    "        val_env = PortfolioEnv(val_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        obs, _ = val_env.reset()\n",
    "        done, total_reward = False, 0\n",
    "\n",
    "        while not done:\n",
    "            num_samples = 100  # Recommended starting point\n",
    "            action_samples = []\n",
    "        \n",
    "            for _ in range(num_samples):\n",
    "                sampled_action, _ = model.predict(obs, deterministic=False)  # obs directly\n",
    "                action_samples.append(sampled_action)\n",
    "        \n",
    "            action = np.mean(action_samples, axis=0)\n",
    "        \n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_params = {**params, 'risk_coefficient': risk_coeff}\n",
    "\n",
    "    return best_params\n",
    "\n",
    "def scale_data(df, feature_cols, scaler):\n",
    "    scaled_features = scaler.transform(df[feature_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=feature_cols, index=df.index)\n",
    "\n",
    "    # Re-add columns that were not scaled (e.g., Date, Actual_Return_*)\n",
    "    for col in df.columns:\n",
    "        if col not in feature_cols:\n",
    "            scaled_df[col] = df[col].values\n",
    "\n",
    "    # Keep original column order\n",
    "    scaled_df = scaled_df[df.columns]\n",
    "    return scaled_df\n",
    "\n",
    "# Main execution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for idx, start_idx in enumerate(start_indices):\n",
    "    # for start_idx in range(0, 252*2, 252):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Explicit indices for training, validation, and prediction datasets\n",
    "    train_start_idx = start_idx\n",
    "    train_end_idx = train_start_idx + train_window_days\n",
    "\n",
    "    val_start_idx = train_end_idx\n",
    "    val_end_idx = val_start_idx + validation_window_days\n",
    "\n",
    "    pred_start_idx = val_end_idx\n",
    "    pred_end_idx = pred_start_idx + prediction_window_days\n",
    "\n",
    "    # Corresponding dates explicitly\n",
    "    train_start_date = data_with_features.loc[train_start_idx, 'Date']\n",
    "    train_end_date = data_with_features.loc[train_end_idx - 1, 'Date']\n",
    "\n",
    "    val_start_date = data_with_features.loc[val_start_idx, 'Date']\n",
    "    val_end_date = data_with_features.loc[val_end_idx - 1, 'Date']\n",
    "\n",
    "    pred_start_date = data_with_features.loc[pred_start_idx, 'Date']\n",
    "    pred_end_date = data_with_features.loc[pred_end_idx - 1, 'Date']\n",
    "\n",
    "    # Clearly print ranges for clarity\n",
    "    print(f\"Training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "    print(f\"Validation period: {val_start_date.date()} to {val_end_date.date()}\")\n",
    "    print(f\"Prediction period: {pred_start_date.date()} to {pred_end_date.date()}\")\n",
    "\n",
    "    # Explicitly subset data accordingly\n",
    "    train_data = data_with_features.iloc[train_start_idx:train_end_idx].reset_index(drop=True)\n",
    "    val_data = data_with_features.iloc[val_start_idx:val_end_idx].reset_index(drop=True)\n",
    "    pred_data = data_with_features.iloc[pred_start_idx:pred_end_idx].reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [col for col in train_data.columns if col != 'Date' and not col.startswith('Actual_Return')]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_data[feature_cols])\n",
    "\n",
    "    train_data_scaled = scale_data(train_data, feature_cols, scaler)\n",
    "    val_data_scaled = scale_data(val_data, feature_cols, scaler)\n",
    "    pred_data_scaled = scale_data(pred_data, feature_cols, scaler)\n",
    "\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    best_params = validate_and_tune(train_data_scaled, val_data_scaled, reward_type)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    incremental_timesteps = 5000\n",
    "    max_timesteps = 30000\n",
    "    patience = 3\n",
    "    \n",
    "    best_val_reward = -np.inf\n",
    "    no_improve_steps = 0\n",
    "\n",
    "    risk_coeff = best_params.pop('risk_coefficient',0.5)\n",
    "    policy_kwargs = dict(net_arch=[256, 256])\n",
    "\n",
    "    env = make_vec_env(lambda: PortfolioEnv(train_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "    \n",
    "    # Load previous model if exists\n",
    "    if idx > 0 and os.path.exists(model_path):\n",
    "        print(f\"Loading previous model from {model_path}...\")\n",
    "        model = PPO.load(model_path, env=env)\n",
    "        model.set_env(env)\n",
    "    else:\n",
    "        print(\"Initializing new PPO model...\")\n",
    "        model = PPO('MlpPolicy', env,\n",
    "                    policy_kwargs=policy_kwargs,\n",
    "                    ent_coef=0.01,\n",
    "                    clip_range=0.2,\n",
    "                    **best_params, verbose=0)\n",
    "     # always retrain\n",
    "    # model = PPO('MlpPolicy', env,\n",
    "    #             policy_kwargs=policy_kwargs,\n",
    "    #             ent_coef=0.01,    # explicitly encourages exploration\n",
    "    #             clip_range=0.2,\n",
    "    #             **best_params, verbose=0)\n",
    "    # print(\"Starting model training...\")\n",
    "    # model.learn(total_timesteps=20000)\n",
    "    print(\"Starting model training with early stopping...\")\n",
    "\n",
    "    for step in range(0, max_timesteps, incremental_timesteps):\n",
    "        model.learn(total_timesteps=incremental_timesteps)\n",
    "    \n",
    "        # Evaluate on validation environment\n",
    "        val_env = PortfolioEnv(val_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        val_obs, _ = val_env.reset()\n",
    "        val_done = False\n",
    "        val_total_reward = 0.0\n",
    "    \n",
    "        while not val_done:\n",
    "            # val_action, _ = model.predict(val_obs, deterministic=True)\n",
    "            num_samples = 100  # Recommended\n",
    "            value_action_samples = []\n",
    "    \n",
    "            for _ in range(num_samples):\n",
    "                value_sampled_action, _ = model.predict(val_obs, deterministic=False)\n",
    "                value_action_samples.append(value_sampled_action)\n",
    "        \n",
    "            val_action = np.mean(value_action_samples, axis=0)    \n",
    "            \n",
    "            val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "            val_total_reward += val_reward\n",
    "    \n",
    "        print(f\"Step: {step + incremental_timesteps}, Validation Total Reward: {val_total_reward:.4f}\")\n",
    "    \n",
    "        # Early stopping check\n",
    "        if val_total_reward > best_val_reward:\n",
    "            best_val_reward = val_total_reward\n",
    "            no_improve_steps = 0\n",
    "            # model.save(\"best_ppo_model.zip\")\n",
    "            model.save(model_path)\n",
    "            print(f\"Improved validation reward; model saved at step {step + incremental_timesteps}\")\n",
    "        else:\n",
    "            no_improve_steps += 1\n",
    "            print(f\"No improvement ({no_improve_steps}/{patience})\")\n",
    "    \n",
    "            if no_improve_steps >= patience:\n",
    "                print(\"Early stopping explicitly triggered.\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model explicitly\n",
    "    model = PPO.load(model_path)\n",
    "    print(\"Loaded the best PPO model explicitly for prediction.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure historical context explicitly available in prediction\n",
    "    full_data = pd.concat([train_data_scaled, val_data_scaled, pred_data_scaled])\n",
    "    pred_data_with_history = full_data[full_data['Date'] >= (pred_start_date - pd.Timedelta(days=lookback_period))].reset_index(drop=True)\n",
    "\n",
    "    pred_env = PortfolioEnv(pred_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "    # pred_env = PortfolioEnv(pred_data_with_history, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "\n",
    "    obs, info = pred_env.reset()\n",
    "    done = False\n",
    "\n",
    "    action = np.zeros(len(etf_list), dtype=np.float32)\n",
    "\n",
    "    while not done:\n",
    "        if pred_env.current_step >= lookback_period and pred_env.current_step % pred_env.rebalance_period == 0:\n",
    "            # obs_for_agent = pred_data_with_history.drop(columns=['Date']).iloc[pred_env.current_step - lookback_period:pred_env.current_step].values.flatten().astype(np.float32)\n",
    "            # action, _ = model.predict(obs_for_agent, deterministic=True)\n",
    "\n",
    "            # v1 normalize weight\n",
    "            # action, _ = model.predict(obs, deterministic=True)\n",
    "            # use determinstic = FALSE       \n",
    "            # num_samples = 100  # Recommended\n",
    "            # action_samples = []\n",
    "            # for _ in range(num_samples):\n",
    "            #     sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "            #     action_samples.append(sampled_action)\n",
    "            # action = np.mean(action_samples, axis=0)    \n",
    "            # \n",
    "            # temperature = 0.5\n",
    "            # scaled_action = action / temperature\n",
    "            # weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "            # rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "            # all_weights.append([rebalance_date] + weights.tolist())\n",
    "\n",
    "\n",
    "            # v2 long short normalization\n",
    "            # action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # uncomment this for predictopm\n",
    "            num_samples = 100  # Recommended\n",
    "            action_samples = []\n",
    "\n",
    "            for _ in range(num_samples):\n",
    "                sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "                action_samples.append(sampled_action)\n",
    "\n",
    "            action = np.mean(action_samples, axis=0)    \n",
    "\n",
    "            # Explicitly apply your new 120/20 normalization logic (to match environment step)\n",
    "            desired_long = 1.20  # Explicitly 120% long exposure\n",
    "            desired_short = 0.20  # Explicitly 20% short exposure\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate after clipping explicitly\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "\n",
    "            rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "            all_weights.append([rebalance_date] + final_weights.tolist())\n",
    "\n",
    "        obs, _, done, _, _ = pred_env.step(action)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "columns = ['Date'] + etf_list\n",
    "weights_df = pd.DataFrame(all_weights, columns=columns)\n",
    "weights_df.to_csv('ppo_multi_year_weights_DIA_ETF.csv', index=False)\n",
    "print(\"Saved predictions to ppo_multi_year_weights_DIA_ETF.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c770edf2acf6b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "columns = ['Date'] + etf_list\n",
    "weights_df = pd.DataFrame(all_weights, columns=columns)\n",
    "weights_df.to_csv('ppo_multi_year_weights.csv', index=False)\n",
    "print(\"Saved predictions to ppo_multi_year_weights.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6c99175692295b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "############################## This is start to run 25 iterations ##############################\n",
    "########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8acf6abff959b252",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ITERATION - final variable: 128/20 - retrain - 50kx30k sample - mean cvar - determinstic false with 50 - 7 yr train by 21 day test\n",
    "# start of stage 2 training\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar', risk_coefficient=0.5, rebalance_period=21, lookback_period=21):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(etf_list),), dtype=np.float32)\n",
    "\n",
    "        # Explicitly select feature columns (excluding Date and returns used only for calculating reward)\n",
    "        self.feature_cols = [col for col in data.columns if col not in ['Date'] and not col.startswith('Actual_Return')]\n",
    "        self.num_features_per_day = len(self.feature_cols)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.num_features_per_day * self.lookback_period,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(etf_list)] * len(etf_list))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(self.etf_list)] * len(self.etf_list))\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        next_step = self.current_step + 1\n",
    "\n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            # v2 long short\n",
    "            desired_long = 1.20  # 120% long exposure explicitly\n",
    "            desired_short = 0.20  # 20% short exposure explicitly\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                # Normal 120/20 explicitly0\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                # Only long explicitly: default realistically to 100% long\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                # Only short explicitly (unrealistic), fallback clearly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                # All zeros explicitly: fallback explicitly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            # Apply explicit clipping\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate explicitly after clipping\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            # Final explicit normalization after clipping\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)  # exactly 100% long\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                # Realistic fallback explicitly: equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "            self.current_weights = final_weights\n",
    "            \n",
    "            # v1 softmax normalization\n",
    "            # \n",
    "            # temperature = 0.5  # Explicitly lower for higher concentration (try 0.2 to 0.8)\n",
    "            # scaled_action = action / temperature\n",
    "            # self.current_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "\n",
    "        else:\n",
    "            returns_today = np.array([self.data.loc[self.current_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            self.current_weights *= (1 + returns_today)\n",
    "            self.current_weights /= np.sum(self.current_weights)\n",
    "\n",
    "        if next_step >= len(self.data):\n",
    "            terminated = True\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            returns = np.array([self.data.loc[next_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            portfolio_return = np.dot(self.current_weights, returns)\n",
    "            self.cumulative_wealth *= (1 + portfolio_return)\n",
    "            reward = self.calculate_reward(portfolio_return, returns)\n",
    "            terminated = next_step >= len(self.data) - 1\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "        # def _get_obs(self):\n",
    "        #     obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        #     obs_window = obs_window.drop(columns=['Date']).values.flatten().astype(np.float32)\n",
    "        #     return obs_window\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        obs_window = obs_window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "        return obs_window\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns):\n",
    "        if self.reward_type == 'cumulative_return':\n",
    "            return self.cumulative_wealth - 1.0\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            return np.log(self.cumulative_wealth)\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            return portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100 * alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            return portfolio_return - self.risk_coefficient * cvar\n",
    "        else:\n",
    "            raise ValueError('Invalid reward type')\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_stable_features(df, etf_list):\n",
    "    data = df.copy()\n",
    "\n",
    "    for etf in etf_list:\n",
    "        price_col = f'Price_{etf}'\n",
    "\n",
    "        # Volatility (20-day)\n",
    "        data[f'Volatility_{etf}'] = data[price_col].pct_change().rolling(20).std()\n",
    "\n",
    "        # Momentum indicators (returns over 5, 10, 20 days)\n",
    "        data[f'Momentum_5d_{etf}'] = data[price_col].pct_change(periods=5)\n",
    "        data[f'Momentum_10d_{etf}'] = data[price_col].pct_change(periods=10)\n",
    "        data[f'Momentum_20d_{etf}'] = data[price_col].pct_change(periods=20)\n",
    "\n",
    "        # Moving averages (5-day and 20-day)\n",
    "        data[f'MA_5d_{etf}'] = data[price_col].rolling(5).mean()\n",
    "        data[f'MA_20d_{etf}'] = data[price_col].rolling(20).mean()\n",
    "\n",
    "        # Moving average crossover (5-day MA - 20-day MA)\n",
    "        data[f'MA_Crossover_{etf}'] = data[f'MA_5d_{etf}'] - data[f'MA_20d_{etf}']\n",
    "\n",
    "    # Drop NaN values due to rolling calculations\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def filter_features(df, include_predicted_returns=True, include_shap_metrics=True):\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Explicit patterns to identify columns\n",
    "    predicted_return_pattern = 'Predicted_Return'\n",
    "    shap_metric_pattern = 'SHAP'\n",
    "\n",
    "    # Exclude Predicted Returns explicitly if requested\n",
    "    if not include_predicted_returns:\n",
    "        predicted_cols = [col for col in df_filtered.columns if predicted_return_pattern in col]\n",
    "        df_filtered.drop(columns=predicted_cols, inplace=True)\n",
    "        print(f\"Excluded predicted return columns: {predicted_cols}\")\n",
    "\n",
    "    # Exclude SHAP-related metrics explicitly if requested\n",
    "    if not include_shap_metrics:\n",
    "        shap_cols = [col for col in df_filtered.columns if shap_metric_pattern in col]\n",
    "        df_filtered.drop(columns=shap_cols, inplace=True)\n",
    "        print(f\"Excluded SHAP-related columns: {shap_cols}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# ETFs\n",
    "# etf_list = ['XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLY', 'XLV', 'XLU']\n",
    "etf_list = ['BA',\n",
    "'AMGN',\n",
    "'DIS',\n",
    "'NKE',\n",
    "'HON',\n",
    "'MMM',\n",
    "'CAT',\n",
    "'KO',\n",
    "'PG',\n",
    "'AXP',\n",
    "'JPM',\n",
    "'MCD',\n",
    "'HD',\n",
    "'AAPL',\n",
    "'CSCO',\n",
    "'IBM',\n",
    "'MSFT',\n",
    "'TRV',\n",
    "'UNH',\n",
    "'CVX',\n",
    "'JNJ',\n",
    "'MRK',\n",
    "'AMZN',\n",
    "'WMT',\n",
    "'INTC',\n",
    "'VZ']\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-5],\n",
    "    'n_steps': [20, 40],\n",
    "    'batch_size': [5, 10],\n",
    "    'gamma': [0.98, 0.99]\n",
    "}\n",
    "consolidated_file = 'stage2_rl_observations_optimized_DIA_ETF.csv'\n",
    "reward_type = 'mean_cvar'\n",
    "# data = pd.read_csv(consolidated_file, parse_dates=['Date'])\n",
    "# data = data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "data = pd.read_csv('stage2_rl_observations_optimized_DIA_ETF.csv', parse_dates=['Date'])\n",
    "price_data = pd.read_csv('stock_prices_DIA_ETF.csv')\n",
    "\n",
    "# Convert the Date column in price data, handling the timezone correctly\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], utc=True)\n",
    "price_data['Date'] = price_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Rename price columns explicitly to 'price_{ticker}'\n",
    "price_cols = {col: f'Price_{col}' for col in price_data.columns if col != 'Date'}\n",
    "price_data.rename(columns=price_cols, inplace=True)\n",
    "\n",
    "# Merge datasets on Date\n",
    "merged_data = pd.merge(data, price_data, on='Date', how='inner')\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "# Check if merge was successful\n",
    "if len(merged_data) != len(data):\n",
    "    print(f\"Warning: Data length mismatch after merging (Original: {len(data)}, Merged: {len(merged_data)}).\")\n",
    "else:\n",
    "    print(\"Merged successfully with aligned dates.\")\n",
    "\n",
    "data_with_features_raw = add_stable_features(merged_data, etf_list)\n",
    "data_with_features_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Usage Example clearly for benchmark (only price metrics, no predicted return or SHAP):\n",
    "data_with_features = filter_features(data_with_features_raw, \n",
    "                                 include_predicted_returns=True, \n",
    "                                 include_shap_metrics=True)\n",
    "################### override data to use SHAP only\n",
    "# data_with_features = data\n",
    "################### END override \n",
    "\n",
    "# Define your rolling window lengths clearly:\n",
    "train_window_days = 252 * 7\n",
    "validation_window_days = 252\n",
    "prediction_window_days = 252\n",
    "lookback_period = 21\n",
    "rebalance_period = 21\n",
    "\n",
    "start_indices = range(0, len(data) - (train_window_days + validation_window_days + prediction_window_days), prediction_window_days)\n",
    "all_weights = []\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "def validate_and_tune(train_data, val_data, reward_type, rebalance_period=10, lookback_period=10, n_iter=8, timesteps=5000):\n",
    "    best_reward, best_params = -np.inf, None\n",
    "\n",
    "    # Narrow and meaningful parameter distribution\n",
    "    param_dist = {\n",
    "        'learning_rate': [3e-4, 1e-4],\n",
    "        'n_steps': [20, 40],\n",
    "        'batch_size': [10, 20],\n",
    "        'gamma': [0.95, 0.98],\n",
    "        'risk_coefficient': [0.1, 0.5, 1.0] if reward_type in ['mean_var', 'mean_cvar'] else [0.5],\n",
    "    }\n",
    "\n",
    "    sampled_params = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "    for params in sampled_params:\n",
    "        risk_coeff = params.pop('risk_coefficient', 0.5)\n",
    "\n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "        model = PPO('MlpPolicy', env,\n",
    "                    ent_coef=0.01,    # explicitly encourages exploration\n",
    "                    clip_range=0.2,\n",
    "                    **params, verbose=0)\n",
    "        model.learn(total_timesteps=timesteps)\n",
    "\n",
    "        val_env = PortfolioEnv(val_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        obs, _ = val_env.reset()\n",
    "        done, total_reward = False, 0\n",
    "        \n",
    "        # while not done:\n",
    "        #     action, _ = model.predict(obs, deterministic=True)\n",
    "        #     obs, reward, done, _, _ = val_env.step(action)\n",
    "        #     total_reward += reward\n",
    "        \n",
    "        while not done:\n",
    "            num_samples = 100  # Recommended starting point\n",
    "            action_samples = []\n",
    "        \n",
    "            for _ in range(num_samples):\n",
    "                sampled_action, _ = model.predict(obs, deterministic=False)  # obs directly\n",
    "                action_samples.append(sampled_action)\n",
    "        \n",
    "            action = np.mean(action_samples, axis=0)\n",
    "        \n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_params = {**params, 'risk_coefficient': risk_coeff}\n",
    "\n",
    "    return best_params\n",
    "\n",
    "def scale_data(df, feature_cols, scaler):\n",
    "    scaled_features = scaler.transform(df[feature_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=feature_cols, index=df.index)\n",
    "\n",
    "    # Re-add columns that were not scaled (e.g., Date, Actual_Return_*)\n",
    "    for col in df.columns:\n",
    "        if col not in feature_cols:\n",
    "            scaled_df[col] = df[col].values\n",
    "\n",
    "    # Keep original column order\n",
    "    scaled_df = scaled_df[df.columns]\n",
    "    return scaled_df\n",
    "\n",
    "# Main execution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "iterations = 10\n",
    "all_weights_iterations = []\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    print(f\"\\n==== Starting Iteration {iteration + 1}/{iterations} ====\")\n",
    "    model_path = f\"ppo_train_best_model_iteration_{iteration}.zip\"\n",
    "    for idx, start_idx in enumerate(start_indices):\n",
    "        # for start_idx in range(0, 252*2, 252):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        # Explicit indices for training, validation, and prediction datasets\n",
    "        train_start_idx = start_idx\n",
    "        train_end_idx = train_start_idx + train_window_days\n",
    "    \n",
    "        val_start_idx = train_end_idx\n",
    "        val_end_idx = val_start_idx + validation_window_days\n",
    "    \n",
    "        pred_start_idx = val_end_idx\n",
    "        pred_end_idx = pred_start_idx + prediction_window_days\n",
    "    \n",
    "        # Corresponding dates explicitly\n",
    "        train_start_date = data_with_features.loc[train_start_idx, 'Date']\n",
    "        train_end_date = data_with_features.loc[train_end_idx - 1, 'Date']\n",
    "    \n",
    "        val_start_date = data_with_features.loc[val_start_idx, 'Date']\n",
    "        val_end_date = data_with_features.loc[val_end_idx - 1, 'Date']\n",
    "    \n",
    "        pred_start_date = data_with_features.loc[pred_start_idx, 'Date']\n",
    "        pred_end_date = data_with_features.loc[pred_end_idx - 1, 'Date']\n",
    "    \n",
    "        # Clearly print ranges for clarity\n",
    "        print(f\"Training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "        print(f\"Validation period: {val_start_date.date()} to {val_end_date.date()}\")\n",
    "        print(f\"Prediction period: {pred_start_date.date()} to {pred_end_date.date()}\")\n",
    "    \n",
    "        # Explicitly subset data accordingly\n",
    "        train_data = data_with_features.iloc[train_start_idx:train_end_idx].reset_index(drop=True)\n",
    "        val_data = data_with_features.iloc[val_start_idx:val_end_idx].reset_index(drop=True)\n",
    "        pred_data = data_with_features.iloc[pred_start_idx:pred_end_idx].reset_index(drop=True)\n",
    "    \n",
    "        feature_cols = [col for col in train_data.columns if col != 'Date' and not col.startswith('Actual_Return')]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data[feature_cols])\n",
    "    \n",
    "        train_data_scaled = scale_data(train_data, feature_cols, scaler)\n",
    "        val_data_scaled = scale_data(val_data, feature_cols, scaler)\n",
    "        pred_data_scaled = scale_data(pred_data, feature_cols, scaler)\n",
    "    \n",
    "        print(\"Starting hyperparameter tuning...\")\n",
    "        best_params = validate_and_tune(train_data_scaled, val_data_scaled, reward_type)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "        incremental_timesteps = 5000\n",
    "        max_timesteps = 30000\n",
    "        patience = 3\n",
    "        \n",
    "        best_val_reward = -np.inf\n",
    "        no_improve_steps = 0\n",
    "    \n",
    "        risk_coeff = best_params.pop('risk_coefficient',0.5)\n",
    "        policy_kwargs = dict(net_arch=[256, 256])\n",
    "    \n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "        \n",
    "        # Load previous model if exists\n",
    "        if idx > 0 and os.path.exists(model_path):\n",
    "            print(f\"Loading previous model from {model_path}...\")\n",
    "            model = PPO.load(model_path, env=env)\n",
    "            model.set_env(env)\n",
    "        else:\n",
    "            print(\"Initializing new PPO model...\")\n",
    "            model = PPO('MlpPolicy', env,\n",
    "                        policy_kwargs=policy_kwargs,\n",
    "                        ent_coef=0.01,\n",
    "                        clip_range=0.2,\n",
    "                        **best_params, verbose=0)\n",
    "         # always retrain\n",
    "        # model = PPO('MlpPolicy', env,\n",
    "        #             policy_kwargs=policy_kwargs,\n",
    "        #             ent_coef=0.01,    # explicitly encourages exploration\n",
    "        #             clip_range=0.2,\n",
    "        #             **best_params, verbose=0)\n",
    "        # print(\"Starting model training...\")\n",
    "        # model.learn(total_timesteps=20000)\n",
    "        print(\"Starting model training with early stopping...\")\n",
    "        \n",
    "        # model = PPO('MlpPolicy', env,\n",
    "        #             policy_kwargs=policy_kwargs,\n",
    "        #             ent_coef=0.01,    # explicitly encourages exploration\n",
    "        #             clip_range=0.2,\n",
    "        #             **best_params, verbose=0)\n",
    "        # print(\"Starting model training...\")\n",
    "        # model.learn(total_timesteps=20000)\n",
    "    \n",
    "        for step in range(0, max_timesteps, incremental_timesteps):\n",
    "            model.learn(total_timesteps=incremental_timesteps)\n",
    "        \n",
    "            # Evaluate on validation environment\n",
    "            val_env = PortfolioEnv(val_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "            val_obs, _ = val_env.reset()\n",
    "            val_done = False\n",
    "            val_total_reward = 0.0\n",
    "        \n",
    "            while not val_done:\n",
    "                # val_action, _ = model.predict(val_obs, deterministic=True)\n",
    "                # val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "                # val_total_reward += val_reward\n",
    "                \n",
    "                num_samples = 100  # Recommended\n",
    "                value_action_samples = []\n",
    "        \n",
    "                for _ in range(num_samples):\n",
    "                    value_sampled_action, _ = model.predict(val_obs, deterministic=False)\n",
    "                    value_action_samples.append(value_sampled_action)\n",
    "            \n",
    "                val_action = np.mean(value_action_samples, axis=0)    \n",
    "                \n",
    "                val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "                val_total_reward += val_reward\n",
    "        \n",
    "            print(f\"Step: {step + incremental_timesteps}, Validation Total Reward: {val_total_reward:.4f}\")\n",
    "        \n",
    "            # Early stopping check\n",
    "            if val_total_reward > best_val_reward:\n",
    "                best_val_reward = val_total_reward\n",
    "                no_improve_steps = 0\n",
    "                # model.save(\"best_ppo_model.zip\")\n",
    "                model.save(model_path)\n",
    "                print(f\"Improved validation reward; model saved at step {step + incremental_timesteps}\")\n",
    "            else:\n",
    "                no_improve_steps += 1\n",
    "                print(f\"No improvement ({no_improve_steps}/{patience})\")\n",
    "        \n",
    "                if no_improve_steps >= patience:\n",
    "                    print(\"Early stopping explicitly triggered.\")\n",
    "                    break\n",
    "        \n",
    "        # Load the best model explicitly\n",
    "        # model = PPO.load(\"best_ppo_model.zip\")\n",
    "        model = PPO.load(model_path)\n",
    "        \n",
    "        print(\"Loaded the best PPO model explicitly for prediction.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Ensure historical context explicitly available in prediction\n",
    "        full_data = pd.concat([train_data_scaled, val_data_scaled, pred_data_scaled])\n",
    "        pred_data_with_history = full_data[full_data['Date'] >= (pred_start_date - pd.Timedelta(days=lookback_period))].reset_index(drop=True)\n",
    "    \n",
    "        pred_env = PortfolioEnv(pred_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        # pred_env = PortfolioEnv(pred_data_with_history, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "    \n",
    "        obs, info = pred_env.reset()\n",
    "        done = False\n",
    "    \n",
    "        action = np.zeros(len(etf_list), dtype=np.float32)\n",
    "    \n",
    "        while not done:\n",
    "            if pred_env.current_step >= lookback_period and pred_env.current_step % pred_env.rebalance_period == 0:\n",
    "                # obs_for_agent = pred_data_with_history.drop(columns=['Date']).iloc[pred_env.current_step - lookback_period:pred_env.current_step].values.flatten().astype(np.float32)\n",
    "                # action, _ = model.predict(obs_for_agent, deterministic=True)\n",
    "    \n",
    "                # v1 normalize weight\n",
    "                # action, _ = model.predict(obs, deterministic=True)\n",
    "                \n",
    "                # num_samples = 100  # Recommended\n",
    "                # action_samples = []\n",
    "                # \n",
    "                # for _ in range(num_samples):\n",
    "                #     sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "                #     action_samples.append(sampled_action)\n",
    "                # \n",
    "                # action = np.mean(action_samples, axis=0)    \n",
    "                # \n",
    "                # temperature = 0.5\n",
    "                # scaled_action = action / temperature\n",
    "                # final_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "                # rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "                # # all_weights.append([rebalance_date] + weights.tolist())\n",
    "                # all_weights_iterations.append([iteration + 1, rebalance_date] + final_weights.tolist())\n",
    "    \n",
    "                # v2 long short normalization\n",
    "                # action, _ = model.predict(obs, deterministic=True)\n",
    "                \n",
    "                num_samples = 100  # Recommended\n",
    "                action_samples = []\n",
    "\n",
    "                for _ in range(num_samples):\n",
    "                    sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "                    action_samples.append(sampled_action)\n",
    "\n",
    "                action = np.mean(action_samples, axis=0)    \n",
    "\n",
    "                # Explicitly apply your new 120/20 normalization logic (to match environment step)\n",
    "                desired_long = 1.20  # Explicitly 120% long exposure\n",
    "                desired_short = 0.20  # Explicitly 20% short exposure\n",
    "                clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "                raw_weights = action.copy()\n",
    "\n",
    "                # Separate explicitly positive (long) and negative (short) actions\n",
    "                long_weights = np.maximum(raw_weights, 0)\n",
    "                short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "                has_longs = np.sum(long_weights) > 0\n",
    "                has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "                if has_longs and has_shorts:\n",
    "                    normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                    normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "                elif has_longs and not has_shorts:\n",
    "                    normalized_long = long_weights / np.sum(long_weights)\n",
    "                    normalized_short = np.zeros_like(short_weights)\n",
    "                elif not has_longs and has_shorts:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    normalized_long = np.ones(num_assets) / num_assets\n",
    "                    normalized_short = np.zeros(num_assets)\n",
    "                else:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    normalized_long = np.ones(num_assets) / num_assets\n",
    "                    normalized_short = np.zeros(num_assets)\n",
    "\n",
    "                combined_weights = normalized_long - normalized_short\n",
    "                clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "                # Re-separate after clipping explicitly\n",
    "                long_clipped = np.maximum(clipped_weights, 0)\n",
    "                short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "                has_long_clipped = np.sum(long_clipped) > 0\n",
    "                has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "                if has_long_clipped and has_short_clipped:\n",
    "                    final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                    final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "                elif has_long_clipped and not has_short_clipped:\n",
    "                    final_long = long_clipped / np.sum(long_clipped)\n",
    "                    final_short = np.zeros_like(short_clipped)\n",
    "                else:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    final_long = np.ones(num_assets) / num_assets\n",
    "                    final_short = np.zeros(num_assets)\n",
    "\n",
    "                final_weights = final_long - final_short\n",
    "\n",
    "                rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "                # all_weights.append([rebalance_date] + final_weights.tolist())\n",
    "                all_weights_iterations.append([iteration + 1, rebalance_date] + final_weights.tolist())\n",
    "                # \n",
    "            obs, _, done, _, _ = pred_env.step(action)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        print(f\"Iteration {iteration + 1}, start index {start_idx} completed in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "columns = ['Iteration', 'Date'] + etf_list\n",
    "weights_df = pd.DataFrame(all_weights_iterations, columns=columns)\n",
    "weights_df.to_csv('ppo_allocations_multiple_iterations_DIA_ETF.csv', index=False)\n",
    "print(\"Saved all iterations' allocations to ppo_allocations_multiple_iterations_DIA_ETF.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d1a98b60121652",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6947d247eaecd896",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
