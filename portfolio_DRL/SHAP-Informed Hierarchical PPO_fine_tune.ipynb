{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "895e7096145459d4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP importances for ETF: XLB\n",
      "Computing SHAP importances for ETF: XLE\n",
      "Computing SHAP importances for ETF: XLF\n",
      "Computing SHAP importances for ETF: XLI\n",
      "Computing SHAP importances for ETF: XLK\n",
      "Computing SHAP importances for ETF: XLP\n",
      "Computing SHAP importances for ETF: XLY\n",
      "Computing SHAP importances for ETF: XLV\n",
      "Computing SHAP importances for ETF: XLU\n",
      "\n",
      "==== Training models for ETF: XLB ====\n",
      "Selected features for XLB: ['XLB_Vol_5', 'SMB_lag_2', 'XLB_Mom_3', 'HML_lag_2', 'XLB_SMA_5', 'XLB_LagRet_1', 'XLB_EMA_12', 'SMB', 'XLB_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000449  RMSE: 0.021187  MAE: 0.016501  R²: -0.000434  DirAcc: 48.41%\n",
      "Window processed in 36.46 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000252  RMSE: 0.015883  MAE: 0.011830  R²: -0.032893  DirAcc: 54.76%\n",
      "Window processed in 39.99 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000385  RMSE: 0.019619  MAE: 0.014535  R²: -0.008845  DirAcc: 48.02%\n",
      "Window processed in 40.19 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000123  RMSE: 0.011109  MAE: 0.008490  R²: 0.000697  DirAcc: 48.80%\n",
      "Window processed in 40.06 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000081  RMSE: 0.008978  MAE: 0.007004  R²: -0.001313  DirAcc: 55.56%\n",
      "Window processed in 41.69 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000081  RMSE: 0.009014  MAE: 0.006792  R²: -0.043465  DirAcc: 45.63%\n",
      "Window processed in 49.61 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000139  RMSE: 0.011802  MAE: 0.008952  R²: -0.008489  DirAcc: 47.22%\n",
      "Window processed in 41.39 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000125  RMSE: 0.011189  MAE: 0.008336  R²: -0.002765  DirAcc: 56.75%\n",
      "Window processed in 41.23 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000044  RMSE: 0.006654  MAE: 0.004964  R²: -0.017093  DirAcc: 56.18%\n",
      "Window processed in 39.62 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000146  RMSE: 0.012093  MAE: 0.009367  R²: -0.007683  DirAcc: 48.21%\n",
      "Window processed in 36.60 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000099  RMSE: 0.009942  MAE: 0.007581  R²: -0.006573  DirAcc: 53.97%\n",
      "Window processed in 39.01 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000609  RMSE: 0.024676  MAE: 0.016321  R²: -0.041224  DirAcc: 53.75%\n",
      "Window processed in 40.98 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000117  RMSE: 0.010810  MAE: 0.008547  R²: -0.005637  DirAcc: 55.16%\n",
      "Window processed in 39.03 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000255  RMSE: 0.015983  MAE: 0.012687  R²: -0.016848  DirAcc: 47.81%\n",
      "Window processed in 39.82 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000112  RMSE: 0.010581  MAE: 0.008372  R²: 0.004224  DirAcc: 54.40%\n",
      "Window processed in 35.20 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000071  RMSE: 0.008443  MAE: 0.006617  R²: -0.003432  DirAcc: 49.34%\n",
      "Window processed in 37.49 seconds\n",
      "\n",
      "==== Training models for ETF: XLE ====\n",
      "Selected features for XLE: ['XLE_Vol_5', 'SMB_lag_2', 'XLE_Mom_3', 'HML_lag_2', 'XLE_SMA_5', 'XLE_LagRet_1', 'XLE_EMA_12', 'SMB', 'XLE_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000503  RMSE: 0.022428  MAE: 0.016940  R²: -0.034818  DirAcc: 48.81%\n",
      "Window processed in 39.84 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000214  RMSE: 0.014642  MAE: 0.010619  R²: -0.000178  DirAcc: 54.37%\n",
      "Window processed in 41.57 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000404  RMSE: 0.020099  MAE: 0.014794  R²: -0.011776  DirAcc: 49.21%\n",
      "Window processed in 39.19 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000129  RMSE: 0.011362  MAE: 0.008989  R²: 0.002772  DirAcc: 48.40%\n",
      "Window processed in 48.85 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000091  RMSE: 0.009515  MAE: 0.007392  R²: -0.127835  DirAcc: 48.81%\n",
      "Window processed in 44.27 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000135  RMSE: 0.011600  MAE: 0.008455  R²: -0.026457  DirAcc: 44.05%\n",
      "Window processed in 44.69 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000256  RMSE: 0.016013  MAE: 0.012146  R²: -0.035938  DirAcc: 42.46%\n",
      "Window processed in 53.56 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000242  RMSE: 0.015566  MAE: 0.011507  R²: -0.007236  DirAcc: 47.22%\n",
      "Window processed in 41.18 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000070  RMSE: 0.008392  MAE: 0.006518  R²: 0.000379  DirAcc: 49.80%\n",
      "Window processed in 54.19 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000207  RMSE: 0.014373  MAE: 0.010545  R²: -0.045484  DirAcc: 49.00%\n",
      "Window processed in 42.55 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000145  RMSE: 0.012033  MAE: 0.009304  R²: 0.003828  DirAcc: 51.59%\n",
      "Window processed in 39.90 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.001737  RMSE: 0.041682  MAE: 0.027408  R²: -0.188876  DirAcc: 49.41%\n",
      "Window processed in 39.63 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000359  RMSE: 0.018956  MAE: 0.014993  R²: -0.016754  DirAcc: 51.59%\n",
      "Window processed in 37.31 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000521  RMSE: 0.022833  MAE: 0.018225  R²: -0.067233  DirAcc: 49.80%\n",
      "Window processed in 36.67 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000202  RMSE: 0.014219  MAE: 0.010974  R²: 0.003662  DirAcc: 50.00%\n",
      "Window processed in 37.04 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000124  RMSE: 0.011146  MAE: 0.008569  R²: -0.011068  DirAcc: 55.90%\n",
      "Window processed in 35.86 seconds\n",
      "\n",
      "==== Training models for ETF: XLF ====\n",
      "Selected features for XLF: ['XLF_Vol_5', 'SMB_lag_2', 'XLF_Mom_3', 'HML_lag_2', 'XLF_SMA_5', 'XLF_LagRet_1', 'XLF_EMA_12', 'SMB', 'XLF_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.002008  RMSE: 0.044815  MAE: 0.033613  R²: -0.208209  DirAcc: 48.81%\n",
      "Window processed in 57.89 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000272  RMSE: 0.016479  MAE: 0.012385  R²: -0.059209  DirAcc: 50.00%\n",
      "Window processed in 38.82 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000443  RMSE: 0.021040  MAE: 0.014604  R²: -0.009191  DirAcc: 50.00%\n",
      "Window processed in 38.45 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000124  RMSE: 0.011127  MAE: 0.008569  R²: -0.010407  DirAcc: 46.80%\n",
      "Window processed in 39.12 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000080  RMSE: 0.008939  MAE: 0.006987  R²: -0.019192  DirAcc: 42.06%\n",
      "Window processed in 35.72 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000066  RMSE: 0.008112  MAE: 0.006127  R²: -0.006616  DirAcc: 51.98%\n",
      "Window processed in 36.03 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000137  RMSE: 0.011723  MAE: 0.008627  R²: -0.087795  DirAcc: 51.98%\n",
      "Window processed in 44.34 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000137  RMSE: 0.011703  MAE: 0.008221  R²: 0.007469  DirAcc: 51.59%\n",
      "Window processed in 48.24 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000069  RMSE: 0.008289  MAE: 0.006144  R²: -0.019880  DirAcc: 50.60%\n",
      "Window processed in 45.68 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000152  RMSE: 0.012341  MAE: 0.008904  R²: 0.000774  DirAcc: 51.00%\n",
      "Window processed in 35.48 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000097  RMSE: 0.009857  MAE: 0.007322  R²: -0.017529  DirAcc: 53.97%\n",
      "Window processed in 36.00 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000879  RMSE: 0.029650  MAE: 0.019115  R²: -0.077117  DirAcc: 51.38%\n",
      "Window processed in 41.03 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000146  RMSE: 0.012101  MAE: 0.009433  R²: -0.029946  DirAcc: 57.54%\n",
      "Window processed in 39.14 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000240  RMSE: 0.015502  MAE: 0.012226  R²: -0.019484  DirAcc: 46.22%\n",
      "Window processed in 39.45 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000101  RMSE: 0.010057  MAE: 0.007498  R²: 0.024954  DirAcc: 53.20%\n",
      "Window processed in 42.47 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000080  RMSE: 0.008959  MAE: 0.006652  R²: -0.028900  DirAcc: 54.59%\n",
      "Window processed in 38.76 seconds\n",
      "\n",
      "==== Training models for ETF: XLI ====\n",
      "Selected features for XLI: ['XLI_Vol_5', 'SMB_lag_2', 'XLI_Mom_3', 'HML_lag_2', 'XLI_SMA_5', 'XLI_LagRet_1', 'XLI_EMA_12', 'SMB', 'XLI_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000432  RMSE: 0.020795  MAE: 0.015680  R²: -0.018156  DirAcc: 55.95%\n",
      "Window processed in 36.65 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000195  RMSE: 0.013950  MAE: 0.009899  R²: -0.017129  DirAcc: 45.63%\n",
      "Window processed in 40.60 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000319  RMSE: 0.017874  MAE: 0.012799  R²: -0.080064  DirAcc: 52.38%\n",
      "Window processed in 37.62 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000094  RMSE: 0.009703  MAE: 0.007382  R²: -0.001311  DirAcc: 53.60%\n",
      "Window processed in 35.94 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000067  RMSE: 0.008172  MAE: 0.006346  R²: -0.017471  DirAcc: 57.14%\n",
      "Window processed in 38.99 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000074  RMSE: 0.008588  MAE: 0.006360  R²: -0.004584  DirAcc: 50.79%\n",
      "Window processed in 36.55 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000106  RMSE: 0.010286  MAE: 0.007795  R²: -0.008072  DirAcc: 45.63%\n",
      "Window processed in 42.06 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000086  RMSE: 0.009296  MAE: 0.006642  R²: -0.013795  DirAcc: 51.19%\n",
      "Window processed in 35.99 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000033  RMSE: 0.005782  MAE: 0.004359  R²: -0.011121  DirAcc: 57.77%\n",
      "Window processed in 38.12 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000144  RMSE: 0.012005  MAE: 0.008667  R²: -0.003399  DirAcc: 52.99%\n",
      "Window processed in 38.48 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000099  RMSE: 0.009954  MAE: 0.007378  R²: -0.010857  DirAcc: 51.98%\n",
      "Window processed in 37.95 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000630  RMSE: 0.025101  MAE: 0.016150  R²: -0.009807  DirAcc: 57.71%\n",
      "Window processed in 35.74 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000097  RMSE: 0.009848  MAE: 0.007619  R²: -0.017144  DirAcc: 49.60%\n",
      "Window processed in 37.15 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000197  RMSE: 0.014019  MAE: 0.011068  R²: -0.042193  DirAcc: 47.41%\n",
      "Window processed in 38.15 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000086  RMSE: 0.009285  MAE: 0.007416  R²: 0.004600  DirAcc: 54.00%\n",
      "Window processed in 36.82 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000075  RMSE: 0.008641  MAE: 0.006617  R²: -0.027499  DirAcc: 47.16%\n",
      "Window processed in 34.82 seconds\n",
      "\n",
      "==== Training models for ETF: XLK ====\n",
      "Selected features for XLK: ['XLK_Vol_5', 'SMB_lag_2', 'XLK_Mom_3', 'HML_lag_2', 'XLK_SMA_5', 'XLK_LagRet_1', 'XLK_EMA_12', 'SMB', 'XLK_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000250  RMSE: 0.015819  MAE: 0.011705  R²: 0.028599  DirAcc: 50.40%\n",
      "Window processed in 47.83 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000140  RMSE: 0.011849  MAE: 0.008537  R²: -0.017267  DirAcc: 54.76%\n",
      "Window processed in 40.20 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000203  RMSE: 0.014249  MAE: 0.010512  R²: -0.005567  DirAcc: 53.97%\n",
      "Window processed in 40.81 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000091  RMSE: 0.009541  MAE: 0.007208  R²: -0.011603  DirAcc: 46.80%\n",
      "Window processed in 48.11 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000063  RMSE: 0.007951  MAE: 0.006422  R²: -0.272098  DirAcc: 42.06%\n",
      "Window processed in 39.06 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000064  RMSE: 0.007977  MAE: 0.006002  R²: -0.002611  DirAcc: 51.59%\n",
      "Window processed in 40.70 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000129  RMSE: 0.011355  MAE: 0.008269  R²: -0.016802  DirAcc: 53.17%\n",
      "Window processed in 40.63 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000095  RMSE: 0.009730  MAE: 0.007048  R²: -0.015291  DirAcc: 51.19%\n",
      "Window processed in 47.63 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000044  RMSE: 0.006662  MAE: 0.004683  R²: -0.037734  DirAcc: 56.57%\n",
      "Window processed in 42.59 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000215  RMSE: 0.014656  MAE: 0.010500  R²: 0.004218  DirAcc: 53.39%\n",
      "Window processed in 36.88 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000133  RMSE: 0.011547  MAE: 0.008406  R²: -0.024558  DirAcc: 51.98%\n",
      "Window processed in 40.26 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000639  RMSE: 0.025278  MAE: 0.016408  R²: -0.001652  DirAcc: 50.20%\n",
      "Window processed in 48.18 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000147  RMSE: 0.012111  MAE: 0.009396  R²: -0.002642  DirAcc: 50.79%\n",
      "Window processed in 44.55 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000428  RMSE: 0.020699  MAE: 0.016738  R²: -0.007050  DirAcc: 45.82%\n",
      "Window processed in 37.03 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000140  RMSE: 0.011823  MAE: 0.009298  R²: -0.007760  DirAcc: 54.80%\n",
      "Window processed in 45.35 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000200  RMSE: 0.014158  MAE: 0.010492  R²: -0.012361  DirAcc: 50.66%\n",
      "Window processed in 41.23 seconds\n",
      "\n",
      "==== Training models for ETF: XLP ====\n",
      "Selected features for XLP: ['XLP_Vol_5', 'SMB_lag_2', 'XLP_Mom_3', 'HML_lag_2', 'XLP_SMA_5', 'XLP_LagRet_1', 'XLP_EMA_12', 'SMB', 'XLP_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000119  RMSE: 0.010896  MAE: 0.008264  R²: -0.001460  DirAcc: 56.75%\n",
      "Window processed in 36.10 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000060  RMSE: 0.007738  MAE: 0.005768  R²: -0.015453  DirAcc: 45.24%\n",
      "Window processed in 36.02 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000090  RMSE: 0.009500  MAE: 0.007062  R²: -0.043805  DirAcc: 49.60%\n",
      "Window processed in 35.65 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000039  RMSE: 0.006278  MAE: 0.004619  R²: 0.001127  DirAcc: 52.40%\n",
      "Window processed in 35.82 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000050  RMSE: 0.007066  MAE: 0.005298  R²: -0.011804  DirAcc: 46.03%\n",
      "Window processed in 35.54 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000038  RMSE: 0.006145  MAE: 0.004754  R²: -0.020609  DirAcc: 51.59%\n",
      "Window processed in 39.27 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000078  RMSE: 0.008850  MAE: 0.006687  R²: -0.007475  DirAcc: 52.78%\n",
      "Window processed in 41.74 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000055  RMSE: 0.007432  MAE: 0.005611  R²: -0.003747  DirAcc: 55.95%\n",
      "Window processed in 42.10 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000024  RMSE: 0.004929  MAE: 0.003738  R²: -0.012587  DirAcc: 45.82%\n",
      "Window processed in 41.49 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000086  RMSE: 0.009288  MAE: 0.006812  R²: -0.033976  DirAcc: 49.00%\n",
      "Window processed in 39.19 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000046  RMSE: 0.006793  MAE: 0.005107  R²: -0.000671  DirAcc: 58.33%\n",
      "Window processed in 45.41 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000304  RMSE: 0.017442  MAE: 0.010463  R²: 0.018140  DirAcc: 51.78%\n",
      "Window processed in 36.01 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000050  RMSE: 0.007048  MAE: 0.005277  R²: -0.028757  DirAcc: 54.37%\n",
      "Window processed in 36.68 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000125  RMSE: 0.011168  MAE: 0.008254  R²: -0.032887  DirAcc: 52.19%\n",
      "Window processed in 37.80 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000052  RMSE: 0.007180  MAE: 0.005682  R²: 0.001105  DirAcc: 51.60%\n",
      "Window processed in 37.06 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000042  RMSE: 0.006506  MAE: 0.005175  R²: -0.139796  DirAcc: 49.78%\n",
      "Window processed in 37.04 seconds\n",
      "\n",
      "==== Training models for ETF: XLY ====\n",
      "Selected features for XLY: ['XLY_Vol_5', 'SMB_lag_2', 'XLY_Mom_3', 'HML_lag_2', 'XLY_SMA_5', 'XLY_LagRet_1', 'XLY_EMA_12', 'SMB', 'XLY_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000386  RMSE: 0.019647  MAE: 0.014812  R²: -0.012861  DirAcc: 51.59%\n",
      "Window processed in 47.52 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000172  RMSE: 0.013123  MAE: 0.009583  R²: -0.018631  DirAcc: 48.02%\n",
      "Window processed in 38.36 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000231  RMSE: 0.015199  MAE: 0.011135  R²: -0.011968  DirAcc: 46.43%\n",
      "Window processed in 39.05 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000080  RMSE: 0.008950  MAE: 0.006755  R²: -0.009898  DirAcc: 48.40%\n",
      "Window processed in 42.10 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000063  RMSE: 0.007950  MAE: 0.006332  R²: -0.023700  DirAcc: 51.19%\n",
      "Window processed in 40.23 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000069  RMSE: 0.008288  MAE: 0.006465  R²: 0.005508  DirAcc: 57.14%\n",
      "Window processed in 38.08 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000111  RMSE: 0.010551  MAE: 0.008024  R²: -0.033125  DirAcc: 52.78%\n",
      "Window processed in 38.22 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000083  RMSE: 0.009096  MAE: 0.006625  R²: -0.007922  DirAcc: 46.83%\n",
      "Window processed in 37.95 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000028  RMSE: 0.005253  MAE: 0.004075  R²: -0.024416  DirAcc: 56.97%\n",
      "Window processed in 38.02 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000147  RMSE: 0.012106  MAE: 0.008650  R²: 0.009224  DirAcc: 54.18%\n",
      "Window processed in 35.86 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000080  RMSE: 0.008917  MAE: 0.006758  R²: -0.008547  DirAcc: 57.54%\n",
      "Window processed in 37.83 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000479  RMSE: 0.021897  MAE: 0.013868  R²: -0.066392  DirAcc: 55.34%\n",
      "Window processed in 42.15 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000132  RMSE: 0.011475  MAE: 0.008746  R²: 0.006564  DirAcc: 57.14%\n",
      "Window processed in 40.22 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000470  RMSE: 0.021689  MAE: 0.017090  R²: -0.021457  DirAcc: 48.61%\n",
      "Window processed in 37.48 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000161  RMSE: 0.012691  MAE: 0.009843  R²: -0.018985  DirAcc: 57.20%\n",
      "Window processed in 48.47 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000132  RMSE: 0.011477  MAE: 0.009053  R²: -0.007445  DirAcc: 52.40%\n",
      "Window processed in 37.50 seconds\n",
      "\n",
      "==== Training models for ETF: XLV ====\n",
      "Selected features for XLV: ['XLV_Vol_5', 'SMB_lag_2', 'XLV_Mom_3', 'HML_lag_2', 'XLV_SMA_5', 'XLV_LagRet_1', 'XLV_EMA_12', 'SMB', 'XLV_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000153  RMSE: 0.012368  MAE: 0.009194  R²: 0.036565  DirAcc: 51.19%\n",
      "Window processed in 38.22 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000089  RMSE: 0.009434  MAE: 0.007074  R²: -0.012766  DirAcc: 46.43%\n",
      "Window processed in 40.62 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000154  RMSE: 0.012416  MAE: 0.008749  R²: -0.006685  DirAcc: 49.60%\n",
      "Window processed in 40.77 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000048  RMSE: 0.006950  MAE: 0.005278  R²: -0.003740  DirAcc: 52.40%\n",
      "Window processed in 40.15 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000059  RMSE: 0.007667  MAE: 0.005909  R²: -0.027898  DirAcc: 52.38%\n",
      "Window processed in 43.11 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000084  RMSE: 0.009160  MAE: 0.006946  R²: -0.022208  DirAcc: 48.81%\n",
      "Window processed in 37.93 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000138  RMSE: 0.011732  MAE: 0.008861  R²: -0.022936  DirAcc: 50.79%\n",
      "Window processed in 39.57 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000092  RMSE: 0.009604  MAE: 0.007265  R²: -0.006563  DirAcc: 49.21%\n",
      "Window processed in 44.70 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000030  RMSE: 0.005513  MAE: 0.004302  R²: -0.007031  DirAcc: 54.18%\n",
      "Window processed in 36.69 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000122  RMSE: 0.011032  MAE: 0.007997  R²: 0.003950  DirAcc: 50.20%\n",
      "Window processed in 42.31 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000070  RMSE: 0.008388  MAE: 0.006241  R²: -0.011887  DirAcc: 54.76%\n",
      "Window processed in 47.57 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000416  RMSE: 0.020385  MAE: 0.012474  R²: -0.122979  DirAcc: 48.62%\n",
      "Window processed in 39.68 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000058  RMSE: 0.007600  MAE: 0.005890  R²: -0.043292  DirAcc: 48.81%\n",
      "Window processed in 38.47 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000150  RMSE: 0.012234  MAE: 0.009882  R²: -0.054148  DirAcc: 44.62%\n",
      "Window processed in 36.96 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000053  RMSE: 0.007313  MAE: 0.005973  R²: 0.002767  DirAcc: 52.40%\n",
      "Window processed in 36.69 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000090  RMSE: 0.009474  MAE: 0.007920  R²: -0.990774  DirAcc: 49.34%\n",
      "Window processed in 46.69 seconds\n",
      "\n",
      "==== Training models for ETF: XLU ====\n",
      "Selected features for XLU: ['XLU_Vol_5', 'SMB_lag_2', 'XLU_Mom_3', 'HML_lag_2', 'XLU_SMA_5', 'XLU_LagRet_1', 'XLU_EMA_12', 'SMB', 'XLU_RSI_7', 'CMA_lag_1']\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000170  RMSE: 0.013043  MAE: 0.009982  R²: -0.043267  DirAcc: 49.21%\n",
      "Window processed in 37.16 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000091  RMSE: 0.009535  MAE: 0.007177  R²: -0.002548  DirAcc: 47.22%\n",
      "Window processed in 36.53 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000111  RMSE: 0.010547  MAE: 0.007713  R²: -0.002519  DirAcc: 51.19%\n",
      "Window processed in 36.09 seconds\n",
      "\n",
      "Training window starting 2012\n",
      "MSE: 0.000038  RMSE: 0.006201  MAE: 0.004803  R²: 0.000525  DirAcc: 49.20%\n",
      "Window processed in 39.97 seconds\n",
      "\n",
      "Training window starting 2013\n",
      "MSE: 0.000060  RMSE: 0.007723  MAE: 0.005964  R²: 0.006304  DirAcc: 52.78%\n",
      "Window processed in 39.92 seconds\n",
      "\n",
      "Training window starting 2014\n",
      "MSE: 0.000073  RMSE: 0.008564  MAE: 0.006785  R²: -0.016685  DirAcc: 50.79%\n",
      "Window processed in 38.02 seconds\n",
      "\n",
      "Training window starting 2015\n",
      "MSE: 0.000120  RMSE: 0.010940  MAE: 0.008302  R²: -0.017290  DirAcc: 56.75%\n",
      "Window processed in 44.81 seconds\n",
      "\n",
      "Training window starting 2016\n",
      "MSE: 0.000099  RMSE: 0.009957  MAE: 0.007397  R²: -0.009146  DirAcc: 53.17%\n",
      "Window processed in 43.07 seconds\n",
      "\n",
      "Training window starting 2017\n",
      "MSE: 0.000039  RMSE: 0.006209  MAE: 0.004907  R²: -0.011585  DirAcc: 52.59%\n",
      "Window processed in 45.67 seconds\n",
      "\n",
      "Training window starting 2018\n",
      "MSE: 0.000090  RMSE: 0.009476  MAE: 0.007209  R²: 0.019425  DirAcc: 55.38%\n",
      "Window processed in 38.95 seconds\n",
      "\n",
      "Training window starting 2019\n",
      "MSE: 0.000052  RMSE: 0.007199  MAE: 0.005475  R²: -0.020820  DirAcc: 55.16%\n",
      "Window processed in 42.43 seconds\n",
      "\n",
      "Training window starting 2020\n",
      "MSE: 0.000631  RMSE: 0.025126  MAE: 0.015065  R²: -0.062813  DirAcc: 53.75%\n",
      "Window processed in 41.63 seconds\n",
      "\n",
      "Training window starting 2021\n",
      "MSE: 0.000088  RMSE: 0.009379  MAE: 0.007492  R²: -0.009299  DirAcc: 50.40%\n",
      "Window processed in 41.62 seconds\n",
      "\n",
      "Training window starting 2022\n",
      "MSE: 0.000180  RMSE: 0.013403  MAE: 0.010348  R²: -0.005125  DirAcc: 48.61%\n",
      "Window processed in 41.14 seconds\n",
      "\n",
      "Training window starting 2023\n",
      "MSE: 0.000129  RMSE: 0.011349  MAE: 0.008641  R²: -0.017466  DirAcc: 50.00%\n",
      "Window processed in 40.25 seconds\n",
      "\n",
      "Training window starting 2024\n",
      "MSE: 0.000097  RMSE: 0.009838  MAE: 0.007741  R²: -0.037169  DirAcc: 48.91%\n",
      "Window processed in 44.77 seconds\n",
      "Stage 1 completed and data saved for Stage 2.\n"
     ]
    }
   ],
   "source": [
    "# # stage 1 training and prediction\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import shap\n",
    "# import ta\n",
    "# import joblib\n",
    "# from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import time\n",
    "# import random\n",
    "# import os\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "# \n",
    "# GLOBAL_SEED = 42\n",
    "# np.random.seed(GLOBAL_SEED)\n",
    "# random.seed(GLOBAL_SEED)\n",
    "# os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "# # ------------------------------------------------------------------------\n",
    "# # 0. Load and align data\n",
    "# # ------------------------------------------------------------------------\n",
    "# factors = pd.read_csv(\"aligned_factors.csv\", index_col=0, parse_dates=True)\n",
    "# returns = pd.read_csv(\"daily_returns_10ETFs.csv\", index_col=0, parse_dates=True)\n",
    "# \n",
    "# # Align dates to ensure matching indices\n",
    "# dates = factors.index.intersection(returns.index)\n",
    "# factors = factors.loc[dates]\n",
    "# returns = returns.loc[dates]\n",
    "# \n",
    "# \n",
    "# # ------------------------------------------------------------------------\n",
    "# # 1. Compute technical indicators and lagged features per ETF\n",
    "# # ------------------------------------------------------------------------\n",
    "# all_tech_features = []\n",
    "# \n",
    "# for etf in returns.columns:\n",
    "#     close = (1 + returns[etf]).cumprod()\n",
    "#     tech_df = pd.DataFrame(index=returns.index)\n",
    "# \n",
    "#     # Selected indicators (others commented out to reduce noise)\n",
    "#     tech_df[f'{etf}_SMA_5']   = ta.trend.sma_indicator(close, window=5)\n",
    "#     tech_df[f'{etf}_EMA_12']  = ta.trend.ema_indicator(close, window=12)\n",
    "#     tech_df[f'{etf}_RSI_7']   = ta.momentum.rsi(close, window=7)\n",
    "#     tech_df[f'{etf}_MACD']    = ta.trend.macd_diff(close)\n",
    "#     tech_df[f'{etf}_ATR']     = ta.volatility.average_true_range(\n",
    "#         high=close * 1.01, low=close * 0.99, close=close, window=10\n",
    "#     )\n",
    "#     tech_df[f'{etf}_Vol_5']   = returns[etf].rolling(window=5).std()\n",
    "#     tech_df[f'{etf}_Mom_3']   = returns[etf].rolling(window=3).mean()\n",
    "# \n",
    "#     # Lagged returns (shifted so only past information is used)\n",
    "#     for lag in [1, 2, 3]:\n",
    "#         tech_df[f'{etf}_LagRet_{lag}'] = returns[etf].shift(lag)\n",
    "# \n",
    "#     all_tech_features.append(tech_df)\n",
    "# \n",
    "# # Concatenate technical indicators for all ETFs\n",
    "# technical_features = pd.concat(all_tech_features, axis=1)\n",
    "# \n",
    "# # ------------------------------------------------------------------------\n",
    "# # 2. Create lagged factor features\n",
    "# # ------------------------------------------------------------------------\n",
    "# for factor in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']:\n",
    "#     for lag in [1, 2, 3]:\n",
    "#         factors[f'{factor}_lag_{lag}'] = factors[factor].shift(lag)\n",
    "# \n",
    "# # Drop rows with NA values arising from lagging\n",
    "# factors = factors.dropna()\n",
    "# \n",
    "# # ------------------------------------------------------------------------\n",
    "# # 3. Combine factors, technical features, and VIX change\n",
    "# # ------------------------------------------------------------------------\n",
    "# features = pd.concat([factors, technical_features], axis=1).dropna()\n",
    "# vix = pd.read_csv(\"VIX_History.csv\", index_col=0, parse_dates=True)\n",
    "# \n",
    "# # Align VIX to our feature dates and compute lagged change\n",
    "# vix_aligned = vix['CLOSE'].reindex(features.index).ffill()\n",
    "# features['VIX'] = vix_aligned.pct_change(fill_method=None).shift(1)\n",
    "# features['VIX'] = features['VIX'].fillna(0)\n",
    "# \n",
    "# # Define the target: next-day return per ETF\n",
    "# target_returns = returns.shift(-1).loc[features.index].dropna()\n",
    "# features = features.loc[target_returns.index]\n",
    "# \n",
    "# # ------------------------------------------------------------------------\n",
    "# # 4. Define rolling window parameters\n",
    "# # ------------------------------------------------------------------------\n",
    "# train_years = 12      # years used for training\n",
    "# valid_years = 1       # years used for validation\n",
    "# test_years  = 1       # years used for testing/prediction\n",
    "# retrain_frequency = 1 # years between retrainings\n",
    "# start_year = 2009\n",
    "# end_year   = 2024\n",
    "# \n",
    "# # List generic features used for SHAP importance ranking\n",
    "# all_generic_features = [\n",
    "#     'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA',\n",
    "#     'Mkt-RF_lag_1', 'Mkt-RF_lag_2', 'Mkt-RF_lag_3',\n",
    "#     'SMB_lag_1', 'SMB_lag_2', 'SMB_lag_3',\n",
    "#     'HML_lag_1', 'HML_lag_2', 'HML_lag_3',\n",
    "#     'RMW_lag_1', 'RMW_lag_2', 'RMW_lag_3',\n",
    "#     'CMA_lag_1', 'CMA_lag_2', 'CMA_lag_3',\n",
    "#     'SMA_5', 'EMA_12', 'RSI_7', 'MACD',\n",
    "#     'Vol_5', 'Mom_3',\n",
    "#     'LagRet_1', 'LagRet_2', 'LagRet_3', 'VIX'\n",
    "# ]\n",
    "# \n",
    "# # ------------------------------------------------------------------------\n",
    "# # 5. Compute generic feature importance via SHAP\n",
    "# #    (aggregated across ETFs, using only the initial training window)\n",
    "# # ------------------------------------------------------------------------\n",
    "# shap_importances = pd.DataFrame(0.0, index=all_generic_features, columns=['SHAP_Value'])\n",
    "# \n",
    "# # Use a fixed period (e.g. up to year 2009) for computing importances\n",
    "# base_train_start = pd.Timestamp(start_year - train_years, 1, 1)\n",
    "# base_train_end   = pd.Timestamp(start_year - valid_years - 1, 12, 31)\n",
    "# \n",
    "# for etf in returns.columns:\n",
    "#     print(f\"Computing SHAP importances for ETF: {etf}\")\n",
    "#     # Filter columns relevant to this ETF (generic + factor features)\n",
    "#     etf_cols = [\n",
    "#         col for col in features.columns\n",
    "#         if (etf in col and any(k in col for k in ['SMA_5', 'EMA_12', 'RSI_7',\n",
    "#                                                   'MACD', 'Vol_5', 'Mom_3',\n",
    "#                                                   'LagRet_1','LagRet_2','LagRet_3', 'VIX']))\n",
    "#         or col in ['Mkt-RF','SMB','HML','RMW','CMA',\n",
    "#                    'Mkt-RF_lag_1','Mkt-RF_lag_2','Mkt-RF_lag_3',\n",
    "#                    'SMB_lag_1','SMB_lag_2','SMB_lag_3',\n",
    "#                    'HML_lag_1','HML_lag_2','HML_lag_3',\n",
    "#                    'RMW_lag_1','RMW_lag_2','RMW_lag_3',\n",
    "#                    'CMA_lag_1','CMA_lag_2','CMA_lag_3']\n",
    "#     ]\n",
    "#     X_base  = features.loc[base_train_start:base_train_end, etf_cols]\n",
    "#     y_base  = target_returns[etf].loc[base_train_start:base_train_end]\n",
    "# \n",
    "#     # Fit a quick model to compute SHAP\n",
    "#     model_base = xgb.XGBRegressor(\n",
    "#         objective='reg:squarederror',\n",
    "#         tree_method='hist',\n",
    "#         random_state=GLOBAL_SEED,\n",
    "#         seed=GLOBAL_SEED,\n",
    "#         device='cuda'\n",
    "#     ).fit(X_base, y_base)\n",
    "# \n",
    "#     explainer_base = shap.Explainer(model_base)\n",
    "#     shap_vals = explainer_base(X_base)\n",
    "# \n",
    "#     # Aggregate SHAP values per generic feature\n",
    "#     for gen_feat in all_generic_features:\n",
    "#         cols = [c for c in X_base.columns if gen_feat in c]\n",
    "#         if cols:\n",
    "#             idx = [X_base.columns.get_loc(c) for c in cols]\n",
    "#             shap_importances.loc[gen_feat] += np.mean(np.abs(shap_vals.values[:, idx]))\n",
    "# \n",
    "# # Average importance across ETFs and select top N\n",
    "# shap_importances /= len(returns.columns)\n",
    "# top_generic_features = (\n",
    "#     shap_importances.sort_values('SHAP_Value', ascending=False)\n",
    "#                     .head(10)\n",
    "#                     .index\n",
    "#                     .tolist()\n",
    "# )\n",
    "# \n",
    "# # returns = returns.iloc[:,:2]\n",
    "# # ------------------------------------------------------------------------\n",
    "# # 6. Retrain models using the selected generic features in rolling windows\n",
    "# # ------------------------------------------------------------------------\n",
    "# all_predictions = []\n",
    "# \n",
    "# # for etf in returns.columns:\n",
    "# #     print(f\"\\n==== Training models for ETF: {etf} ====\")\n",
    "# #     # Select columns containing any of the top_generic_features or factor names\n",
    "# #     selected_features = [\n",
    "# #         f for f in features.columns\n",
    "# #         if any(gen in f for gen in top_generic_features) or f in factors.columns\n",
    "# #     ]\n",
    "# \n",
    "# for etf in returns.columns:\n",
    "#     print(f\"\\n==== Training models for ETF: {etf} ====\")\n",
    "# \n",
    "#     # Select features explicitly relevant to current ETF\n",
    "#     # selected_features = [\n",
    "#     #     f for f in features.columns\n",
    "#     #     if (\n",
    "#     #         # Include ETF-specific technical indicators explicitly\n",
    "#     #         (any(gen in f for gen in top_generic_features) and (etf in f))\n",
    "#     #         # Include ONLY explicitly selected generic FF factors or their lags\n",
    "#     #         or (any(gen == f for gen in top_generic_features))\n",
    "#     #     )\n",
    "#     # ]\n",
    "#     \n",
    "#     selected_features = []\n",
    "# \n",
    "#     for feature in top_generic_features:\n",
    "#         # Clearly check if the feature is ETF-specific (technical indicators)\n",
    "#         etf_specific_feature_name = f'{etf}_{feature}'\n",
    "#         \n",
    "#         # Add ETF-specific feature explicitly if present in columns\n",
    "#         if etf_specific_feature_name in features.columns:\n",
    "#             selected_features.append(etf_specific_feature_name)\n",
    "#         \n",
    "#         # If not ETF-specific, explicitly add generic factor features directly\n",
    "#         elif feature in features.columns:\n",
    "#             selected_features.append(feature)\n",
    "#     \n",
    "#     # Sanity check to ensure you have valid selected features\n",
    "#     if not selected_features:\n",
    "#         raise ValueError(f\"No features selected for {etf}, please verify feature names.\")\n",
    "# \n",
    "#     print(f\"Selected features for {etf}: {selected_features}\")\n",
    "#     \n",
    "#     year = start_year\n",
    "#     while year <= end_year - test_years + 1:\n",
    "#         print(f\"\\nTraining window starting {year}\")\n",
    "#         start_time = time.time()\n",
    "# \n",
    "#         # Define periods\n",
    "#         train_start = pd.Timestamp(year - train_years, 1, 1)\n",
    "#         train_end   = pd.Timestamp(year - valid_years - 1, 12, 31)\n",
    "#         valid_start = pd.Timestamp(year - valid_years, 1, 1)\n",
    "#         valid_end   = pd.Timestamp(year - 1, 12, 31)\n",
    "#         test_start  = pd.Timestamp(year, 1, 1)\n",
    "#         test_end    = pd.Timestamp(year + test_years - 1, 12, 31)\n",
    "# \n",
    "#         # Extract data\n",
    "#         X_train = features.loc[train_start:train_end, selected_features]\n",
    "#         y_train = target_returns[etf].loc[train_start:train_end]\n",
    "#         X_valid = features.loc[valid_start:valid_end, selected_features]\n",
    "#         y_valid = target_returns[etf].loc[valid_start:valid_end]\n",
    "#         X_test  = features.loc[test_start:test_end, selected_features]\n",
    "#         y_test  = target_returns[etf].loc[test_start:test_end]\n",
    "#         \n",
    "#         scaler = StandardScaler()\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_valid_scaled = scaler.transform(X_valid)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "#         \n",
    "#         # # Base model with early stopping\n",
    "#         # base_model = xgb.XGBRegressor(\n",
    "#         #     objective='reg:squarederror',\n",
    "#         #     tree_method='hist',\n",
    "#         #     device='cuda',\n",
    "#         #     random_state=42,\n",
    "#         #     n_jobs=4,\n",
    "#         #     # eval_metric='rmse', # The metric to monitor for early stopping\n",
    "#         #     # early_stopping_rounds=50\n",
    "#         # )\n",
    "#         # \n",
    "#         # param_grid = {\n",
    "#         #     'n_estimators': [200, 400],\n",
    "#         #     'max_depth': [3, 4, 5],\n",
    "#         #     'learning_rate': [0.03, 0.05],\n",
    "#         #     'subsample': [0.7, 0.8],\n",
    "#         #     'colsample_bytree': [0.7, 0.8]\n",
    "#         # }\n",
    "#         # \n",
    "#         # tscv = TimeSeriesSplit(n_splits=3)\n",
    "#         # \n",
    "#         # grid_search = GridSearchCV(\n",
    "#         #     base_model,\n",
    "#         #     param_grid,\n",
    "#         #     cv=tscv,\n",
    "#         #     scoring='neg_mean_squared_error',\n",
    "#         #     verbose=0,\n",
    "#         #     n_jobs=4\n",
    "#         # )\n",
    "#         # \n",
    "#         # # Fit with early stopping on the explicit validation set\n",
    "#         # # fit_params = {\n",
    "#         # #     \"eval_set\": [(X_valid, y_valid)],\n",
    "#         # #     \"verbose\": False\n",
    "#         # # }\n",
    "#         # # \n",
    "#         # # # grid_search.fit(X_train, y_train, **fit_params)\n",
    "#         # # grid_search.fit(X_train_scaled, y_train)\n",
    "#         # \n",
    "#         # fit_params = {\n",
    "#         #     'eval_set': [(X_valid_scaled, y_valid)],\n",
    "#         #     'eval_metric': 'rmse',\n",
    "#         #     'early_stopping_rounds': 50,\n",
    "#         #     'verbose': False\n",
    "#         # }\n",
    "#         # \n",
    "#         # grid_search.fit(X_train_scaled, y_train, **fit_params)\n",
    "#         # \n",
    "#         # best_model = grid_search.best_estimator_\n",
    "#         # \n",
    "#         # # Predict on the test period\n",
    "#         # preds = best_model.predict(X_test_scaled)\n",
    "# \n",
    "#         \n",
    "#         # Define your parameter grid explicitly\n",
    "#         param_grid = {\n",
    "#             'n_estimators': [200, 400],\n",
    "#             'max_depth': [3, 4, 5],\n",
    "#             'learning_rate': [0.03, 0.05],\n",
    "#             'subsample': [0.7, 0.8],\n",
    "#             'colsample_bytree': [0.7, 0.8]\n",
    "#         }\n",
    "#         \n",
    "#         tscv = TimeSeriesSplit(n_splits=3)\n",
    "#         \n",
    "#         best_score = float('inf')\n",
    "#         best_params = None\n",
    "#         best_model = None\n",
    "#         \n",
    "#         # Explicit loop for parameter search and cross-validation\n",
    "#         for params in ParameterGrid(param_grid):\n",
    "#             cv_rmse = []\n",
    "#         \n",
    "#             for train_idx, val_idx in tscv.split(X_train_scaled):\n",
    "#                 X_fold_train, X_fold_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "#                 y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "#         \n",
    "#                 # DMatrix explicitly required by XGBoost native API\n",
    "#                 dtrain = xgb.DMatrix(X_fold_train, label=y_fold_train)\n",
    "#                 dval = xgb.DMatrix(X_fold_val, label=y_fold_val)\n",
    "#         \n",
    "#                 # Setup watchlist explicitly for early stopping\n",
    "#                 watchlist = [(dtrain, 'train'), (dval, 'validation')]\n",
    "#         \n",
    "#                 xgb_params = {\n",
    "#                     'objective': 'reg:squarederror',\n",
    "#                     'tree_method': 'hist',\n",
    "#                     'device': 'cuda',\n",
    "#                     'eval_metric': 'rmse',\n",
    "#                     'seed': 42,\n",
    "#                     'max_depth': params['max_depth'],\n",
    "#                     'learning_rate': params['learning_rate'],\n",
    "#                     'subsample': params['subsample'],\n",
    "#                     'colsample_bytree': params['colsample_bytree']\n",
    "#                 }\n",
    "#         \n",
    "#                 # Explicitly train with early stopping\n",
    "#                 model = xgb.train(\n",
    "#                     xgb_params,\n",
    "#                     dtrain,\n",
    "#                     num_boost_round=params['n_estimators'],\n",
    "#                     evals=watchlist,\n",
    "#                     early_stopping_rounds=50,\n",
    "#                     verbose_eval=False\n",
    "#                 )\n",
    "#         \n",
    "#                 preds = model.predict(dval)\n",
    "#                 rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "#                 cv_rmse.append(rmse)\n",
    "#         \n",
    "#             avg_rmse = np.mean(cv_rmse)\n",
    "#             # print(f\"Params: {params}, CV Avg RMSE: {avg_rmse:.6f}\")\n",
    "#         \n",
    "#             if avg_rmse < best_score:\n",
    "#                 best_score = avg_rmse\n",
    "#                 best_params = params\n",
    "#                 best_model = model\n",
    "#         \n",
    "#         # Train final model explicitly with best parameters on full training data\n",
    "#         dtrain_full = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "#         dvalid_full = xgb.DMatrix(X_valid_scaled, label=y_valid)\n",
    "#         \n",
    "#         watchlist_full = [(dtrain_full, 'train'), (dvalid_full, 'validation')]\n",
    "#         \n",
    "#         final_xgb_params = {\n",
    "#             'objective': 'reg:squarederror',\n",
    "#             'tree_method': 'hist',\n",
    "#             'device': 'cuda',\n",
    "#             'eval_metric': 'rmse',\n",
    "#             'seed': 42,\n",
    "#             'max_depth': best_params['max_depth'],\n",
    "#             'learning_rate': best_params['learning_rate'],\n",
    "#             'subsample': best_params['subsample'],\n",
    "#             'colsample_bytree': best_params['colsample_bytree']\n",
    "#         }\n",
    "#         \n",
    "#         best_model = xgb.train(\n",
    "#             final_xgb_params,\n",
    "#             dtrain_full,\n",
    "#             num_boost_round=best_params['n_estimators'],\n",
    "#             evals=watchlist_full,\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose_eval=False\n",
    "#         )\n",
    "#         \n",
    "#         # Predict explicitly on test data\n",
    "#         dtest = xgb.DMatrix(X_test_scaled)\n",
    "#         preds = best_model.predict(dtest)\n",
    "#         \n",
    "#         # Metrics clearly\n",
    "#         test_rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "#         # print(f\"Test RMSE: {test_rmse:.6f}\")\n",
    "#         \n",
    "#         # Compute evaluation metrics\n",
    "#         mse  = mean_squared_error(y_test, preds)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mae  = mean_absolute_error(y_test, preds)\n",
    "#         r2   = r2_score(y_test, preds)\n",
    "#         dir_acc = np.mean((np.sign(y_test) == np.sign(preds)).astype(int))\n",
    "# \n",
    "#         print(f\"MSE: {mse:.6f}  RMSE: {rmse:.6f}  MAE: {mae:.6f}  \"\n",
    "#               f\"R²: {r2:.6f}  DirAcc: {dir_acc:.2%}\")\n",
    "# \n",
    "#         # Save the model for reproducibility\n",
    "#         joblib.dump(best_model, f\"best_model_{etf}_{year}.joblib\")\n",
    "# \n",
    "#         # Save predictions\n",
    "#         preds_df = pd.DataFrame({\n",
    "#             'Date': X_test.index,\n",
    "#             'ETF': etf,\n",
    "#             'Year': year,\n",
    "#             'Actual_Return': y_test,\n",
    "#             'Predicted_Return': preds\n",
    "#         }).reset_index(drop=True)\n",
    "# \n",
    "#         # Compute SHAP values on the test set\n",
    "#         explainer_test = shap.Explainer(best_model, feature_names=X_test.columns)\n",
    "#         shap_vals_test = explainer_test(X_test_scaled)\n",
    "# \n",
    "#         clean_shap_cols = [\n",
    "#             f'SHAP_{col.replace(f\"{etf}_\", \"\")}' if col.startswith(f'{etf}_') else f'SHAP_{col}'\n",
    "#             for col in X_test.columns\n",
    "#         ]\n",
    "#         \n",
    "#         shap_df = pd.DataFrame(\n",
    "#             shap_vals_test.values,\n",
    "#             columns=clean_shap_cols,\n",
    "#             # columns=[f'SHAP_{col}' for col in X_test.columns],\n",
    "#             index=X_test.index\n",
    "#         ).reset_index().rename(columns={'index': 'Date'})\n",
    "# \n",
    "#         # Merge SHAP values with predictions\n",
    "#         preds_df = preds_df.merge(shap_df, on='Date', how='left')\n",
    "# \n",
    "#         all_predictions.append(preds_df)\n",
    "# \n",
    "#         # Advance the window\n",
    "#         year += retrain_frequency\n",
    "#         print(f\"Window processed in {time.time() - start_time:.2f} seconds\")\n",
    "# \n",
    "# # Concatenate and save all predictions and SHAP values\n",
    "# final_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "# final_predictions_df.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n",
    "# \n",
    "# print(\"Stage 1 completed and data saved for Stage 2.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-05T15:29:36.266588Z",
     "start_time": "2025-08-05T13:52:39.167890Z"
    }
   },
   "id": "8f0500c59fdc3167",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP importances for ETF: XLB\n",
      "Computing SHAP importances for ETF: XLE\n",
      "Computing SHAP importances for ETF: XLF\n",
      "Computing SHAP importances for ETF: XLI\n",
      "Computing SHAP importances for ETF: XLK\n",
      "Computing SHAP importances for ETF: XLP\n",
      "Computing SHAP importances for ETF: XLY\n",
      "Computing SHAP importances for ETF: XLV\n",
      "Computing SHAP importances for ETF: XLU\n",
      "\n",
      "==== Training models for ETF: XLB ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000441  RMSE: 0.021000  MAE: 0.016324  R²: 0.017159  DirAcc: 58.73%\n",
      "Window processed in 43.31 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000265  RMSE: 0.016285  MAE: 0.012467  R²: -0.085798  DirAcc: 44.44%\n",
      "Window processed in 47.58 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000411  RMSE: 0.020278  MAE: 0.014794  R²: -0.077767  DirAcc: 42.86%\n",
      "Window processed in 47.08 seconds\n",
      "\n",
      "==== Training models for ETF: XLE ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000487  RMSE: 0.022059  MAE: 0.016722  R²: -0.001068  DirAcc: 55.95%\n",
      "Window processed in 51.32 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000221  RMSE: 0.014871  MAE: 0.010866  R²: -0.031714  DirAcc: 44.84%\n",
      "Window processed in 46.26 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000410  RMSE: 0.020255  MAE: 0.014883  R²: -0.027575  DirAcc: 57.94%\n",
      "Window processed in 48.27 seconds\n",
      "\n",
      "==== Training models for ETF: XLF ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.001707  RMSE: 0.041316  MAE: 0.028653  R²: -0.026921  DirAcc: 48.81%\n",
      "Window processed in 47.80 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000263  RMSE: 0.016215  MAE: 0.012079  R²: -0.025583  DirAcc: 52.38%\n",
      "Window processed in 52.19 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000468  RMSE: 0.021633  MAE: 0.014992  R²: -0.066905  DirAcc: 51.19%\n",
      "Window processed in 42.97 seconds\n",
      "\n",
      "==== Training models for ETF: XLI ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000446  RMSE: 0.021117  MAE: 0.015802  R²: -0.049967  DirAcc: 54.37%\n",
      "Window processed in 44.30 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000194  RMSE: 0.013942  MAE: 0.009992  R²: -0.015928  DirAcc: 51.59%\n",
      "Window processed in 41.35 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000322  RMSE: 0.017942  MAE: 0.013186  R²: -0.088295  DirAcc: 53.17%\n",
      "Window processed in 41.58 seconds\n",
      "\n",
      "==== Training models for ETF: XLK ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000262  RMSE: 0.016190  MAE: 0.011832  R²: -0.017439  DirAcc: 54.37%\n",
      "Window processed in 43.45 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000146  RMSE: 0.012095  MAE: 0.008756  R²: -0.059946  DirAcc: 48.41%\n",
      "Window processed in 41.88 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000216  RMSE: 0.014700  MAE: 0.010658  R²: -0.070255  DirAcc: 49.60%\n",
      "Window processed in 41.47 seconds\n",
      "\n",
      "==== Training models for ETF: XLP ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000127  RMSE: 0.011253  MAE: 0.008338  R²: -0.068139  DirAcc: 57.14%\n",
      "Window processed in 42.99 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000063  RMSE: 0.007913  MAE: 0.006022  R²: -0.061913  DirAcc: 44.05%\n",
      "Window processed in 54.93 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000091  RMSE: 0.009527  MAE: 0.006977  R²: -0.049667  DirAcc: 51.59%\n",
      "Window processed in 41.87 seconds\n",
      "\n",
      "==== Training models for ETF: XLY ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000505  RMSE: 0.022480  MAE: 0.017280  R²: -0.325976  DirAcc: 52.38%\n",
      "Window processed in 43.30 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000173  RMSE: 0.013152  MAE: 0.009659  R²: -0.023155  DirAcc: 50.40%\n",
      "Window processed in 49.47 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000247  RMSE: 0.015717  MAE: 0.011463  R²: -0.082154  DirAcc: 48.02%\n",
      "Window processed in 44.69 seconds\n",
      "\n",
      "==== Training models for ETF: XLV ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000167  RMSE: 0.012937  MAE: 0.009394  R²: -0.054165  DirAcc: 57.54%\n",
      "Window processed in 42.91 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000090  RMSE: 0.009495  MAE: 0.007122  R²: -0.025818  DirAcc: 45.24%\n",
      "Window processed in 43.05 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000163  RMSE: 0.012785  MAE: 0.008842  R²: -0.067397  DirAcc: 48.81%\n",
      "Window processed in 42.82 seconds\n",
      "\n",
      "==== Training models for ETF: XLU ====\n",
      "\n",
      "Training window starting 2009\n",
      "MSE: 0.000171  RMSE: 0.013087  MAE: 0.009956  R²: -0.050241  DirAcc: 54.37%\n",
      "Window processed in 41.33 seconds\n",
      "\n",
      "Training window starting 2010\n",
      "MSE: 0.000092  RMSE: 0.009609  MAE: 0.007235  R²: -0.018232  DirAcc: 45.63%\n",
      "Window processed in 42.19 seconds\n",
      "\n",
      "Training window starting 2011\n",
      "MSE: 0.000132  RMSE: 0.011488  MAE: 0.008063  R²: -0.189267  DirAcc: 46.43%\n",
      "Window processed in 43.16 seconds\n",
      "Stage 1 completed and data saved for Stage 2.\n"
     ]
    }
   ],
   "source": [
    "# stage 1 training and prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import ta\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# 0. Load and align data\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 0. Load and align data\n",
    "# ------------------------------------------------------------------------\n",
    "factors = pd.read_csv(\"aligned_factors.csv\", index_col=0, parse_dates=True)\n",
    "returns = pd.read_csv(\"daily_returns_10ETFs.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align dates to ensure matching indices\n",
    "dates = factors.index.intersection(returns.index)\n",
    "factors = factors.loc[dates]\n",
    "returns = returns.loc[dates]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1. Compute technical indicators and lagged features per ETF\n",
    "# ------------------------------------------------------------------------\n",
    "all_tech_features = []\n",
    "\n",
    "for etf in returns.columns:\n",
    "    close = (1 + returns[etf]).cumprod()\n",
    "    tech_df = pd.DataFrame(index=returns.index)\n",
    "\n",
    "    # Selected indicators (others commented out to reduce noise)\n",
    "    tech_df[f'{etf}_SMA_5']   = ta.trend.sma_indicator(close, window=5)\n",
    "    tech_df[f'{etf}_EMA_12']  = ta.trend.ema_indicator(close, window=12)\n",
    "    tech_df[f'{etf}_RSI_7']   = ta.momentum.rsi(close, window=7)\n",
    "    tech_df[f'{etf}_MACD']    = ta.trend.macd_diff(close)\n",
    "    tech_df[f'{etf}_ATR']     = ta.volatility.average_true_range(\n",
    "        high=close * 1.01, low=close * 0.99, close=close, window=10\n",
    "    )\n",
    "    tech_df[f'{etf}_Vol_5']   = returns[etf].rolling(window=5).std()\n",
    "    tech_df[f'{etf}_Mom_3']   = returns[etf].rolling(window=3).mean()\n",
    "\n",
    "    # Lagged returns (shifted so only past information is used)\n",
    "    for lag in [1, 2, 3]:\n",
    "        tech_df[f'{etf}_LagRet_{lag}'] = returns[etf].shift(lag)\n",
    "\n",
    "    all_tech_features.append(tech_df)\n",
    "\n",
    "# Concatenate technical indicators for all ETFs\n",
    "technical_features = pd.concat(all_tech_features, axis=1)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. Create lagged factor features\n",
    "# ------------------------------------------------------------------------\n",
    "for factor in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']:\n",
    "    for lag in [1, 2, 3]:\n",
    "        factors[f'{factor}_lag_{lag}'] = factors[factor].shift(lag)\n",
    "\n",
    "# Drop rows with NA values arising from lagging\n",
    "factors = factors.dropna()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Combine factors, technical features, and VIX change\n",
    "# ------------------------------------------------------------------------\n",
    "features = pd.concat([factors, technical_features], axis=1).dropna()\n",
    "vix = pd.read_csv(\"VIX_History.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Align VIX to our feature dates and compute lagged change\n",
    "vix_aligned = vix['CLOSE'].reindex(features.index).ffill()\n",
    "features['VIX'] = vix_aligned.pct_change(fill_method=None).shift(1)\n",
    "features['VIX'] = features['VIX'].fillna(0)\n",
    "\n",
    "# Define the target: next-day return per ETF\n",
    "target_returns = returns.shift(-1).loc[features.index].dropna()\n",
    "features = features.loc[target_returns.index]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4. Define rolling window parameters\n",
    "# ------------------------------------------------------------------------\n",
    "train_years = 12      # years used for training\n",
    "valid_years = 1       # years used for validation\n",
    "test_years  = 1       # years used for testing/prediction\n",
    "retrain_frequency = 1 # years between retrainings\n",
    "start_year = 2009\n",
    "end_year   = 2024\n",
    "\n",
    "# List generic features used for SHAP importance ranking\n",
    "all_generic_features = [\n",
    "    'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA',\n",
    "    'Mkt-RF_lag_1', 'Mkt-RF_lag_2', 'Mkt-RF_lag_3',\n",
    "    'SMB_lag_1', 'SMB_lag_2', 'SMB_lag_3',\n",
    "    'HML_lag_1', 'HML_lag_2', 'HML_lag_3',\n",
    "    'RMW_lag_1', 'RMW_lag_2', 'RMW_lag_3',\n",
    "    'CMA_lag_1', 'CMA_lag_2', 'CMA_lag_3',\n",
    "    'SMA_5', 'EMA_12', 'RSI_7', 'MACD',\n",
    "    'Vol_5', 'Mom_3',\n",
    "    'LagRet_1', 'LagRet_2', 'LagRet_3', 'VIX'\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Compute generic feature importance via SHAP\n",
    "#    (aggregated across ETFs, using only the initial training window)\n",
    "# ------------------------------------------------------------------------\n",
    "shap_importances = pd.DataFrame(0.0, index=all_generic_features, columns=['SHAP_Value'])\n",
    "\n",
    "# Use a fixed period (e.g. up to year 2009) for computing importances\n",
    "base_train_start = pd.Timestamp(start_year - train_years, 1, 1)\n",
    "base_train_end   = pd.Timestamp(start_year - valid_years - 1, 12, 31)\n",
    "\n",
    "for etf in returns.columns:\n",
    "    print(f\"Computing SHAP importances for ETF: {etf}\")\n",
    "    # Filter columns relevant to this ETF (generic + factor features)\n",
    "    etf_cols = [\n",
    "        col for col in features.columns\n",
    "        if (etf in col and any(k in col for k in ['SMA_5', 'EMA_12', 'RSI_7',\n",
    "                                                  'MACD', 'Vol_5', 'Mom_3',\n",
    "                                                  'LagRet_1','LagRet_2','LagRet_3', 'VIX']))\n",
    "        or col in ['Mkt-RF','SMB','HML','RMW','CMA',\n",
    "                   'Mkt-RF_lag_1','Mkt-RF_lag_2','Mkt-RF_lag_3',\n",
    "                   'SMB_lag_1','SMB_lag_2','SMB_lag_3',\n",
    "                   'HML_lag_1','HML_lag_2','HML_lag_3',\n",
    "                   'RMW_lag_1','RMW_lag_2','RMW_lag_3',\n",
    "                   'CMA_lag_1','CMA_lag_2','CMA_lag_3']\n",
    "    ]\n",
    "    X_base  = features.loc[base_train_start:base_train_end, etf_cols]\n",
    "    y_base  = target_returns[etf].loc[base_train_start:base_train_end]\n",
    "\n",
    "    # Fit a quick model to compute SHAP\n",
    "    model_base = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        # random_state=GLOBAL_SEED,\n",
    "        # seed=GLOBAL_SEED,\n",
    "        device='cuda'\n",
    "    ).fit(X_base, y_base)\n",
    "\n",
    "    explainer_base = shap.Explainer(model_base)\n",
    "    shap_vals = explainer_base(X_base)\n",
    "\n",
    "    # Aggregate SHAP values per generic feature\n",
    "    for gen_feat in all_generic_features:\n",
    "        cols = [c for c in X_base.columns if gen_feat in c]\n",
    "        if cols:\n",
    "            idx = [X_base.columns.get_loc(c) for c in cols]\n",
    "            shap_importances.loc[gen_feat] += np.mean(np.abs(shap_vals.values[:, idx]))\n",
    "\n",
    "# Average importance across ETFs and select top N\n",
    "shap_importances /= len(returns.columns)\n",
    "top_generic_features = (\n",
    "    shap_importances.sort_values('SHAP_Value', ascending=False)\n",
    "                    .head(10)\n",
    "                    .index\n",
    "                    .tolist()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6. Retrain models using the selected generic features in rolling windows\n",
    "# ------------------------------------------------------------------------\n",
    "all_predictions = []\n",
    "\n",
    "for etf in returns.columns:\n",
    "    print(f\"\\n==== Training models for ETF: {etf} ====\")\n",
    "    # Select columns containing any of the top_generic_features or factor names\n",
    "    selected_features = [\n",
    "        f for f in features.columns\n",
    "        if any(gen in f for gen in top_generic_features) or f in factors.columns\n",
    "    ]\n",
    "\n",
    "    year = start_year\n",
    "    while year <= end_year - test_years + 1:\n",
    "        print(f\"\\nTraining window starting {year}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Define periods\n",
    "        train_start = pd.Timestamp(year - train_years, 1, 1)\n",
    "        train_end   = pd.Timestamp(year - valid_years - 1, 12, 31)\n",
    "        valid_start = pd.Timestamp(year - valid_years, 1, 1)\n",
    "        valid_end   = pd.Timestamp(year - 1, 12, 31)\n",
    "        test_start  = pd.Timestamp(year, 1, 1)\n",
    "        test_end    = pd.Timestamp(year + test_years - 1, 12, 31)\n",
    "\n",
    "        # Extract data\n",
    "        X_train = features.loc[train_start:train_end, selected_features]\n",
    "        y_train = target_returns[etf].loc[train_start:train_end]\n",
    "        X_valid = features.loc[valid_start:valid_end, selected_features]\n",
    "        y_valid = target_returns[etf].loc[valid_start:valid_end]\n",
    "        X_test  = features.loc[test_start:test_end, selected_features]\n",
    "        y_test  = target_returns[etf].loc[test_start:test_end]\n",
    "\n",
    "        # Base model with early stopping\n",
    "        base_model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            tree_method='hist',\n",
    "            random_state=42,\n",
    "            # random_state=GLOBAL_SEED,\n",
    "            # seed=GLOBAL_SEED,\n",
    "            n_jobs=4\n",
    "        )\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [200, 400],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.03, 0.05],\n",
    "            'subsample': [0.7, 0.8],\n",
    "            'colsample_bytree': [0.7, 0.8]\n",
    "        }\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            param_grid,\n",
    "            cv=tscv,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=4\n",
    "        )\n",
    "\n",
    "        # Fit with early stopping on the explicit validation set\n",
    "        grid_search.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            # eval_metric='rmse',\n",
    "            # early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predict on the test period\n",
    "        preds = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        mse  = mean_squared_error(y_test, preds)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae  = mean_absolute_error(y_test, preds)\n",
    "        r2   = r2_score(y_test, preds)\n",
    "        dir_acc = np.mean((np.sign(y_test) == np.sign(preds)).astype(int))\n",
    "\n",
    "        print(f\"MSE: {mse:.6f}  RMSE: {rmse:.6f}  MAE: {mae:.6f}  \"\n",
    "              f\"R²: {r2:.6f}  DirAcc: {dir_acc:.2%}\")\n",
    "\n",
    "        # Save the model for reproducibility\n",
    "        joblib.dump(best_model, f\"best_model_{etf}_{year}.joblib\")\n",
    "\n",
    "        # Save predictions\n",
    "        preds_df = pd.DataFrame({\n",
    "            'Date': X_test.index,\n",
    "            'ETF': etf,\n",
    "            'Year': year,\n",
    "            'Actual_Return': y_test,\n",
    "            'Predicted_Return': preds\n",
    "        }).reset_index(drop=True)\n",
    "\n",
    "        # Compute SHAP values on the test set\n",
    "        explainer_test = shap.Explainer(best_model)\n",
    "        shap_vals_test = explainer_test(X_test)\n",
    "\n",
    "        shap_df = pd.DataFrame(\n",
    "            shap_vals_test.values,\n",
    "            columns=[f'SHAP_{col}' for col in X_test.columns],\n",
    "            index=X_test.index\n",
    "        ).reset_index().rename(columns={'index': 'Date'})\n",
    "\n",
    "        # Merge SHAP values with predictions\n",
    "        preds_df = preds_df.merge(shap_df, on='Date', how='left')\n",
    "\n",
    "        all_predictions.append(preds_df)\n",
    "\n",
    "        # Advance the window\n",
    "        year += retrain_frequency\n",
    "        print(f\"Window processed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Concatenate and save all predictions and SHAP values\n",
    "final_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "final_predictions_df.to_csv(\"stage1_predictions_with_shap_10ETFs.csv\", index=False)\n",
    "\n",
    "print(\"Stage 1 completed and data saved for Stage 2.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-08T03:40:21.886866Z",
     "start_time": "2025-08-08T03:19:32.146222Z"
    }
   },
   "id": "c449d0418b87114f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46b46b2e610dc12b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea958cf59209ccad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "returns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc45fc95e8410dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a1973a72e42310b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Vol_5',\n 'SMB_lag_2',\n 'Mom_3',\n 'HML_lag_2',\n 'SMA_5',\n 'LagRet_1',\n 'EMA_12',\n 'SMB',\n 'RSI_7',\n 'CMA_lag_1']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_generic_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-08T03:42:46.831350Z",
     "start_time": "2025-08-08T03:42:46.818347Z"
    }
   },
   "id": "6efb3e1a4faf0b68",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame shape: (752, 60)\n",
      "Aggregated DataFrame summary stats:\n",
      "                          count                 mean                  min  \\\n",
      "Date                        752  2010-07-06 01:30:00  2009-01-08 00:00:00   \n",
      "Predicted_Return_XLB      752.0            -0.000014            -0.018909   \n",
      "Actual_Return_XLB         752.0             0.000665            -0.073135   \n",
      "Volatility_XLB            752.0             0.017153             0.001524   \n",
      "Predicted_Return_XLE      752.0             0.000207            -0.026809   \n",
      "Actual_Return_XLE         752.0             0.000642             -0.08506   \n",
      "Volatility_XLE            752.0             0.016898             0.002602   \n",
      "Predicted_Return_XLF      752.0             0.003816            -0.017859   \n",
      "Actual_Return_XLF         752.0             0.000537            -0.165289   \n",
      "Volatility_XLF            752.0             0.022012             0.001018   \n",
      "Predicted_Return_XLI      752.0             0.001175            -0.024231   \n",
      "Actual_Return_XLI         752.0             0.000648            -0.070529   \n",
      "Volatility_XLI            752.0              0.01515             0.001405   \n",
      "Predicted_Return_XLK      752.0             0.001459            -0.012265   \n",
      "Actual_Return_XLK         752.0             0.000744            -0.056309   \n",
      "Volatility_XLK            752.0             0.012369             0.000897   \n",
      "Predicted_Return_XLP      752.0             0.000656            -0.007804   \n",
      "Actual_Return_XLP         752.0             0.000479            -0.038331   \n",
      "Volatility_XLP            752.0             0.008318             0.001594   \n",
      "Predicted_Return_XLY      752.0             0.003969            -0.027415   \n",
      "Actual_Return_XLY         752.0             0.000894            -0.062741   \n",
      "Volatility_XLY            752.0             0.014107             0.001256   \n",
      "Predicted_Return_XLV      752.0             0.000246            -0.024764   \n",
      "Actual_Return_XLV         752.0             0.000446            -0.051242   \n",
      "Volatility_XLV            752.0             0.010111             0.001581   \n",
      "Predicted_Return_XLU      752.0             0.000415            -0.019279   \n",
      "Actual_Return_XLU         752.0              0.00031            -0.052995   \n",
      "Volatility_XLU            752.0             0.009766             0.000867   \n",
      "Avg_SHAP_Vol_5            752.0             0.000038            -0.000718   \n",
      "Std_SHAP_Vol_5            752.0             0.000156             0.000054   \n",
      "Avg_SHAP_SMB_lag_2        752.0             0.000005            -0.004397   \n",
      "Std_SHAP_SMB_lag_2        752.0             0.000235             0.000048   \n",
      "Avg_SHAP_Mom_3            752.0             0.000006            -0.001067   \n",
      "Std_SHAP_Mom_3            752.0             0.000171              0.00004   \n",
      "Avg_SHAP_HML_lag_2        752.0            -0.000022            -0.001002   \n",
      "Std_SHAP_HML_lag_2        752.0             0.000409             0.000074   \n",
      "Avg_SHAP_SMA_5            752.0             0.000047            -0.000172   \n",
      "Std_SHAP_SMA_5            752.0             0.000241             0.000079   \n",
      "Avg_SHAP_LagRet_1         752.0             0.000003             -0.00039   \n",
      "Std_SHAP_LagRet_1         752.0             0.000148             0.000042   \n",
      "Avg_SHAP_EMA_12           752.0             0.000049            -0.000137   \n",
      "Std_SHAP_EMA_12           752.0             0.000189             0.000078   \n",
      "Avg_SHAP_SMB              752.0            -0.000021            -0.000431   \n",
      "Std_SHAP_SMB              752.0             0.000196             0.000028   \n",
      "Avg_SHAP_RSI_7            752.0                 -0.0            -0.000382   \n",
      "Std_SHAP_RSI_7            752.0             0.000122             0.000038   \n",
      "Avg_SHAP_CMA_lag_1        752.0             0.000026            -0.000409   \n",
      "Std_SHAP_CMA_lag_1        752.0             0.000115             0.000028   \n",
      "CrossSec_Mean_PredRet     752.0             0.001325            -0.013837   \n",
      "CrossSec_Std_PredRet      752.0             0.002852             0.000309   \n",
      "CrossSec_Mean_Volatility  752.0             0.013987             0.002731   \n",
      "Rank_PredRet_XLB          752.0             0.456856             0.111111   \n",
      "Rank_PredRet_XLE          752.0             0.506944             0.111111   \n",
      "Rank_PredRet_XLF          752.0             0.715426             0.111111   \n",
      "Rank_PredRet_XLI          752.0             0.532949             0.111111   \n",
      "Rank_PredRet_XLK          752.0             0.583629             0.111111   \n",
      "Rank_PredRet_XLP          752.0             0.497784             0.111111   \n",
      "Rank_PredRet_XLY          752.0              0.71779             0.111111   \n",
      "Rank_PredRet_XLV          752.0             0.468824             0.111111   \n",
      "Rank_PredRet_XLU          752.0             0.519799             0.111111   \n",
      "\n",
      "                                          25%                  50%  \\\n",
      "Date                      2009-10-06 18:00:00  2010-07-07 12:00:00   \n",
      "Predicted_Return_XLB                -0.002084             0.000083   \n",
      "Actual_Return_XLB                   -0.009983               0.0015   \n",
      "Volatility_XLB                       0.011015             0.015545   \n",
      "Predicted_Return_XLE                -0.001158             0.000171   \n",
      "Actual_Return_XLE                   -0.009058             0.000682   \n",
      "Volatility_XLE                       0.010583             0.014449   \n",
      "Predicted_Return_XLF                -0.000591             0.001806   \n",
      "Actual_Return_XLF                   -0.010683             0.000293   \n",
      "Volatility_XLF                       0.010557             0.016034   \n",
      "Predicted_Return_XLI                -0.001422             0.000337   \n",
      "Actual_Return_XLI                   -0.008061             0.001094   \n",
      "Volatility_XLI                       0.009172             0.013415   \n",
      "Predicted_Return_XLK                -0.000732             0.000426   \n",
      "Actual_Return_XLK                   -0.005367             0.001578   \n",
      "Volatility_XLK                       0.007045             0.011321   \n",
      "Predicted_Return_XLP                -0.001107              0.00013   \n",
      "Actual_Return_XLP                   -0.004576             0.001085   \n",
      "Volatility_XLP                       0.004805              0.00713   \n",
      "Predicted_Return_XLY                -0.000716             0.001409   \n",
      "Actual_Return_XLY                   -0.006942             0.001219   \n",
      "Volatility_XLY                        0.00812             0.012028   \n",
      "Predicted_Return_XLV                -0.000934            -0.000179   \n",
      "Actual_Return_XLV                   -0.005091             0.000649   \n",
      "Volatility_XLV                        0.00614             0.008895   \n",
      "Predicted_Return_XLU                -0.000549             0.000076   \n",
      "Actual_Return_XLU                   -0.005693             0.000489   \n",
      "Volatility_XLU                       0.006365             0.008899   \n",
      "Avg_SHAP_Vol_5                       0.000015             0.000032   \n",
      "Std_SHAP_Vol_5                       0.000094              0.00012   \n",
      "Avg_SHAP_SMB_lag_2                   -0.00007            -0.000036   \n",
      "Std_SHAP_SMB_lag_2                   0.000099             0.000149   \n",
      "Avg_SHAP_Mom_3                      -0.000011            -0.000004   \n",
      "Std_SHAP_Mom_3                       0.000072             0.000103   \n",
      "Avg_SHAP_HML_lag_2                  -0.000279            -0.000015   \n",
      "Std_SHAP_HML_lag_2                   0.000148             0.000232   \n",
      "Avg_SHAP_SMA_5                      -0.000052            -0.000027   \n",
      "Std_SHAP_SMA_5                       0.000139             0.000173   \n",
      "Avg_SHAP_LagRet_1                   -0.000021            -0.000006   \n",
      "Std_SHAP_LagRet_1                    0.000066             0.000097   \n",
      "Avg_SHAP_EMA_12                     -0.000045            -0.000005   \n",
      "Std_SHAP_EMA_12                      0.000115             0.000142   \n",
      "Avg_SHAP_SMB                        -0.000061            -0.000024   \n",
      "Std_SHAP_SMB                         0.000075             0.000124   \n",
      "Avg_SHAP_RSI_7                      -0.000028            -0.000015   \n",
      "Std_SHAP_RSI_7                       0.000072             0.000094   \n",
      "Avg_SHAP_CMA_lag_1                   0.000003             0.000041   \n",
      "Std_SHAP_CMA_lag_1                   0.000069             0.000087   \n",
      "CrossSec_Mean_PredRet               -0.000656             0.000264   \n",
      "CrossSec_Std_PredRet                 0.001301             0.001974   \n",
      "CrossSec_Mean_Volatility             0.008734             0.011925   \n",
      "Rank_PredRet_XLB                     0.222222             0.444444   \n",
      "Rank_PredRet_XLE                     0.222222             0.444444   \n",
      "Rank_PredRet_XLF                     0.444444             0.888889   \n",
      "Rank_PredRet_XLI                     0.222222             0.555556   \n",
      "Rank_PredRet_XLK                     0.333333             0.611111   \n",
      "Rank_PredRet_XLP                     0.333333             0.444444   \n",
      "Rank_PredRet_XLY                     0.444444             0.777778   \n",
      "Rank_PredRet_XLV                     0.222222             0.444444   \n",
      "Rank_PredRet_XLU                     0.333333             0.555556   \n",
      "\n",
      "                                          75%                  max       std  \n",
      "Date                      2011-04-04 06:00:00  2011-12-30 00:00:00       NaN  \n",
      "Predicted_Return_XLB                 0.001553              0.01726  0.003463  \n",
      "Actual_Return_XLB                    0.011742             0.061616  0.018962  \n",
      "Volatility_XLB                       0.022139             0.056534  0.008535  \n",
      "Predicted_Return_XLE                 0.001801             0.020099  0.003412  \n",
      "Actual_Return_XLE                    0.010892             0.082326  0.019119  \n",
      "Volatility_XLE                       0.021613             0.058628  0.009273  \n",
      "Predicted_Return_XLF                 0.008275             0.032035  0.006447  \n",
      "Actual_Return_XLF                    0.011463             0.164619  0.028058  \n",
      "Volatility_XLF                       0.027209             0.115807  0.018583  \n",
      "Predicted_Return_XLI                 0.004439             0.021336  0.004124  \n",
      "Actual_Return_XLI                    0.009574             0.075521  0.017394  \n",
      "Volatility_XLI                       0.019509             0.056266  0.008706  \n",
      "Predicted_Return_XLK                 0.002917             0.027455  0.004378  \n",
      "Actual_Return_XLK                    0.008136             0.059176  0.014098  \n",
      "Volatility_XLK                       0.016153             0.045542  0.007196  \n",
      "Predicted_Return_XLP                 0.002063             0.014018  0.002808  \n",
      "Actual_Return_XLP                    0.005689             0.043753  0.009374  \n",
      "Volatility_XLP                        0.01079             0.033751  0.004864  \n",
      "Predicted_Return_XLY                 0.009082             0.024855  0.006704  \n",
      "Actual_Return_XLY                    0.009322              0.07062  0.016087  \n",
      "Volatility_XLY                       0.018435             0.050043  0.008255  \n",
      "Predicted_Return_XLV                 0.000669              0.02073  0.002961  \n",
      "Actual_Return_XLV                    0.006977             0.048967  0.011561  \n",
      "Volatility_XLV                       0.012087             0.044507  0.005769  \n",
      "Predicted_Return_XLU                 0.001105             0.016298  0.002568  \n",
      "Actual_Return_XLU                    0.006795             0.042157  0.011034  \n",
      "Volatility_XLU                       0.012145             0.038924  0.005038  \n",
      "Avg_SHAP_Vol_5                       0.000051             0.000316  0.000068  \n",
      "Std_SHAP_Vol_5                       0.000166             0.001423  0.000129  \n",
      "Avg_SHAP_SMB_lag_2                    0.00006             0.001201   0.00026  \n",
      "Std_SHAP_SMB_lag_2                    0.00029             0.004378  0.000253  \n",
      "Avg_SHAP_Mom_3                       0.000008             0.000439  0.000071  \n",
      "Std_SHAP_Mom_3                       0.000189             0.002384  0.000186  \n",
      "Avg_SHAP_HML_lag_2                    0.00011             0.002186  0.000427  \n",
      "Std_SHAP_HML_lag_2                   0.000447             0.004697  0.000548  \n",
      "Avg_SHAP_SMA_5                       0.000213             0.000477   0.00014  \n",
      "Std_SHAP_SMA_5                       0.000354             0.000752  0.000132  \n",
      "Avg_SHAP_LagRet_1                    0.000011             0.001509   0.00009  \n",
      "Std_SHAP_LagRet_1                     0.00016             0.002033  0.000169  \n",
      "Avg_SHAP_EMA_12                      0.000182             0.000365  0.000116  \n",
      "Std_SHAP_EMA_12                      0.000272             0.000533  0.000099  \n",
      "Avg_SHAP_SMB                         0.000012             0.001999  0.000113  \n",
      "Std_SHAP_SMB                         0.000248             0.002089  0.000214  \n",
      "Avg_SHAP_RSI_7                        0.00001             0.000287  0.000056  \n",
      "Std_SHAP_RSI_7                       0.000137             0.001057  0.000101  \n",
      "Avg_SHAP_CMA_lag_1                   0.000061             0.000363  0.000065  \n",
      "Std_SHAP_CMA_lag_1                   0.000119             0.000994  0.000095  \n",
      "CrossSec_Mean_PredRet                0.003662             0.012648  0.003183  \n",
      "CrossSec_Std_PredRet                 0.004282             0.011438  0.001999  \n",
      "CrossSec_Mean_Volatility              0.01793             0.051012  0.007613  \n",
      "Rank_PredRet_XLB                     0.666667                  1.0  0.291998  \n",
      "Rank_PredRet_XLE                     0.777778                  1.0  0.307957  \n",
      "Rank_PredRet_XLF                          1.0                  1.0  0.291281  \n",
      "Rank_PredRet_XLI                     0.777778                  1.0  0.279198  \n",
      "Rank_PredRet_XLK                     0.777778                  1.0   0.26201  \n",
      "Rank_PredRet_XLP                     0.666667                  1.0  0.228125  \n",
      "Rank_PredRet_XLY                          1.0                  1.0  0.285858  \n",
      "Rank_PredRet_XLV                     0.666667                  1.0  0.250947  \n",
      "Rank_PredRet_XLU                     0.666667                  1.0   0.23649  \n",
      "Optimized Stage 2 RL dataset successfully saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load stage 1 predictions with SHAP values explicitly\n",
    "stage1_df = pd.read_csv(\"stage1_predictions_with_shap_10ETFs.csv\", parse_dates=['Date'])\n",
    "etfs = stage1_df['ETF'].unique()\n",
    "\n",
    "# Initialize DataFrame explicitly for aggregated daily data\n",
    "dates = sorted(stage1_df['Date'].unique())\n",
    "aggregated_data = pd.DataFrame({'Date': dates})\n",
    "\n",
    "# Pivot tables for efficient cross-sectional computations\n",
    "predicted_returns = stage1_df.pivot(index='Date', columns='ETF', values='Predicted_Return')\n",
    "actual_returns = stage1_df.pivot(index='Date', columns='ETF', values='Actual_Return')\n",
    "\n",
    "# Compute ETF-specific volatility (rolling 5-day window)\n",
    "volatility = actual_returns.rolling(window=5).std()\n",
    "\n",
    "# Merge explicitly into aggregated_data\n",
    "for etf in etfs:\n",
    "    aggregated_data[f'Predicted_Return_{etf}'] = aggregated_data['Date'].map(predicted_returns[etf])\n",
    "    aggregated_data[f'Actual_Return_{etf}'] = aggregated_data['Date'].map(actual_returns[etf])\n",
    "    aggregated_data[f'Volatility_{etf}'] = aggregated_data['Date'].map(volatility[etf])\n",
    "\n",
    "# Dynamically load the top generic features from Stage 1 explicitly to maintain consistency\n",
    "# generic_shap_features = ['LagRet_1',\n",
    "#  'HML_lag_2',\n",
    "#  'LagRet_2',\n",
    "#  'Vol_5',\n",
    "#  'Mom_3',\n",
    "#  'LagRet_3',\n",
    "#  'SMB_lag_2',\n",
    "#  'MACD',\n",
    "#  'Mkt-RF',\n",
    "#  'HML']\n",
    "generic_shap_features = top_generic_features\n",
    "\n",
    "# Aggregate SHAP values (mean and std across ETFs) explicitly by generic feature\n",
    "shap_aggregated_features = {}\n",
    "\n",
    "for feature in generic_shap_features:\n",
    "    matching_cols = [col for col in stage1_df.columns \n",
    "                     if col.startswith('SHAP_') and col.endswith(feature)]\n",
    "\n",
    "    if matching_cols:\n",
    "        shap_means = stage1_df.groupby('Date')[matching_cols].mean().mean(axis=1)\n",
    "        shap_stds = stage1_df.groupby('Date')[matching_cols].std().mean(axis=1)\n",
    "\n",
    "        shap_aggregated_features[f'Avg_SHAP_{feature}'] = shap_means\n",
    "        shap_aggregated_features[f'Std_SHAP_{feature}'] = shap_stds\n",
    "    else:\n",
    "        print(f\"Warning: No matches found for SHAP feature: {feature}\")\n",
    "\n",
    "# Convert aggregated SHAP features explicitly to DataFrame\n",
    "shap_aggregated_df = pd.DataFrame(shap_aggregated_features).reset_index()\n",
    "\n",
    "# Merge aggregated SHAP features explicitly\n",
    "aggregated_data = pd.merge(aggregated_data, shap_aggregated_df, on='Date', how='left')\n",
    "\n",
    "# Explicitly compute additional cross-sectional signals for richer Stage 2 observations\n",
    "# Cross-sectional mean and std of predicted returns\n",
    "aggregated_data['CrossSec_Mean_PredRet'] = predicted_returns.mean(axis=1).values\n",
    "aggregated_data['CrossSec_Std_PredRet'] = predicted_returns.std(axis=1).values\n",
    "\n",
    "# Cross-sectional mean volatility\n",
    "aggregated_data['CrossSec_Mean_Volatility'] = volatility.mean(axis=1).values\n",
    "\n",
    "# Rank ETFs by predicted return explicitly (percentile ranks)\n",
    "ranked_preds = predicted_returns.rank(axis=1, pct=True)\n",
    "for etf in etfs:\n",
    "    aggregated_data[f'Rank_PredRet_{etf}'] = aggregated_data['Date'].map(ranked_preds[etf])\n",
    "\n",
    "# Handle missing values explicitly and robustly:\n",
    "# Forward-fill only SHAP and cross-sectional features explicitly\n",
    "shap_and_crosssec_cols = [col for col in aggregated_data.columns if 'SHAP' in col or 'CrossSec' in col]\n",
    "aggregated_data[shap_and_crosssec_cols] = aggregated_data[shap_and_crosssec_cols].ffill()\n",
    "\n",
    "# Drop rows explicitly where ETF volatility calculations have initial NaNs\n",
    "vol_cols = [f'Volatility_{etf}' for etf in etfs]\n",
    "aggregated_data.dropna(subset=vol_cols, inplace=True)\n",
    "\n",
    "# Final sanity checks explicitly for data quality assurance\n",
    "if aggregated_data.empty:\n",
    "    raise ValueError(\"Aggregated dataset is empty after preprocessing. Verify your input data.\")\n",
    "else:\n",
    "    # Quick summary statistics explicitly for diagnostics\n",
    "    print(\"Aggregated DataFrame shape:\", aggregated_data.shape)\n",
    "    print(\"Aggregated DataFrame summary stats:\")\n",
    "    print(aggregated_data.describe().transpose())\n",
    "\n",
    "    # Save optimized data explicitly for Stage 2\n",
    "    aggregated_data.to_csv(\"stage2_rl_observations_optimized_10ETFs.csv\", index=False)\n",
    "    print(\"Optimized Stage 2 RL dataset successfully saved.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-08T03:43:15.464521Z",
     "start_time": "2025-08-08T03:43:15.143448Z"
    }
   },
   "id": "626373434f64d0c4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f3f0813e659ead",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting iteration 1/2 (Seed: 42) at 2025-08-08 00:07:24\n",
      "  - Starting window 1/8 at 2025-08-08 00:07:24\n",
      "triam new model and saved under stage2_iterations\\iteration_00\\window_00\\best_ppo.zip\n",
      "  - Completed window 1/8 in 22.17 minutes.\n",
      "  - Starting window 2/8 at 2025-08-08 00:29:35\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_00\\best_ppo.zip and retrain\n",
      "  - Completed window 2/8 in 5.52 minutes.\n",
      "  - Starting window 3/8 at 2025-08-08 00:35:06\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_01\\best_ppo.zip and retrain\n",
      "  - Completed window 3/8 in 4.08 minutes.\n",
      "  - Starting window 4/8 at 2025-08-08 00:39:11\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_02\\best_ppo.zip and retrain\n",
      "  - Completed window 4/8 in 4.99 minutes.\n",
      "  - Starting window 5/8 at 2025-08-08 00:44:10\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_03\\best_ppo.zip and retrain\n",
      "  - Completed window 5/8 in 4.05 minutes.\n",
      "  - Starting window 6/8 at 2025-08-08 00:48:14\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_04\\best_ppo.zip and retrain\n",
      "  - Completed window 6/8 in 4.01 minutes.\n",
      "  - Starting window 7/8 at 2025-08-08 00:52:14\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_05\\best_ppo.zip and retrain\n",
      "  - Completed window 7/8 in 3.93 minutes.\n",
      "  - Starting window 8/8 at 2025-08-08 00:56:10\n",
      "load the exising model from stage2_iterations\\iteration_00\\window_06\\best_ppo.zip and retrain\n",
      "  - Completed window 8/8 in 4.92 minutes.\n",
      "\n",
      "Starting iteration 2/2 (Seed: 43) at 2025-08-08 01:01:05\n",
      "  - Starting window 1/8 at 2025-08-08 01:01:05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 569\u001B[0m\n\u001B[0;32m    567\u001B[0m \u001B[38;5;66;03m# Explicit seed handling\u001B[39;00m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 569\u001B[0m     best_params \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_and_tune\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    570\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metf_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miter_seed\u001B[49m\n\u001B[0;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    573\u001B[0m     \u001B[38;5;66;03m# Fetch tuned seed explicitly from best_params\u001B[39;00m\n\u001B[0;32m    574\u001B[0m     tuned_seed \u001B[38;5;241m=\u001B[39m best_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m'\u001B[39m, iter_seed)\n",
      "Cell \u001B[1;32mIn[4], line 312\u001B[0m, in \u001B[0;36mvalidate_and_tune\u001B[1;34m(train_data, val_data, etf_list, cfg, random_seed)\u001B[0m\n\u001B[0;32m    302\u001B[0m env \u001B[38;5;241m=\u001B[39m make_vec_env(\u001B[38;5;28;01mlambda\u001B[39;00m: PortfolioEnv(\n\u001B[0;32m    303\u001B[0m     train_data, etf_list, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_cvar\u001B[39m\u001B[38;5;124m'\u001B[39m, risk_coeff,\n\u001B[0;32m    304\u001B[0m     cfg\u001B[38;5;241m.\u001B[39mrebalance_period, cfg\u001B[38;5;241m.\u001B[39mlookback_period,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    308\u001B[0m     lambda_hhi\u001B[38;5;241m=\u001B[39mlambda_hhi\n\u001B[0;32m    309\u001B[0m ), n_envs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, seed\u001B[38;5;241m=\u001B[39mseed)\n\u001B[0;32m    311\u001B[0m model \u001B[38;5;241m=\u001B[39m PPO(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m'\u001B[39m, env, ent_coef\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, clip_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, seed\u001B[38;5;241m=\u001B[39mseed, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 312\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtuning_timesteps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# Evaluate explicitly on validation set\u001B[39;00m\n\u001B[0;32m    315\u001B[0m val_env \u001B[38;5;241m=\u001B[39m PortfolioEnv(\n\u001B[0;32m    316\u001B[0m     val_data, etf_list, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_cvar\u001B[39m\u001B[38;5;124m'\u001B[39m, risk_coeff,\n\u001B[0;32m    317\u001B[0m     cfg\u001B[38;5;241m.\u001B[39mrebalance_period, cfg\u001B[38;5;241m.\u001B[39mlookback_period,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    321\u001B[0m     lambda_hhi\u001B[38;5;241m=\u001B[39mlambda_hhi\n\u001B[0;32m    322\u001B[0m )\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    304\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    309\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    310\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:337\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    334\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mep_info_buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    335\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdump_logs(iteration)\n\u001B[1;32m--> 337\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    339\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_end()\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:277\u001B[0m, in \u001B[0;36mPPO.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    275\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;66;03m# Clip grad norm\u001B[39;00m\n\u001B[1;32m--> 277\u001B[0m     \u001B[43mth\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclip_grad_norm_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_grad_norm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_updates \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:34\u001B[0m, in \u001B[0;36m_no_grad.<locals>._no_grad_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_no_grad_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 34\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:215\u001B[0m, in \u001B[0;36mclip_grad_norm_\u001B[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001B[0m\n\u001B[0;32m    213\u001B[0m     parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(parameters)\n\u001B[0;32m    214\u001B[0m grads \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m--> 215\u001B[0m total_norm \u001B[38;5;241m=\u001B[39m \u001B[43m_get_total_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_if_nonfinite\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforeach\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_norm\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:34\u001B[0m, in \u001B[0;36m_no_grad.<locals>._no_grad_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_no_grad_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 34\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\XAI\\RL_with_SHAP\\pythonProject1\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:87\u001B[0m, in \u001B[0;36m_get_total_norm\u001B[1;34m(tensors, norm_type, error_if_nonfinite, foreach)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (device, _), ([device_tensors], _) \u001B[38;5;129;01min\u001B[39;00m grouped_tensors\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (foreach \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m _has_foreach_support(device_tensors, device)) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m     85\u001B[0m         foreach \u001B[38;5;129;01mand\u001B[39;00m _device_has_foreach_support(device)\n\u001B[0;32m     86\u001B[0m     ):\n\u001B[1;32m---> 87\u001B[0m         norms\u001B[38;5;241m.\u001B[39mextend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_foreach_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm_type\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m foreach:\n\u001B[0;32m     89\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     90\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach=True was passed, but can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt use the foreach API on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;241m.\u001B[39mtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     91\u001B[0m         )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# fine tune to use change‑based actions\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "import time\n",
    "from gymnasium import spaces\n",
    "import gc\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration dataclass\n",
    "# ---------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    train_window_days: int = 252 * 7      # 10 years for training\n",
    "    validation_window_days: int = 252      # ~6 months for validation\n",
    "    prediction_window_days: int = 252      # ~6 months for prediction\n",
    "    lookback_period: int = 21              # lookback for observations\n",
    "    rebalance_period: int = 21             # rebalance every 10 days\n",
    "    n_iter_tuning: int = 20                # number of hyperparameter samples\n",
    "    tuning_timesteps: int = 10_000          # timesteps for each tune\n",
    "    incremental_timesteps: int = 10_000     # PPO training step size\n",
    "    max_timesteps: int = 50_000            # maximum PPO timesteps\n",
    "    patience: int = 3                      # early stopping patience\n",
    "    policy_arch: Tuple[int, int] = (256, 256)  # network architecture\n",
    "    num_iterations: int = 2                # number of outer iterations (seeds)\n",
    "    base_seed: int = 42                    # base random seed\n",
    "    default_risk_coeff: float = 0.5        # default risk coefficient\n",
    "    desired_long: float = 1.0       # Default no leverage, 100% allocation\n",
    "    desired_short: float = 0.0      # Default no short selling\n",
    "    weight_bounds: Tuple[float, float] = (0.0, 1.0)  # Default bounds [0,1] for no shorts\n",
    "    lambda_hhi: float = 0.1\n",
    "    lambda_turnover: float = 0.005\n",
    "    transaction_cost_rate: float = 0.0\n",
    "    model_retrain: bool  = False\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Seed-setting utility\n",
    "# ---------------------------------------------------------------------\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Feature engineering\n",
    "# ---------------------------------------------------------------------\n",
    "def add_stable_features(df: pd.DataFrame, etf_list: List[str]) -> pd.DataFrame:\n",
    "    data = df.copy()\n",
    "    for etf in etf_list:\n",
    "        price_col = f'Price_{etf}'\n",
    "        data[f'Volatility_{etf}'] = data[price_col].pct_change().rolling(20).std()\n",
    "        data[f'Momentum_5d_{etf}'] = data[price_col].pct_change(periods=5)\n",
    "        data[f'Momentum_10d_{etf}'] = data[price_col].pct_change(periods=10)\n",
    "        data[f'Momentum_20d_{etf}'] = data[price_col].pct_change(periods=20)\n",
    "        data[f'MA_5d_{etf}'] = data[price_col].rolling(5).mean()\n",
    "        data[f'MA_20d_{etf}'] = data[price_col].rolling(20).mean()\n",
    "        data[f'MA_Crossover_{etf}'] = data[f'MA_5d_{etf}'] - data[f'MA_20d_{etf}']\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n",
    "def filter_features(df: pd.DataFrame,\n",
    "                    include_predicted_returns: bool = True,\n",
    "                    include_shap_metrics: bool = True) -> pd.DataFrame:\n",
    "    df_filtered = df.copy()\n",
    "    if not include_predicted_returns:\n",
    "        pred_cols = [c for c in df_filtered.columns if 'Predicted_Return' in c]\n",
    "        df_filtered.drop(columns=pred_cols, inplace=True)\n",
    "    if not include_shap_metrics:\n",
    "        shap_cols = [c for c in df_filtered.columns if 'SHAP' in c]\n",
    "        df_filtered.drop(columns=shap_cols, inplace=True)\n",
    "    return df_filtered\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Custom Gym environment\n",
    "# ---------------------------------------------------------------------\n",
    "class PortfolioEnv(gym.Env):\n",
    "    metadata = {'render_modes': []}\n",
    "\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar',\n",
    "                 risk_coefficient=0.5, rebalance_period=21,\n",
    "                 lookback_period=21, weight_bounds=(0.0, 1.0),\n",
    "                 desired_long=1.0, desired_short=0.0,\n",
    "                 use_baseline=False, baseline_fn=None,\n",
    "                 transaction_cost_rate=0.0,\n",
    "                 lambda_turnover=0.001,   # <- Add explicitly\n",
    "                 lambda_hhi=0.1):         # <- Add explicitly\n",
    "        super().__init__()\n",
    "        self.transaction_cost_rate = transaction_cost_rate\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "        self.weight_bounds = weight_bounds\n",
    "        self.desired_long = desired_long       # Add this explicitly\n",
    "        self.desired_short = desired_short     # Add this explicitly\n",
    "        self.use_baseline = use_baseline\n",
    "        self.baseline_fn = baseline_fn\n",
    "        self.transaction_cost_rate = transaction_cost_rate\n",
    "        self.lambda_turnover = lambda_turnover\n",
    "        self.lambda_hhi = lambda_hhi\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0,\n",
    "                                       shape=(len(etf_list),), dtype=np.float32)\n",
    "        self.feature_cols = [c for c in data.columns\n",
    "                             if c != 'Date' and not c.startswith('Actual_Return')]\n",
    "        self.num_features_per_day = len(self.feature_cols)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.num_features_per_day * lookback_period,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.current_step = lookback_period\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(etf_list)] * len(etf_list))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(self.etf_list)] * len(self.etf_list))\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs_window = self.data.iloc[self.current_step - self.lookback_period : self.current_step]\n",
    "        obs_values = obs_window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "        \n",
    "        if np.isnan(obs_values).any() or np.isinf(obs_values).any():\n",
    "            obs_values = np.nan_to_num(obs_values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return obs_values\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns, turnover):\n",
    "        hhi = np.sum(np.square(np.abs(self.current_weights)))\n",
    "    \n",
    "        if np.isnan(portfolio_return) or np.isinf(portfolio_return):\n",
    "            portfolio_return = 0.0  # safeguard explicitly\n",
    "    \n",
    "        portfolio_return = np.clip(portfolio_return, -0.5, 0.5)  # explicitly clip returns\n",
    "    \n",
    "        if self.reward_type == 'cumulative_return':\n",
    "            base_reward = portfolio_return\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            base_reward = np.log(max(1 + portfolio_return, 1e-8))\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            base_reward = portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100 * alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            base_reward = portfolio_return - self.risk_coefficient * cvar\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid reward type: {self.reward_type}\")\n",
    "    \n",
    "        reward = base_reward \\\n",
    "                 - self.lambda_turnover * turnover \\\n",
    "                 - self.lambda_hhi * hhi\n",
    "    \n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = -1.0  # explicit fallback\n",
    "    \n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        next_step = self.current_step + 1\n",
    "        prev_weights = self.current_weights.copy()\n",
    "    \n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            if self.use_baseline and self.baseline_fn is not None:\n",
    "                current_date = self.data.loc[self.current_step, 'Date']\n",
    "                baseline_w = self.baseline_fn(current_date)\n",
    "                raw = baseline_w * (1.0 + action)\n",
    "            else:\n",
    "                raw = self.current_weights + action\n",
    "    \n",
    "            long_w = np.maximum(raw, 0.0)\n",
    "            short_w = np.abs(np.minimum(raw, 0.0))\n",
    "    \n",
    "            has_long = long_w.sum() > 0\n",
    "            has_short = short_w.sum() > 0\n",
    "    \n",
    "            if has_long and has_short:\n",
    "                norm_long = self.desired_long * long_w / long_w.sum()\n",
    "                norm_short = self.desired_short * short_w / short_w.sum()\n",
    "                combined = norm_long - norm_short\n",
    "            elif has_long and not has_short:\n",
    "                # explicitly no leverage if no shorts\n",
    "                combined = long_w / long_w.sum()\n",
    "            elif not has_long and has_short:\n",
    "                # explicitly full short if no longs\n",
    "                combined = -short_w / short_w.sum()\n",
    "            else:\n",
    "                # fallback explicitly to equal weights\n",
    "                combined = np.ones(len(raw)) / len(raw)\n",
    "    \n",
    "            clipped = np.clip(combined, self.weight_bounds[0], self.weight_bounds[1])\n",
    "    \n",
    "            # After clipping explicitly re-normalize\n",
    "            long_c = np.maximum(clipped, 0.0)\n",
    "            short_c = np.abs(np.minimum(clipped, 0.0))\n",
    "    \n",
    "            if long_c.sum() > 0 and short_c.sum() > 0:\n",
    "                final_long = self.desired_long * long_c / long_c.sum()\n",
    "                final_short = self.desired_short * short_c / short_c.sum()\n",
    "                self.current_weights = final_long - final_short\n",
    "            elif long_c.sum() > 0:\n",
    "                self.current_weights = long_c / long_c.sum()\n",
    "            elif short_c.sum() > 0:\n",
    "                self.current_weights = -short_c / short_c.sum()\n",
    "            else:\n",
    "                self.current_weights = np.ones(len(raw)) / len(raw)\n",
    "    \n",
    "            turnover = np.sum(np.abs(self.current_weights - prev_weights))\n",
    "        else:\n",
    "            # Passive reweighting between rebalances\n",
    "            returns_today = np.array([\n",
    "                self.data.loc[self.current_step, f\"Actual_Return_{etf}\"]\n",
    "                for etf in self.etf_list\n",
    "            ])\n",
    "            self.current_weights *= (1.0 + returns_today)\n",
    "            self.current_weights /= np.sum(np.abs(self.current_weights))\n",
    "            turnover = 0.0\n",
    "    \n",
    "        # Check for termination\n",
    "        if next_step >= len(self.data):\n",
    "            reward = 0.0\n",
    "            terminated = True\n",
    "        else:\n",
    "            asset_returns = np.array([\n",
    "                self.data.loc[next_step, f\"Actual_Return_{etf}\"]\n",
    "                for etf in self.etf_list\n",
    "            ])\n",
    "            portfolio_return = np.dot(self.current_weights, asset_returns)\n",
    "            portfolio_return = np.nan_to_num(portfolio_return, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "            self.cumulative_wealth *= (1.0 + portfolio_return)\n",
    "            reward = self.calculate_reward(portfolio_return, asset_returns, turnover)\n",
    "            reward -= self.transaction_cost_rate * turnover\n",
    "            terminated = next_step >= len(self.data) - 1\n",
    "    \n",
    "        self.current_step += 1\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "    \n",
    "        # advance time and return observation, reward, termination flags\n",
    "        self.current_step += 1\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Hyperparameter tuning function\n",
    "# ---------------------------------------------------------------------\n",
    "def equal_weight_baseline(date):\n",
    "    return np.ones(len(etf_list)) / len(etf_list)\n",
    "\n",
    "def validate_and_tune(train_data: pd.DataFrame, val_data: pd.DataFrame,\n",
    "                      etf_list: List[str], cfg: TrainingConfig,\n",
    "                      random_seed: int) -> Dict[str, float]:\n",
    "\n",
    "    param_dist = {\n",
    "        'learning_rate': [5e-4, 1e-5, 5e-5],\n",
    "        'n_steps': [20, 40],\n",
    "        'batch_size': [10, 20],\n",
    "        'gamma': [0.95, 0.98],\n",
    "        'risk_coefficient': [0.1, 0.5, 1.0, 5.0],\n",
    "        'lambda_turnover': [0.005, 0.01, 0.05],\n",
    "        'lambda_hhi': [0.5, 1, 5],\n",
    "        'seed': [random_seed, random_seed + 11, random_seed + 23]  # explicitly vary seeds\n",
    "    }\n",
    "\n",
    "    # Crucial: explicitly pass random_seed to ParameterSampler\n",
    "    sampled_params = list(ParameterSampler(\n",
    "        param_dist, n_iter=cfg.n_iter_tuning, random_state=random_seed\n",
    "    ))\n",
    "\n",
    "    best_reward = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for params in sampled_params:\n",
    "        seed = params.pop('seed')\n",
    "        risk_coeff = params.pop('risk_coefficient', cfg.default_risk_coeff)\n",
    "        lambda_turnover = params.pop('lambda_turnover', cfg.lambda_turnover)\n",
    "        lambda_hhi = params.pop('lambda_hhi', cfg.lambda_hhi)\n",
    "        \n",
    "        set_global_seed(seed)\n",
    "\n",
    "\n",
    "        env = make_vec_env(lambda: PortfolioEnv(\n",
    "            train_data, etf_list, 'mean_cvar', risk_coeff,\n",
    "            cfg.rebalance_period, cfg.lookback_period,\n",
    "            use_baseline=True, baseline_fn=equal_weight_baseline,\n",
    "            transaction_cost_rate=0.0005,\n",
    "            lambda_turnover=lambda_turnover,\n",
    "            lambda_hhi=lambda_hhi\n",
    "        ), n_envs=1, seed=seed)\n",
    "\n",
    "        model = PPO('MlpPolicy', env, ent_coef=0.01, clip_range=0.2, seed=seed, **params, verbose=0)\n",
    "        model.learn(total_timesteps=cfg.tuning_timesteps)\n",
    "\n",
    "        # Evaluate explicitly on validation set\n",
    "        val_env = PortfolioEnv(\n",
    "            val_data, etf_list, 'mean_cvar', risk_coeff,\n",
    "            cfg.rebalance_period, cfg.lookback_period,\n",
    "            use_baseline=True, baseline_fn=equal_weight_baseline,\n",
    "            transaction_cost_rate=0.0005,\n",
    "            lambda_turnover=lambda_turnover,\n",
    "            lambda_hhi=lambda_hhi\n",
    "        )\n",
    "\n",
    "        obs, _ = val_env.reset(seed=seed)\n",
    "        done, total_reward = False, 0.0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_params = params.copy()\n",
    "            best_params.update({\n",
    "                'risk_coefficient': risk_coeff,\n",
    "                'lambda_turnover': lambda_turnover,\n",
    "                'lambda_hhi': lambda_hhi,\n",
    "                'seed': seed\n",
    "            })\n",
    "\n",
    "    return best_params\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Training and prediction function\n",
    "# ---------------------------------------------------------------------\n",
    "def train_and_predict(train_df: pd.DataFrame, val_df: pd.DataFrame,\n",
    "                      pred_df: pd.DataFrame, etf_list: List[str],\n",
    "                      cfg: TrainingConfig, best_params: Dict[str, float],\n",
    "                      model_path: str) -> Tuple[List[List[float]], List[pd.Timestamp]]:\n",
    "    risk_coeff = best_params.pop('risk_coefficient')\n",
    "    seed = best_params.pop('seed')\n",
    "    set_global_seed(seed)\n",
    "\n",
    "    # Initialize training environment\n",
    "    env_train = make_vec_env(\n",
    "        lambda: PortfolioEnv(\n",
    "            train_df, etf_list,\n",
    "            'mean_cvar', risk_coeff,\n",
    "            cfg.rebalance_period,\n",
    "            cfg.lookback_period,\n",
    "            use_baseline=True,\n",
    "            baseline_fn=equal_weight_baseline,\n",
    "            transaction_cost_rate=cfg.transaction_cost_rate,\n",
    "\t\t\tdesired_long=cfg.desired_long,\n",
    "\t\t    desired_short=cfg.desired_short,\n",
    "\t\t    weight_bounds=cfg.weight_bounds,\n",
    "            lambda_turnover=cfg.lambda_turnover,\n",
    "            lambda_hhi=cfg.lambda_hhi\n",
    "        ),\n",
    "        n_envs=1, seed=seed\n",
    "    )\n",
    "\n",
    "    policy_kwargs = dict(net_arch=list(cfg.policy_arch))\n",
    "    model = PPO(\n",
    "        'MlpPolicy', env_train,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        ent_coef=0.01,\n",
    "        clip_range=0.2,\n",
    "        seed=seed,\n",
    "        verbose=0,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    best_val_reward = -np.inf\n",
    "    no_improve = 0\n",
    "\n",
    "    # Early stopping loop\n",
    "    for step in range(0, cfg.max_timesteps, cfg.incremental_timesteps):\n",
    "        model.learn(total_timesteps=cfg.incremental_timesteps)\n",
    "\n",
    "        # Initialize validation environment\n",
    "        val_env = PortfolioEnv(\n",
    "            val_df, etf_list,\n",
    "            'mean_cvar', risk_coeff,\n",
    "            cfg.rebalance_period,\n",
    "            cfg.lookback_period,\n",
    "            use_baseline=True,\n",
    "            baseline_fn=equal_weight_baseline,\n",
    "            transaction_cost_rate=cfg.transaction_cost_rate,\n",
    "\t\t\tdesired_long=cfg.desired_long,\n",
    "\t\t    desired_short=cfg.desired_short,\n",
    "\t\t    weight_bounds=cfg.weight_bounds,\n",
    "            lambda_turnover=cfg.lambda_turnover,\n",
    "            lambda_hhi=cfg.lambda_hhi\n",
    "        )\n",
    "\n",
    "        obs, _ = val_env.reset(seed=seed)\n",
    "        done = False\n",
    "        val_reward = 0.0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            val_reward += reward\n",
    "\n",
    "        if val_reward > best_val_reward:\n",
    "            best_val_reward = val_reward\n",
    "            no_improve = 0\n",
    "            model.save(model_path)\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= cfg.patience:\n",
    "                break\n",
    "\n",
    "    # Load best model and predict on pred_df\n",
    "    best_model = PPO.load(model_path)\n",
    "\n",
    "    env_pred = PortfolioEnv(\n",
    "        pred_df, etf_list,\n",
    "        reward_type='mean_cvar',  # Use Mean-CVaR reward explicitly\n",
    "        risk_coefficient=risk_coeff,\n",
    "        rebalance_period=cfg.rebalance_period,\n",
    "        lookback_period=cfg.lookback_period,\n",
    "        use_baseline=False,  # Set baseline to False for delta actions\n",
    "        transaction_cost_rate=cfg.transaction_cost_rate,\n",
    "\t\tdesired_long=cfg.desired_long,\n",
    "\t\tdesired_short=cfg.desired_short,\n",
    "\t\tweight_bounds=cfg.weight_bounds,\n",
    "        lambda_turnover=cfg.lambda_turnover,\n",
    "        lambda_hhi=cfg.lambda_hhi\n",
    "    )\n",
    "\n",
    "    obs, _ = env_pred.reset()\n",
    "    done = False\n",
    "    weights_list, dates_list = [], []\n",
    "\n",
    "    while not done:\n",
    "        if env_pred.current_step >= cfg.lookback_period and (\n",
    "            env_pred.current_step % cfg.rebalance_period == 0\n",
    "        ):\n",
    "            action, _ = best_model.predict(obs, deterministic=True)\n",
    "            obs, _, done, _, _ = env_pred.step(action)  # step first, then record\n",
    "\n",
    "            # Record weights AFTER applying the action\n",
    "            weights_list.append(env_pred.current_weights.tolist())\n",
    "            dates_list.append(env_pred.data.loc[env_pred.current_step, 'Date'])\n",
    "        else:\n",
    "            obs, _, done, _, _ = env_pred.step(np.zeros(len(etf_list), dtype=np.float32))\n",
    "\n",
    "    return weights_list, dates_list\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Data loading and overall training loop\n",
    "# ---------------------------------------------------------------------\n",
    "cfg = TrainingConfig(model_retrain=False)\n",
    "\n",
    "# Load your prepared Stage‑2 dataset and price data\n",
    "data = pd.read_csv('stage2_rl_observations_optimized_10ETFs.csv', parse_dates=['Date'])\n",
    "price_data = pd.read_csv('stock_prices_10ETFs.csv')\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], utc=True).dt.tz_localize(None)\n",
    "price_cols = {col: f'Price_{col}' for col in price_data.columns if col != 'Date'}\n",
    "price_data.rename(columns=price_cols, inplace=True)\n",
    "\n",
    "merged_data = pd.merge(data, price_data, on='Date', how='inner').reset_index(drop=True)\n",
    "if len(merged_data) != len(data):\n",
    "    print(\"Warning: data length mismatch after merge.\")\n",
    "\n",
    "etf_list = ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU']\n",
    "# etf_list = ['BA',\t'AMGN',\t'DIS',\t'NKE',\t'HON',\t'MMM',\t'CAT',\t'KO',\t'PG',\t'AXP',\t'JPM',\t'MCD',\t'HD',\t'AAPL',\t'CSCO',\t'IBM',\t'MSFT',\t'TRV',\t'UNH',\t'CVX',\t'JNJ',\t'MRK',\t'AMZN',\t'WMT',\t'INTC',\t'VZ']\n",
    "\n",
    "feature_data = add_stable_features(merged_data, etf_list)\n",
    "feature_data = filter_features(feature_data, include_predicted_returns=True, include_shap_metrics=True)\n",
    "\n",
    "# Rolling windows\n",
    "total_len = len(feature_data)\n",
    "# start_indices = range(0,\n",
    "#                       total_len - (cfg.train_window_days + cfg.validation_window_days + cfg.prediction_window_days),\n",
    "#                       cfg.prediction_window_days)\n",
    "\n",
    "start_indices = []\n",
    "current_start = 0\n",
    "\n",
    "while True:\n",
    "    train_start = current_start\n",
    "    train_end = train_start + cfg.train_window_days\n",
    "    val_end = train_end + cfg.validation_window_days\n",
    "    pred_end = val_end + cfg.prediction_window_days\n",
    "    \n",
    "    if pred_end > total_len:\n",
    "        break\n",
    "    \n",
    "    start_indices.append(current_start)\n",
    "    \n",
    "    # move to next window ensuring continuity without gap\n",
    "    current_start += cfg.prediction_window_days - cfg.rebalance_period\n",
    "\n",
    "# Prepare directory for outputs\n",
    "output_dir = 'stage2_iterations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Collect metrics for all iterations\n",
    "summary_records = []\n",
    "for iter_num in range(cfg.num_iterations):\n",
    "\t\n",
    "    iter_seed = cfg.base_seed + iter_num\n",
    "    set_global_seed(iter_seed)\n",
    "    tuned_seed = iter_seed\n",
    "    iter_dir = os.path.join(output_dir, f'iteration_{iter_num:02d}')\n",
    "    os.makedirs(iter_dir, exist_ok=True)\n",
    "    \n",
    "    previous_model_path = None\n",
    "    iter_returns = []\n",
    "    print(f\"\\nStarting iteration {iter_num+1}/{cfg.num_iterations} (Seed: {tuned_seed}) at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\t\n",
    "    for idx, start_idx in enumerate(start_indices):\n",
    "        window_start_time = time.time()\n",
    "        print(f\"  - Starting window {idx+1}/{len(start_indices)} at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        train_start = start_idx\n",
    "        train_end = train_start + cfg.train_window_days\n",
    "        val_start = train_end\n",
    "        val_end = val_start + cfg.validation_window_days\n",
    "        pred_start = val_end\n",
    "        pred_end = pred_start + cfg.prediction_window_days\n",
    "\n",
    "        train_df = feature_data.iloc[train_start:train_end].reset_index(drop=True)\n",
    "        val_df = feature_data.iloc[val_start:val_end].reset_index(drop=True)\n",
    "        pred_df = feature_data.iloc[pred_start:pred_end].reset_index(drop=True)\n",
    "        \n",
    "        train_df.ffill(inplace=True)\n",
    "        train_df.bfill(inplace=True)\n",
    "        \n",
    "        val_df.ffill(inplace=True)\n",
    "        val_df.bfill(inplace=True)\n",
    "        \n",
    "        pred_df.ffill(inplace=True)\n",
    "        pred_df.bfill(inplace=True)\n",
    "        \n",
    "\n",
    "        feature_cols = [c for c in train_df.columns if c != 'Date' and not c.startswith('Actual_Return')]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_df[feature_cols])\n",
    "\t\t\n",
    "        scale = scaler.scale_\n",
    "        scale[scale < 1e-8] = 1.0\n",
    "        scaler.scale_ = scale\n",
    "        \n",
    "        train_scaled = train_df.copy()\n",
    "        train_scaled[feature_cols] = scaler.transform(train_df[feature_cols])\n",
    "        val_scaled = val_df.copy()\n",
    "        val_scaled[feature_cols] = scaler.transform(val_df[feature_cols])\n",
    "        pred_scaled = pred_df.copy()\n",
    "        pred_scaled[feature_cols] = scaler.transform(pred_df[feature_cols])\n",
    "\n",
    "        # Explicit seed handling\n",
    "        if idx == 0:\n",
    "            best_params = validate_and_tune(\n",
    "                train_scaled, val_scaled, etf_list, cfg, random_seed=iter_seed\n",
    "            )\n",
    "            \n",
    "            # Fetch tuned seed explicitly from best_params\n",
    "            tuned_seed = best_params.get('seed', iter_seed)\n",
    "        else:\n",
    "            # Keep explicitly using previously found best_params\n",
    "            best_params = best_params.copy()\n",
    "\n",
    "        seed = tuned_seed\n",
    "        set_global_seed(seed)\n",
    "\n",
    "        window_dir = os.path.join(iter_dir, f'window_{idx:02d}')\n",
    "        os.makedirs(window_dir, exist_ok=True)\n",
    "        model_path = os.path.join(window_dir, 'best_ppo.zip')\n",
    "\n",
    "        # Use tuned parameters explicitly\n",
    "        risk_coeff = best_params.get('risk_coefficient', cfg.default_risk_coeff)\n",
    "        lambda_turnover = best_params.get('lambda_turnover', cfg.lambda_turnover)\n",
    "        lambda_hhi = best_params.get('lambda_hhi', cfg.lambda_hhi)\n",
    "        \n",
    "\n",
    "        env_train = make_vec_env(lambda: PortfolioEnv(\n",
    "                train_scaled, etf_list, 'mean_cvar', risk_coeff, cfg.rebalance_period, cfg.lookback_period,\n",
    "                use_baseline=True,\n",
    "                baseline_fn=equal_weight_baseline,\n",
    "                transaction_cost_rate=0.0005,\n",
    "                desired_long=cfg.desired_long,\n",
    "                desired_short=cfg.desired_short,\n",
    "                weight_bounds=cfg.weight_bounds,\n",
    "                lambda_turnover=lambda_turnover,\n",
    "                lambda_hhi=lambda_hhi\n",
    "            ), n_envs=1, seed=seed)\n",
    "\n",
    "        policy_kwargs = dict(net_arch=list(cfg.policy_arch))\n",
    "\n",
    "        if previous_model_path and os.path.exists(previous_model_path) and not cfg.model_retrain:\n",
    "            print(f'load the exising model from {previous_model_path} and retrain')\n",
    "            model = PPO.load(previous_model_path, env=env_train)\n",
    "            model.set_env(env_train)\n",
    "        else:\n",
    "            print(f'triam new model and saved under {model_path}')\n",
    "            model = PPO('MlpPolicy', env_train, policy_kwargs=policy_kwargs,\n",
    "                ent_coef=0.01,\n",
    "                clip_range=0.2,\n",
    "                seed=seed,\n",
    "                learning_rate=best_params.get('learning_rate', 1e-4),\n",
    "                n_steps=best_params.get('n_steps', 20),\n",
    "                batch_size=best_params.get('batch_size', 10),\n",
    "                gamma=best_params.get('gamma', 0.98),\n",
    "                verbose=0)\n",
    "            \n",
    "        best_val_reward = -np.inf\n",
    "        no_improve = 0\n",
    "        training_log = []\n",
    "\n",
    "        for step in range(0, cfg.max_timesteps, cfg.incremental_timesteps):\n",
    "            model.learn(total_timesteps=cfg.incremental_timesteps)\n",
    "\n",
    "            val_env = PortfolioEnv(val_scaled, etf_list, 'mean_cvar', risk_coeff,\n",
    "                                   cfg.rebalance_period, cfg.lookback_period,\n",
    "                                   use_baseline=True,\n",
    "                                   baseline_fn=equal_weight_baseline,\n",
    "                                   transaction_cost_rate=0.0005, \t\t\t\n",
    "\t\t\t\t\t\t\t\t   desired_long=cfg.desired_long,\n",
    "\t\t\t\t\t\t\t\t   desired_short=cfg.desired_short,\n",
    "\t\t\t\t\t\t\t\t   weight_bounds=cfg.weight_bounds, lambda_turnover=lambda_turnover,\n",
    "                lambda_hhi=lambda_hhi)\n",
    "            obs, _ = val_env.reset(seed=seed)\n",
    "            done, val_reward = False, 0.0\n",
    "\n",
    "            while not done:\n",
    "                action, _ = model.predict(obs, deterministic=True)\n",
    "                obs, reward, done, _, _ = val_env.step(action)\n",
    "                val_reward += reward\n",
    "\n",
    "            training_log.append({'training_step': step + cfg.incremental_timesteps, 'validation_reward': val_reward})\n",
    "\n",
    "            if val_reward > best_val_reward:\n",
    "                best_val_reward = val_reward\n",
    "                no_improve = 0\n",
    "                model.save(model_path)\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= cfg.patience:\n",
    "                    break\n",
    "\n",
    "        pd.DataFrame(training_log).to_csv(os.path.join(window_dir, 'training_validation_log.csv'), index=False)\n",
    "        previous_model_path = model_path\n",
    "\n",
    "        best_model = PPO.load(model_path)\n",
    "        env_pred = PortfolioEnv(\n",
    "            pred_scaled, etf_list,\n",
    "            reward_type='mean_cvar',\n",
    "            risk_coefficient=risk_coeff,\n",
    "            rebalance_period=cfg.rebalance_period,\n",
    "            lookback_period=cfg.lookback_period,\n",
    "            use_baseline=False,\n",
    "            transaction_cost_rate=0.0005,\n",
    "\t\t\tdesired_long=cfg.desired_long,\n",
    "\t\t    desired_short=cfg.desired_short,\n",
    "\t\t    weight_bounds=cfg.weight_bounds, lambda_turnover=lambda_turnover,\n",
    "                lambda_hhi=lambda_hhi\n",
    "        )\n",
    "\n",
    "        obs, _ = env_pred.reset()\n",
    "        done = False\n",
    "        weights_list, dates_list = [], []\n",
    "\n",
    "        while not done:\n",
    "            if env_pred.current_step >= cfg.lookback_period and (\n",
    "                env_pred.current_step % cfg.rebalance_period == 0\n",
    "            ):\n",
    "                action, _ = best_model.predict(obs, deterministic=True)\n",
    "                obs, _, done, _, _ = env_pred.step(action)\n",
    "\n",
    "                weights_list.append(env_pred.current_weights.tolist())\n",
    "                dates_list.append(env_pred.data.loc[env_pred.current_step, 'Date'])\n",
    "            else:\n",
    "                obs, _, done, _, _ = env_pred.step(np.zeros(len(etf_list), dtype=np.float32))\n",
    "\n",
    "        weights_df = pd.DataFrame(weights_list, columns=etf_list)\n",
    "        weights_df.insert(0, 'Date', dates_list)\n",
    "        weights_df.to_csv(os.path.join(window_dir, 'weights.csv'), index=False)\n",
    "\n",
    "        cum_wealth = 1.0\n",
    "        returns_log = []\n",
    "\n",
    "        for t, w in zip(dates_list, weights_list):\n",
    "            step_idx = pred_scaled[pred_scaled['Date'] == t].index[0]\n",
    "            asset_returns = np.array([\n",
    "                pred_scaled.loc[step_idx + 1, f'Actual_Return_{etf}']\n",
    "                for etf in etf_list\n",
    "            ])\n",
    "            port_ret = np.dot(w, asset_returns)\n",
    "            cum_wealth *= (1 + port_ret)\n",
    "            returns_log.append({'Date': t, 'Portfolio_Return': port_ret, 'Cumulative_Wealth': cum_wealth})\n",
    "\n",
    "        iter_returns.append(cum_wealth - 1.0)\n",
    "\n",
    "        pd.DataFrame(returns_log).to_csv(os.path.join(window_dir, 'returns_log.csv'), index=False)\n",
    "        window_end_time = time.time()\n",
    "        elapsed_window_time = window_end_time - window_start_time\n",
    "        print(f\"  - Completed window {idx+1}/{len(start_indices)} in {elapsed_window_time/60:.2f} minutes.\")\n",
    "\n",
    "    mean_ret = np.mean(iter_returns)\n",
    "    std_ret = np.std(iter_returns, ddof=1)\n",
    "    sharpe = (mean_ret / std_ret) * np.sqrt(len(iter_returns)) if std_ret != 0 else np.nan\n",
    "    summary_records.append({\n",
    "        'iteration': iter_num,\n",
    "        'seed': iter_seed,\n",
    "        'mean_return': mean_ret,\n",
    "        'sharpe': sharpe\n",
    "    })\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  # Only if you're using GPU explicitly\n",
    "\n",
    "summary_df = pd.DataFrame(summary_records)\n",
    "summary_df.to_csv(os.path.join(output_dir, 'iterations_summary.csv'), index=False)\n",
    "\n",
    "t_stat, p_val = ttest_1samp(summary_df['mean_return'], 0.0)\n",
    "with open(os.path.join(output_dir, 't_test_result.csv'), 'w') as f:\n",
    "    f.write(f\"t-statistic,{t_stat}\\np-value,{p_val}\\n\")\n",
    "\n",
    "print(summary_df)\n",
    "print(f\"Overall t-statistic={t_stat:.3f}, p-value={p_val:.3f}\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # Only if you're using GPU explicitly\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-08T05:05:33.857580Z",
     "start_time": "2025-08-08T04:07:19.585336Z"
    }
   },
   "id": "cfe656732378c6e7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7aba3a43020d11ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "93ecdbb778338c51",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5556d1f98d4833ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "output_dir = 'stage2_iterations'  # Adjust if your path is different\n",
    "pattern = os.path.join(output_dir, 'iteration_0', 'window_*', 'weights.csv')\n",
    "\n",
    "# Find all weight files matching the pattern\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Initialize an empty list to collect DataFrames\n",
    "all_weights = []\n",
    "\n",
    "for file_path in files:\n",
    "    # Extract iteration and window numbers\n",
    "    parts = file_path.split(os.sep)\n",
    "    iteration = int(parts[-3].split('_')[1])\n",
    "    window = int(parts[-2].split('_')[1])\n",
    "\n",
    "    # Load weights file\n",
    "    df = pd.read_csv(file_path, parse_dates=['Date'])\n",
    "\n",
    "    # Add columns for iteration and window\n",
    "    df.insert(0, 'Window', window)\n",
    "    df.insert(0, 'Iteration', iteration)\n",
    "\n",
    "    # Append to the list\n",
    "    all_weights.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(all_weights, ignore_index=True)\n",
    "\n",
    "# Sort by iteration, window, and date\n",
    "combined_df.sort_values(['Iteration', 'Window', 'Date'], inplace=True)\n",
    "\n",
    "# Save combined data\n",
    "combined_df.to_csv(os.path.join(output_dir, 'combined_weights.csv'), index=False)\n",
    "\n",
    "print(f\"Combined weights saved to: {os.path.join(output_dir, 'combined_weights.csv')}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-08T05:05:33.860580Z",
     "start_time": "2025-08-08T05:05:33.859581Z"
    }
   },
   "id": "9b01351041b154b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b0f510c1ff23295",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "10563904fd258e2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "637f2b485e42e5a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# start of stage 2 training\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "SEED = 42\n",
    "def set_global_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    set_random_seed(seed)\n",
    "\n",
    "set_global_seed(SEED)\n",
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar', risk_coefficient=0.5, rebalance_period=21, lookback_period=21):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(etf_list),), dtype=np.float32)\n",
    "\n",
    "        # Explicitly select feature columns (excluding Date and returns used only for calculating reward)\n",
    "        self.feature_cols = [col for col in data.columns if col not in ['Date'] and not col.startswith('Actual_Return')]\n",
    "        self.num_features_per_day = len(self.feature_cols)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.num_features_per_day * self.lookback_period,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(etf_list)] * len(etf_list))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(self.etf_list)] * len(self.etf_list))\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        next_step = self.current_step + 1\n",
    "\n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            # v2 long short\n",
    "            desired_long = 1.20  # 120% long exposure explicitly\n",
    "            desired_short = 0.20  # 20% short exposure explicitly\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                # Normal 120/20 explicitly0\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                # Only long explicitly: default realistically to 100% long\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                # Only short explicitly (unrealistic), fallback clearly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                # All zeros explicitly: fallback explicitly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            # Apply explicit clipping\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate explicitly after clipping\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            # Final explicit normalization after clipping\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)  # exactly 100% long\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                # Realistic fallback explicitly: equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "            self.current_weights = final_weights\n",
    "            \n",
    "            # v1 softmax normalization\n",
    "            \n",
    "            # temperature = 0.5  # Explicitly lower for higher concentration (try 0.2 to 0.8)\n",
    "            # scaled_action = action / temperature\n",
    "            # self.current_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "\n",
    "        else:\n",
    "            returns_today = np.array([self.data.loc[self.current_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            self.current_weights *= (1 + returns_today)\n",
    "            self.current_weights /= np.sum(self.current_weights)\n",
    "\n",
    "        if next_step >= len(self.data):\n",
    "            terminated = True\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            returns = np.array([self.data.loc[next_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            portfolio_return = np.dot(self.current_weights, returns)\n",
    "            self.cumulative_wealth *= (1 + portfolio_return)\n",
    "            reward = self.calculate_reward(portfolio_return, returns)\n",
    "            terminated = next_step >= len(self.data) - 1\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "        # def _get_obs(self):\n",
    "        #     obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        #     obs_window = obs_window.drop(columns=['Date']).values.flatten().astype(np.float32)\n",
    "        #     return obs_window\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        obs_window = obs_window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "        return obs_window\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns):\n",
    "        if self.reward_type == 'cumulative_return':\n",
    "            return self.cumulative_wealth - 1.0\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            return np.log(self.cumulative_wealth)\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            return portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100 * alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            return portfolio_return - self.risk_coefficient * cvar\n",
    "        else:\n",
    "            raise ValueError('Invalid reward type')\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_stable_features(df, etf_list):\n",
    "    data = df.copy()\n",
    "\n",
    "    for etf in etf_list:\n",
    "        price_col = f'Price_{etf}'\n",
    "\n",
    "        # Volatility (20-day)\n",
    "        data[f'Volatility_{etf}'] = data[price_col].pct_change().rolling(20).std()\n",
    "\n",
    "        # Momentum indicators (returns over 5, 10, 20 days)\n",
    "        data[f'Momentum_5d_{etf}'] = data[price_col].pct_change(periods=5)\n",
    "        data[f'Momentum_10d_{etf}'] = data[price_col].pct_change(periods=10)\n",
    "        data[f'Momentum_20d_{etf}'] = data[price_col].pct_change(periods=20)\n",
    "\n",
    "        # Moving averages (5-day and 20-day)\n",
    "        data[f'MA_5d_{etf}'] = data[price_col].rolling(5).mean()\n",
    "        data[f'MA_20d_{etf}'] = data[price_col].rolling(20).mean()\n",
    "\n",
    "        # Moving average crossover (5-day MA - 20-day MA)\n",
    "        data[f'MA_Crossover_{etf}'] = data[f'MA_5d_{etf}'] - data[f'MA_20d_{etf}']\n",
    "\n",
    "    # Drop NaN values due to rolling calculations\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def filter_features(df, include_predicted_returns=True, include_shap_metrics=True):\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Explicit patterns to identify columns\n",
    "    predicted_return_pattern = 'Predicted_Return'\n",
    "    shap_metric_pattern = 'SHAP'\n",
    "\n",
    "    # Exclude Predicted Returns explicitly if requested\n",
    "    if not include_predicted_returns:\n",
    "        predicted_cols = [col for col in df_filtered.columns if predicted_return_pattern in col]\n",
    "        df_filtered.drop(columns=predicted_cols, inplace=True)\n",
    "        print(f\"Excluded predicted return columns: {predicted_cols}\")\n",
    "\n",
    "    # Exclude SHAP-related metrics explicitly if requested\n",
    "    if not include_shap_metrics:\n",
    "        shap_cols = [col for col in df_filtered.columns if shap_metric_pattern in col]\n",
    "        df_filtered.drop(columns=shap_cols, inplace=True)\n",
    "        print(f\"Excluded SHAP-related columns: {shap_cols}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# ETFs\n",
    "etf_list = ['XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLY', 'XLV', 'XLU']\n",
    "\n",
    "# etf_list = ['BA',\n",
    "# 'AMGN',\n",
    "# 'DIS',\n",
    "# 'NKE',\n",
    "# 'HON',\n",
    "# 'MMM',\n",
    "# 'CAT',\n",
    "# 'KO',\n",
    "# 'PG',\n",
    "# 'AXP',\n",
    "# 'JPM',\n",
    "# 'MCD',\n",
    "# 'HD',\n",
    "# 'AAPL',\n",
    "# 'CSCO',\n",
    "# 'IBM',\n",
    "# 'MSFT',\n",
    "# 'TRV',\n",
    "# 'UNH',\n",
    "# 'CVX',\n",
    "# 'JNJ',\n",
    "# 'MRK',\n",
    "# 'AMZN',\n",
    "# 'WMT',\n",
    "# 'INTC',\n",
    "# 'VZ']\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-5],\n",
    "    'n_steps': [20, 40],\n",
    "    'batch_size': [5, 10],\n",
    "    'gamma': [0.98, 0.99]\n",
    "}\n",
    "consolidated_file = 'stage2_rl_observations_optimized_10ETFs.csv'\n",
    "reward_type = 'mean_cvar'\n",
    "# data = pd.read_csv(consolidated_file, parse_dates=['Date'])\n",
    "# data = data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "data = pd.read_csv('stage2_rl_observations_optimized_10ETFs.csv', parse_dates=['Date'])\n",
    "price_data = pd.read_csv('stock_prices_10ETFs.csv')\n",
    "# price_data = pd.read_csv('stock_prices_10ETFs.csv')\n",
    "# Convert the Date column in price data, handling the timezone correctly\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], utc=True)\n",
    "price_data['Date'] = price_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Rename price columns explicitly to 'price_{ticker}'\n",
    "price_cols = {col: f'Price_{col}' for col in price_data.columns if col != 'Date'}\n",
    "price_data.rename(columns=price_cols, inplace=True)\n",
    "\n",
    "# Merge datasets on Date\n",
    "merged_data = pd.merge(data, price_data, on='Date', how='inner')\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "# Check if merge was successful\n",
    "if len(merged_data) != len(data):\n",
    "    print(f\"Warning: Data length mismatch after merging (Original: {len(data)}, Merged: {len(merged_data)}).\")\n",
    "else:\n",
    "    print(\"Merged successfully with aligned dates.\")\n",
    "\n",
    "data_with_features_raw = add_stable_features(merged_data, etf_list)\n",
    "data_with_features_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Usage Example clearly for benchmark (only price metrics, no predicted return or SHAP):\n",
    "data_with_features = filter_features(data_with_features_raw, \n",
    "                                 include_predicted_returns=True, \n",
    "                                 include_shap_metrics=True)\n",
    "################### override data to use SHAP only\n",
    "# data_with_features = data\n",
    "################### END override \n",
    "\n",
    "# Define your rolling window lengths clearly:\n",
    "train_window_days = 252 * 10\n",
    "validation_window_days = 126\n",
    "prediction_window_days = 126\n",
    "lookback_period = 10\n",
    "rebalance_period = 10\n",
    "\n",
    "start_indices = range(0, len(data) - (train_window_days + validation_window_days + prediction_window_days), prediction_window_days)\n",
    "all_weights = []\n",
    "model_path = 'ppo_single_train_best_model_10ETFs.zip'\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "def validate_and_tune(train_data, val_data, reward_type, rebalance_period=10, lookback_period=10, n_iter=8, timesteps=5000):\n",
    "    best_reward, best_params = -np.inf, None\n",
    "\n",
    "    # Narrow and meaningful parameter distribution\n",
    "    param_dist = {\n",
    "        'learning_rate': [3e-4, 1e-4],\n",
    "        'n_steps': [20, 40],\n",
    "        'batch_size': [10, 20],\n",
    "        'gamma': [0.95, 0.98],\n",
    "        'risk_coefficient': [0.1, 0.5, 1.0] if reward_type in ['mean_var', 'mean_cvar'] else [0.5],\n",
    "        'seed': [42, 100, 2024, 12345, 579]\n",
    "    }\n",
    "\n",
    "    sampled_params = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=SEED))\n",
    "\n",
    "    for params in sampled_params:\n",
    "        seed = params.pop('seed')\n",
    "        risk_coeff = params.pop('risk_coefficient', 0.5)\n",
    "        set_global_seed(seed)\n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1, seed=seed)\n",
    "        model = PPO('MlpPolicy', env,\n",
    "                    ent_coef=0.01,    # explicitly encourages exploration\n",
    "                    clip_range=0.2,\n",
    "                    seed=seed,\n",
    "                    **params, verbose=0)\n",
    "        model.learn(total_timesteps=timesteps)\n",
    "\n",
    "        val_env = PortfolioEnv(val_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        obs, _ = val_env.reset(seed=seed)\n",
    "        done, total_reward = False, 0\n",
    "\n",
    "        while not done:\n",
    "            # num_samples = 100  # Recommended starting point\n",
    "            # action_samples = []\n",
    "            # \n",
    "            # for _ in range(num_samples):\n",
    "            #     sampled_action, _ = model.predict(obs, deterministic=False)  # obs directly\n",
    "            #     action_samples.append(sampled_action)\n",
    "            # \n",
    "            # action = np.mean(action_samples, axis=0)\n",
    "            \n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_params = {**params, 'risk_coefficient': risk_coeff, 'seed': seed}\n",
    "    with open('best_params.json', 'w') as f:\n",
    "        json.dump(best_params, f)\n",
    "    return best_params\n",
    "\n",
    "def scale_data(df, feature_cols, scaler):\n",
    "    scaled_features = scaler.transform(df[feature_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=feature_cols, index=df.index)\n",
    "\n",
    "    # Re-add columns that were not scaled (e.g., Date, Actual_Return_*)\n",
    "    for col in df.columns:\n",
    "        if col not in feature_cols:\n",
    "            scaled_df[col] = df[col].values\n",
    "\n",
    "    # Keep original column order\n",
    "    scaled_df = scaled_df[df.columns]\n",
    "    return scaled_df\n",
    "\n",
    "# Main execution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for idx, start_idx in enumerate(start_indices):\n",
    "    # for start_idx in range(0, 252*2, 252):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Explicit indices for training, validation, and prediction datasets\n",
    "    train_start_idx = start_idx\n",
    "    train_end_idx = train_start_idx + train_window_days\n",
    "\n",
    "    val_start_idx = train_end_idx\n",
    "    val_end_idx = val_start_idx + validation_window_days\n",
    "\n",
    "    pred_start_idx = val_end_idx\n",
    "    pred_end_idx = pred_start_idx + prediction_window_days\n",
    "\n",
    "    # Corresponding dates explicitly\n",
    "    train_start_date = data_with_features.loc[train_start_idx, 'Date']\n",
    "    train_end_date = data_with_features.loc[train_end_idx - 1, 'Date']\n",
    "\n",
    "    val_start_date = data_with_features.loc[val_start_idx, 'Date']\n",
    "    val_end_date = data_with_features.loc[val_end_idx - 1, 'Date']\n",
    "\n",
    "    pred_start_date = data_with_features.loc[pred_start_idx, 'Date']\n",
    "    pred_end_date = data_with_features.loc[pred_end_idx - 1, 'Date']\n",
    "\n",
    "    # Clearly print ranges for clarity\n",
    "    print(f\"Training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "    print(f\"Validation period: {val_start_date.date()} to {val_end_date.date()}\")\n",
    "    print(f\"Prediction period: {pred_start_date.date()} to {pred_end_date.date()}\")\n",
    "\n",
    "    # Explicitly subset data accordingly\n",
    "    train_data = data_with_features.iloc[train_start_idx:train_end_idx].reset_index(drop=True)\n",
    "    val_data = data_with_features.iloc[val_start_idx:val_end_idx].reset_index(drop=True)\n",
    "    pred_data = data_with_features.iloc[pred_start_idx:pred_end_idx].reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [col for col in train_data.columns if col != 'Date' and not col.startswith('Actual_Return')]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_data[feature_cols])\n",
    "\n",
    "    train_data_scaled = scale_data(train_data, feature_cols, scaler)\n",
    "    val_data_scaled = scale_data(val_data, feature_cols, scaler)\n",
    "    pred_data_scaled = scale_data(pred_data, feature_cols, scaler)\n",
    "\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    best_params = validate_and_tune(train_data_scaled, val_data_scaled, reward_type)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    incremental_timesteps = 3000    \n",
    "    max_timesteps = 30000\n",
    "    patience = 3\n",
    "    \n",
    "    best_val_reward = -np.inf\n",
    "    no_improve_steps = 0\n",
    "\n",
    "    # risk_coeff = best_params.pop('risk_coefficient',0.5)\n",
    "    policy_kwargs = dict(net_arch=[256, 256])\n",
    "\n",
    "    with open('best_params.json', 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    \n",
    "    risk_coeff = best_params.pop('risk_coefficient')\n",
    "    seed = best_params.pop('seed')\n",
    "    \n",
    "    set_global_seed(seed)\n",
    "    env = make_vec_env(lambda: PortfolioEnv(train_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1, seed=seed)\n",
    "    \n",
    "    # Load previous model if exists\n",
    "    # if idx > 0 and os.path.exists(model_path):\n",
    "    #     print(f\"Loading previous model from {model_path}...\")\n",
    "    #     model = PPO.load(model_path, env=env)\n",
    "    #     model.set_env(env)\n",
    "    # else:\n",
    "    #     print(\"Initializing new PPO model...\")\n",
    "    #     model = PPO('MlpPolicy', env,\n",
    "    #                 policy_kwargs=policy_kwargs,\n",
    "    #                 ent_coef=0.01,\n",
    "    #                 clip_range=0.2,\n",
    "    #                 seed=seed, \n",
    "    #                 **best_params, verbose=0)\n",
    "     # always retrain\n",
    "    model = PPO('MlpPolicy', env,\n",
    "                    policy_kwargs=policy_kwargs,\n",
    "                    ent_coef=0.01,\n",
    "                    clip_range=0.2,\n",
    "                    seed=seed, \n",
    "                    **best_params, verbose=0)\n",
    "    # model.learn(total_timesteps=20000)\n",
    "    print(\"Starting model training with early stopping...\")\n",
    "\n",
    "    for step in range(0, max_timesteps, incremental_timesteps):\n",
    "        model.learn(total_timesteps=incremental_timesteps)\n",
    "    \n",
    "        # Evaluate on validation environment\n",
    "        val_env = PortfolioEnv(val_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        val_obs, _ = val_env.reset()\n",
    "        val_done = False\n",
    "        val_total_reward = 0.0\n",
    "    \n",
    "        while not val_done:\n",
    "            val_action, _ = model.predict(val_obs, deterministic=True)\n",
    "            # num_samples = 100  # Recommended\n",
    "            # value_action_samples = []\n",
    "            # \n",
    "            # for _ in range(num_samples):\n",
    "            #     value_sampled_action, _ = model.predict(val_obs, deterministic=False)\n",
    "            #     value_action_samples.append(value_sampled_action)\n",
    "            # \n",
    "            # val_action = np.mean(value_action_samples, axis=0)    \n",
    "            \n",
    "            val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "            val_total_reward += val_reward\n",
    "    \n",
    "        print(f\"Step: {step + incremental_timesteps}, Validation Total Reward: {val_total_reward:.4f}\")\n",
    "    \n",
    "        # Early stopping check\n",
    "        if val_total_reward > best_val_reward:\n",
    "            best_val_reward = val_total_reward\n",
    "            no_improve_steps = 0\n",
    "            # model.save(\"best_ppo_model.zip\")\n",
    "            model.save(model_path)\n",
    "            print(f\"Improved validation reward; model saved at step {step + incremental_timesteps}\")\n",
    "        else:\n",
    "            no_improve_steps += 1\n",
    "            print(f\"No improvement ({no_improve_steps}/{patience})\")\n",
    "    \n",
    "            if no_improve_steps >= patience:\n",
    "                print(\"Early stopping explicitly triggered.\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model explicitly\n",
    "    model = PPO.load(model_path)\n",
    "    print(\"Loaded the best PPO model explicitly for prediction.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure historical context explicitly available in prediction\n",
    "    full_data = pd.concat([train_data_scaled, val_data_scaled, pred_data_scaled])\n",
    "    pred_data_with_history = full_data[full_data['Date'] >= (pred_start_date - pd.Timedelta(days=lookback_period))].reset_index(drop=True)\n",
    "\n",
    "    pred_env = PortfolioEnv(pred_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "    # pred_env = PortfolioEnv(pred_data_with_history, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "\n",
    "    obs, info = pred_env.reset()\n",
    "    done = False\n",
    "\n",
    "    action = np.zeros(len(etf_list), dtype=np.float32)\n",
    "\n",
    "    while not done:\n",
    "        if pred_env.current_step >= lookback_period and pred_env.current_step % pred_env.rebalance_period == 0:\n",
    "            # obs_for_agent = pred_data_with_history.drop(columns=['Date']).iloc[pred_env.current_step - lookback_period:pred_env.current_step].values.flatten().astype(np.float32)\n",
    "            # action, _ = model.predict(obs_for_agent, deterministic=True)\n",
    "\n",
    "            # v1 normalize weight\n",
    "            # action, _ = model.predict(obs, deterministic=True)\n",
    "            # use determinstic = FALSE       \n",
    "            # num_samples = 100  # Recommended\n",
    "            # action_samples = []\n",
    "            # for _ in range(num_samples):\n",
    "            #     sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "            #     action_samples.append(sampled_action)\n",
    "            # action = np.mean(action_samples, axis=0)    \n",
    "            # \n",
    "            # temperature = 0.5\n",
    "            # scaled_action = action / temperature\n",
    "            # weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "            # rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "            # all_weights.append([rebalance_date] + weights.tolist())\n",
    "\n",
    "\n",
    "            # v2 long short normalization\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # uncomment this for predictopm\n",
    "            # num_samples = 100  # Recommended\n",
    "            # action_samples = []\n",
    "            # \n",
    "            # for _ in range(num_samples):\n",
    "            #     sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "            #     action_samples.append(sampled_action)\n",
    "            # \n",
    "            # action = np.mean(action_samples, axis=0)    \n",
    "\n",
    "            # Explicitly apply your new 120/20 normalization logic (to match environment step)\n",
    "            desired_long = 1.20  # Explicitly 120% long exposure\n",
    "            desired_short = 0.20  # Explicitly 20% short exposure\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate after clipping explicitly\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "\n",
    "            rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "            all_weights.append([rebalance_date] + final_weights.tolist())\n",
    "\n",
    "        obs, _, done, _, _ = pred_env.step(action)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "columns = ['Date'] + etf_list\n",
    "weights_df = pd.DataFrame(all_weights, columns=columns)\n",
    "weights_df.to_csv('ppo_multi_year_weights_10ETFs.csv', index=False)\n",
    "print(\"Saved predictions to ppo_multi_year_weights_10ETFs.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c770edf2acf6b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "############################## This is start to run 25 iterations ##############################\n",
    "########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8acf6abff959b252",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ITERATION - final variable: 128/20 - retrain - 50kx30k sample - mean cvar - determinstic false with 50 - 7 yr train by 21 day test\n",
    "# start of stage 2 training\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "def set_global_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    set_random_seed(seed)\n",
    "\n",
    "set_global_seed(SEED)\n",
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar', risk_coefficient=0.5, rebalance_period=21, lookback_period=21):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(etf_list),), dtype=np.float32)\n",
    "\n",
    "        # Explicitly select feature columns (excluding Date and returns used only for calculating reward)\n",
    "        self.feature_cols = [col for col in data.columns if col not in ['Date'] and not col.startswith('Actual_Return')]\n",
    "        self.num_features_per_day = len(self.feature_cols)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.num_features_per_day * self.lookback_period,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(etf_list)] * len(etf_list))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.done = False\n",
    "        self.cumulative_wealth = 1.0\n",
    "        self.current_weights = np.array([1.0 / len(self.etf_list)] * len(self.etf_list))\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        next_step = self.current_step + 1\n",
    "\n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            # v2 long short\n",
    "            desired_long = 1.20  # 120% long exposure explicitly\n",
    "            desired_short = 0.20  # 20% short exposure explicitly\n",
    "            clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "            raw_weights = action.copy()\n",
    "\n",
    "            # Separate explicitly positive (long) and negative (short) actions\n",
    "            long_weights = np.maximum(raw_weights, 0)\n",
    "            short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "            has_longs = np.sum(long_weights) > 0\n",
    "            has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "            if has_longs and has_shorts:\n",
    "                # Normal 120/20 explicitly0\n",
    "                normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "            elif has_longs and not has_shorts:\n",
    "                # Only long explicitly: default realistically to 100% long\n",
    "                normalized_long = long_weights / np.sum(long_weights)\n",
    "                normalized_short = np.zeros_like(short_weights)\n",
    "            elif not has_longs and has_shorts:\n",
    "                # Only short explicitly (unrealistic), fallback clearly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "            else:\n",
    "                # All zeros explicitly: fallback explicitly to equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                normalized_long = np.ones(num_assets) / num_assets\n",
    "                normalized_short = np.zeros(num_assets)\n",
    "\n",
    "            # Apply explicit clipping\n",
    "            combined_weights = normalized_long - normalized_short\n",
    "            clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "            # Re-separate explicitly after clipping\n",
    "            long_clipped = np.maximum(clipped_weights, 0)\n",
    "            short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "            has_long_clipped = np.sum(long_clipped) > 0\n",
    "            has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "            # Final explicit normalization after clipping\n",
    "            if has_long_clipped and has_short_clipped:\n",
    "                final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "            elif has_long_clipped and not has_short_clipped:\n",
    "                final_long = long_clipped / np.sum(long_clipped)  # exactly 100% long\n",
    "                final_short = np.zeros_like(short_clipped)\n",
    "            else:\n",
    "                # Realistic fallback explicitly: equal-weight long-only\n",
    "                num_assets = len(raw_weights)\n",
    "                final_long = np.ones(num_assets) / num_assets\n",
    "                final_short = np.zeros(num_assets)\n",
    "\n",
    "            final_weights = final_long - final_short\n",
    "            self.current_weights = final_weights\n",
    "            \n",
    "            # v1 softmax normalization\n",
    "            \n",
    "            # temperature = 0.5  # Explicitly lower for higher concentration (try 0.2 to 0.8)\n",
    "            # scaled_action = action / temperature\n",
    "            # self.current_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "\n",
    "        else:\n",
    "            returns_today = np.array([self.data.loc[self.current_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            self.current_weights *= (1 + returns_today)\n",
    "            self.current_weights /= np.sum(self.current_weights)\n",
    "\n",
    "        if next_step >= len(self.data):\n",
    "            terminated = True\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            returns = np.array([self.data.loc[next_step, f'Actual_Return_{etf}'] for etf in self.etf_list])\n",
    "            portfolio_return = np.dot(self.current_weights, returns)\n",
    "            self.cumulative_wealth *= (1 + portfolio_return)\n",
    "            reward = self.calculate_reward(portfolio_return, returns)\n",
    "            terminated = next_step >= len(self.data) - 1\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "        # def _get_obs(self):\n",
    "        #     obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        #     obs_window = obs_window.drop(columns=['Date']).values.flatten().astype(np.float32)\n",
    "        #     return obs_window\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs_window = self.data.iloc[self.current_step - self.lookback_period:self.current_step]\n",
    "        obs_window = obs_window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "        return obs_window\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns):\n",
    "        if self.reward_type == 'cumulative_return':\n",
    "            return self.cumulative_wealth - 1.0\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            return np.log(self.cumulative_wealth)\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            return portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100 * alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            return portfolio_return - self.risk_coefficient * cvar\n",
    "        else:\n",
    "            raise ValueError('Invalid reward type')\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_stable_features(df, etf_list):\n",
    "    data = df.copy()\n",
    "\n",
    "    for etf in etf_list:\n",
    "        price_col = f'Price_{etf}'\n",
    "\n",
    "        # Volatility (20-day)\n",
    "        data[f'Volatility_{etf}'] = data[price_col].pct_change().rolling(20).std()\n",
    "\n",
    "        # Momentum indicators (returns over 5, 10, 20 days)\n",
    "        data[f'Momentum_5d_{etf}'] = data[price_col].pct_change(periods=5)\n",
    "        data[f'Momentum_10d_{etf}'] = data[price_col].pct_change(periods=10)\n",
    "        data[f'Momentum_20d_{etf}'] = data[price_col].pct_change(periods=20)\n",
    "\n",
    "        # Moving averages (5-day and 20-day)\n",
    "        data[f'MA_5d_{etf}'] = data[price_col].rolling(5).mean()\n",
    "        data[f'MA_20d_{etf}'] = data[price_col].rolling(20).mean()\n",
    "\n",
    "        # Moving average crossover (5-day MA - 20-day MA)\n",
    "        data[f'MA_Crossover_{etf}'] = data[f'MA_5d_{etf}'] - data[f'MA_20d_{etf}']\n",
    "\n",
    "    # Drop NaN values due to rolling calculations\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def filter_features(df, include_predicted_returns=True, include_shap_metrics=True):\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Explicit patterns to identify columns\n",
    "    predicted_return_pattern = 'Predicted_Return'\n",
    "    shap_metric_pattern = 'SHAP'\n",
    "\n",
    "    # Exclude Predicted Returns explicitly if requested\n",
    "    if not include_predicted_returns:\n",
    "        predicted_cols = [col for col in df_filtered.columns if predicted_return_pattern in col]\n",
    "        df_filtered.drop(columns=predicted_cols, inplace=True)\n",
    "        print(f\"Excluded predicted return columns: {predicted_cols}\")\n",
    "\n",
    "    # Exclude SHAP-related metrics explicitly if requested\n",
    "    if not include_shap_metrics:\n",
    "        shap_cols = [col for col in df_filtered.columns if shap_metric_pattern in col]\n",
    "        df_filtered.drop(columns=shap_cols, inplace=True)\n",
    "        print(f\"Excluded SHAP-related columns: {shap_cols}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# ETFs\n",
    "etf_list = ['XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLY', 'XLV', 'XLU']\n",
    "# etf_list = ['BA',\n",
    "# 'AMGN',\n",
    "# 'DIS',\n",
    "# 'NKE',\n",
    "# 'HON',\n",
    "# 'MMM',\n",
    "# 'CAT',\n",
    "# 'KO',\n",
    "# 'PG',\n",
    "# 'AXP',\n",
    "# 'JPM',\n",
    "# 'MCD',\n",
    "# 'HD',\n",
    "# 'AAPL',\n",
    "# 'CSCO',\n",
    "# 'IBM',\n",
    "# 'MSFT',\n",
    "# 'TRV',\n",
    "# 'UNH',\n",
    "# 'CVX',\n",
    "# 'JNJ',\n",
    "# 'MRK',\n",
    "# 'AMZN',\n",
    "# 'WMT',\n",
    "# 'INTC',\n",
    "# 'VZ']\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 3e-4, 5e-4],\n",
    "    'gamma': [0.90, 0.95, 0.98],\n",
    "    'clip_range': [0.1, 0.2, 0.25],\n",
    "    'gae_lambda': [0.8, 0.9, 0.95]\n",
    "}\n",
    "consolidated_file = 'stage2_rl_observations_optimized_10ETFs.csv'\n",
    "reward_type = 'mean_cvar'\n",
    "# data = pd.read_csv(consolidated_file, parse_dates=['Date'])\n",
    "# data = data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "data = pd.read_csv('stage2_rl_observations_optimized_DIA_ETF.csv', parse_dates=['Date'])\n",
    "price_data = pd.read_csv('stock_prices_DIA_ETF.csv')\n",
    "\n",
    "# Convert the Date column in price data, handling the timezone correctly\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], utc=True)\n",
    "price_data['Date'] = price_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Rename price columns explicitly to 'price_{ticker}'\n",
    "price_cols = {col: f'Price_{col}' for col in price_data.columns if col != 'Date'}\n",
    "price_data.rename(columns=price_cols, inplace=True)\n",
    "\n",
    "# Merge datasets on Date\n",
    "merged_data = pd.merge(data, price_data, on='Date', how='inner')\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "# Check if merge was successful\n",
    "if len(merged_data) != len(data):\n",
    "    print(f\"Warning: Data length mismatch after merging (Original: {len(data)}, Merged: {len(merged_data)}).\")\n",
    "else:\n",
    "    print(\"Merged successfully with aligned dates.\")\n",
    "\n",
    "data_with_features_raw = add_stable_features(merged_data, etf_list)\n",
    "data_with_features_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Usage Example clearly for benchmark (only price metrics, no predicted return or SHAP):\n",
    "data_with_features = filter_features(data_with_features_raw, \n",
    "                                 include_predicted_returns=True, \n",
    "                                 include_shap_metrics=True)\n",
    "################### override data to use SHAP only\n",
    "# data_with_features = data\n",
    "################### END override \n",
    "\n",
    "# Define your rolling window lengths clearly:\n",
    "train_window_days = 252 * 7\n",
    "validation_window_days = 252\n",
    "prediction_window_days = 252\n",
    "lookback_period = 21\n",
    "rebalance_period = 21\n",
    "\n",
    "start_indices = range(0, len(data) - (train_window_days + validation_window_days + prediction_window_days), prediction_window_days)\n",
    "all_weights = []\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "def validate_and_tune(train_data, val_data, reward_type, rebalance_period=10, lookback_period=10, n_iter=8, timesteps=5000):\n",
    "    best_reward, best_params = -np.inf, None\n",
    "\n",
    "    # Narrow and meaningful parameter distribution\n",
    "    param_dist = {\n",
    "        'learning_rate': [3e-4, 1e-4],\n",
    "        'n_steps': [20, 40],\n",
    "        'batch_size': [10, 20],\n",
    "        'gamma': [0.95, 0.98],\n",
    "        'risk_coefficient': [0.1, 0.5, 1.0] if reward_type in ['mean_var', 'mean_cvar'] else [0.5],\n",
    "    }\n",
    "\n",
    "    sampled_params = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "    for params in sampled_params:\n",
    "        risk_coeff = params.pop('risk_coefficient', 0.5)\n",
    "\n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "        model = PPO('MlpPolicy', env,\n",
    "                    ent_coef=0.01,    # explicitly encourages exploration\n",
    "                    clip_range=0.2,\n",
    "                    **params, verbose=0)\n",
    "        model.learn(total_timesteps=timesteps)\n",
    "\n",
    "        val_env = PortfolioEnv(val_data, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        obs, _ = val_env.reset()\n",
    "        done, total_reward = False, 0\n",
    "        \n",
    "        # while not done:\n",
    "        #     action, _ = model.predict(obs, deterministic=True)\n",
    "        #     obs, reward, done, _, _ = val_env.step(action)\n",
    "        #     total_reward += reward\n",
    "        \n",
    "        while not done:\n",
    "            num_samples = 100  # Recommended starting point\n",
    "            action_samples = []\n",
    "        \n",
    "            for _ in range(num_samples):\n",
    "                sampled_action, _ = model.predict(obs, deterministic=False)  # obs directly\n",
    "                action_samples.append(sampled_action)\n",
    "        \n",
    "            action = np.mean(action_samples, axis=0)\n",
    "        \n",
    "            obs, reward, done, _, _ = val_env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_params = {**params, 'risk_coefficient': risk_coeff}\n",
    "\n",
    "    return best_params\n",
    "\n",
    "def scale_data(df, feature_cols, scaler):\n",
    "    scaled_features = scaler.transform(df[feature_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=feature_cols, index=df.index)\n",
    "\n",
    "    # Re-add columns that were not scaled (e.g., Date, Actual_Return_*)\n",
    "    for col in df.columns:\n",
    "        if col not in feature_cols:\n",
    "            scaled_df[col] = df[col].values\n",
    "\n",
    "    # Keep original column order\n",
    "    scaled_df = scaled_df[df.columns]\n",
    "    return scaled_df\n",
    "\n",
    "# Main execution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "iterations = 10\n",
    "all_weights_iterations = []\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    print(f\"\\n==== Starting Iteration {iteration + 1}/{iterations} ====\")\n",
    "    model_path = f\"ppo_train_best_model_iteration_{iteration}.zip\"\n",
    "    for idx, start_idx in enumerate(start_indices):\n",
    "        # for start_idx in range(0, 252*2, 252):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        # Explicit indices for training, validation, and prediction datasets\n",
    "        train_start_idx = start_idx\n",
    "        train_end_idx = train_start_idx + train_window_days\n",
    "    \n",
    "        val_start_idx = train_end_idx\n",
    "        val_end_idx = val_start_idx + validation_window_days\n",
    "    \n",
    "        pred_start_idx = val_end_idx\n",
    "        pred_end_idx = pred_start_idx + prediction_window_days\n",
    "    \n",
    "        # Corresponding dates explicitly\n",
    "        train_start_date = data_with_features.loc[train_start_idx, 'Date']\n",
    "        train_end_date = data_with_features.loc[train_end_idx - 1, 'Date']\n",
    "    \n",
    "        val_start_date = data_with_features.loc[val_start_idx, 'Date']\n",
    "        val_end_date = data_with_features.loc[val_end_idx - 1, 'Date']\n",
    "    \n",
    "        pred_start_date = data_with_features.loc[pred_start_idx, 'Date']\n",
    "        pred_end_date = data_with_features.loc[pred_end_idx - 1, 'Date']\n",
    "    \n",
    "        # Clearly print ranges for clarity\n",
    "        print(f\"Training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "        print(f\"Validation period: {val_start_date.date()} to {val_end_date.date()}\")\n",
    "        print(f\"Prediction period: {pred_start_date.date()} to {pred_end_date.date()}\")\n",
    "    \n",
    "        # Explicitly subset data accordingly\n",
    "        train_data = data_with_features.iloc[train_start_idx:train_end_idx].reset_index(drop=True)\n",
    "        val_data = data_with_features.iloc[val_start_idx:val_end_idx].reset_index(drop=True)\n",
    "        pred_data = data_with_features.iloc[pred_start_idx:pred_end_idx].reset_index(drop=True)\n",
    "    \n",
    "        feature_cols = [col for col in train_data.columns if col != 'Date' and not col.startswith('Actual_Return')]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data[feature_cols])\n",
    "    \n",
    "        train_data_scaled = scale_data(train_data, feature_cols, scaler)\n",
    "        val_data_scaled = scale_data(val_data, feature_cols, scaler)\n",
    "        pred_data_scaled = scale_data(pred_data, feature_cols, scaler)\n",
    "    \n",
    "        print(\"Starting hyperparameter tuning...\")\n",
    "        best_params = validate_and_tune(train_data_scaled, val_data_scaled, reward_type)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "        incremental_timesteps = 5000\n",
    "        max_timesteps = 30000\n",
    "        patience = 3\n",
    "        \n",
    "        best_val_reward = -np.inf\n",
    "        no_improve_steps = 0\n",
    "    \n",
    "        risk_coeff = best_params.pop('risk_coefficient',0.5)\n",
    "        policy_kwargs = dict(net_arch=[256, 256])\n",
    "    \n",
    "        env = make_vec_env(lambda: PortfolioEnv(train_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period), n_envs=1)\n",
    "        \n",
    "        # Load previous model if exists\n",
    "        if idx > 0 and os.path.exists(model_path):\n",
    "            print(f\"Loading previous model from {model_path}...\")\n",
    "            model = PPO.load(model_path, env=env)\n",
    "            model.set_env(env)\n",
    "        else:\n",
    "            print(\"Initializing new PPO model...\")\n",
    "            model = PPO('MlpPolicy', env,\n",
    "                        policy_kwargs=policy_kwargs,\n",
    "                        ent_coef=0.01,\n",
    "                        clip_range=0.2,\n",
    "                        **best_params, verbose=0)\n",
    "         # always retrain\n",
    "        # model = PPO('MlpPolicy', env,\n",
    "        #             policy_kwargs=policy_kwargs,\n",
    "        #             ent_coef=0.01,    # explicitly encourages exploration\n",
    "        #             clip_range=0.2,\n",
    "        #             **best_params, verbose=0)\n",
    "        # print(\"Starting model training...\")\n",
    "        # model.learn(total_timesteps=20000)\n",
    "        print(\"Starting model training with early stopping...\")\n",
    "        \n",
    "        # model = PPO('MlpPolicy', env,\n",
    "        #             policy_kwargs=policy_kwargs,\n",
    "        #             ent_coef=0.01,    # explicitly encourages exploration\n",
    "        #             clip_range=0.2,\n",
    "        #             **best_params, verbose=0)\n",
    "        # print(\"Starting model training...\")\n",
    "        # model.learn(total_timesteps=20000)\n",
    "    \n",
    "        for step in range(0, max_timesteps, incremental_timesteps):\n",
    "            model.learn(total_timesteps=incremental_timesteps)\n",
    "        \n",
    "            # Evaluate on validation environment\n",
    "            val_env = PortfolioEnv(val_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "            val_obs, _ = val_env.reset()\n",
    "            val_done = False\n",
    "            val_total_reward = 0.0\n",
    "        \n",
    "            while not val_done:\n",
    "                # val_action, _ = model.predict(val_obs, deterministic=True)\n",
    "                # val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "                # val_total_reward += val_reward\n",
    "                \n",
    "                num_samples = 100  # Recommended\n",
    "                value_action_samples = []\n",
    "        \n",
    "                for _ in range(num_samples):\n",
    "                    value_sampled_action, _ = model.predict(val_obs, deterministic=False)\n",
    "                    value_action_samples.append(value_sampled_action)\n",
    "            \n",
    "                val_action = np.mean(value_action_samples, axis=0)    \n",
    "                \n",
    "                val_obs, val_reward, val_done, _, _ = val_env.step(val_action)\n",
    "                val_total_reward += val_reward\n",
    "        \n",
    "            print(f\"Step: {step + incremental_timesteps}, Validation Total Reward: {val_total_reward:.4f}\")\n",
    "        \n",
    "            # Early stopping check\n",
    "            if val_total_reward > best_val_reward:\n",
    "                best_val_reward = val_total_reward\n",
    "                no_improve_steps = 0\n",
    "                # model.save(\"best_ppo_model.zip\")\n",
    "                model.save(model_path)\n",
    "                print(f\"Improved validation reward; model saved at step {step + incremental_timesteps}\")\n",
    "            else:\n",
    "                no_improve_steps += 1\n",
    "                print(f\"No improvement ({no_improve_steps}/{patience})\")\n",
    "        \n",
    "                if no_improve_steps >= patience:\n",
    "                    print(\"Early stopping explicitly triggered.\")\n",
    "                    break\n",
    "        \n",
    "        # Load the best model explicitly\n",
    "        # model = PPO.load(\"best_ppo_model.zip\")\n",
    "        model = PPO.load(model_path)\n",
    "        \n",
    "        print(\"Loaded the best PPO model explicitly for prediction.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Ensure historical context explicitly available in prediction\n",
    "        full_data = pd.concat([train_data_scaled, val_data_scaled, pred_data_scaled])\n",
    "        pred_data_with_history = full_data[full_data['Date'] >= (pred_start_date - pd.Timedelta(days=lookback_period))].reset_index(drop=True)\n",
    "    \n",
    "        pred_env = PortfolioEnv(pred_data_scaled, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "        # pred_env = PortfolioEnv(pred_data_with_history, etf_list, reward_type, risk_coeff, rebalance_period, lookback_period)\n",
    "    \n",
    "        obs, info = pred_env.reset()\n",
    "        done = False\n",
    "    \n",
    "        action = np.zeros(len(etf_list), dtype=np.float32)\n",
    "    \n",
    "        while not done:\n",
    "            if pred_env.current_step >= lookback_period and pred_env.current_step % pred_env.rebalance_period == 0:\n",
    "                # obs_for_agent = pred_data_with_history.drop(columns=['Date']).iloc[pred_env.current_step - lookback_period:pred_env.current_step].values.flatten().astype(np.float32)\n",
    "                # action, _ = model.predict(obs_for_agent, deterministic=True)\n",
    "    \n",
    "                # v1 normalize weight\n",
    "                # action, _ = model.predict(obs, deterministic=True)\n",
    "                \n",
    "                # num_samples = 100  # Recommended\n",
    "                # action_samples = []\n",
    "                # \n",
    "                # for _ in range(num_samples):\n",
    "                #     sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "                #     action_samples.append(sampled_action)\n",
    "                # \n",
    "                # action = np.mean(action_samples, axis=0)    \n",
    "                # \n",
    "                # temperature = 0.5\n",
    "                # scaled_action = action / temperature\n",
    "                # final_weights = np.exp(scaled_action) / np.sum(np.exp(scaled_action))\n",
    "                # rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "                # # all_weights.append([rebalance_date] + weights.tolist())\n",
    "                # all_weights_iterations.append([iteration + 1, rebalance_date] + final_weights.tolist())\n",
    "    \n",
    "                # v2 long short normalization\n",
    "                # action, _ = model.predict(obs, deterministic=True)\n",
    "                \n",
    "                num_samples = 100  # Recommended\n",
    "                action_samples = []\n",
    "\n",
    "                for _ in range(num_samples):\n",
    "                    sampled_action, _ = model.predict(obs, deterministic=False)\n",
    "                    action_samples.append(sampled_action)\n",
    "\n",
    "                action = np.mean(action_samples, axis=0)    \n",
    "\n",
    "                # Explicitly apply your new 120/20 normalization logic (to match environment step)\n",
    "                desired_long = 1.20  # Explicitly 120% long exposure\n",
    "                desired_short = 0.20  # Explicitly 20% short exposure\n",
    "                clip_bounds = (-0.2, 0.8)\n",
    "\n",
    "                raw_weights = action.copy()\n",
    "\n",
    "                # Separate explicitly positive (long) and negative (short) actions\n",
    "                long_weights = np.maximum(raw_weights, 0)\n",
    "                short_weights = np.abs(np.minimum(raw_weights, 0))\n",
    "\n",
    "                has_longs = np.sum(long_weights) > 0\n",
    "                has_shorts = np.sum(short_weights) > 0\n",
    "\n",
    "                if has_longs and has_shorts:\n",
    "                    normalized_long = desired_long * long_weights / np.sum(long_weights)\n",
    "                    normalized_short = desired_short * short_weights / np.sum(short_weights)\n",
    "                elif has_longs and not has_shorts:\n",
    "                    normalized_long = long_weights / np.sum(long_weights)\n",
    "                    normalized_short = np.zeros_like(short_weights)\n",
    "                elif not has_longs and has_shorts:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    normalized_long = np.ones(num_assets) / num_assets\n",
    "                    normalized_short = np.zeros(num_assets)\n",
    "                else:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    normalized_long = np.ones(num_assets) / num_assets\n",
    "                    normalized_short = np.zeros(num_assets)\n",
    "\n",
    "                combined_weights = normalized_long - normalized_short\n",
    "                clipped_weights = np.clip(combined_weights, clip_bounds[0], clip_bounds[1])\n",
    "\n",
    "                # Re-separate after clipping explicitly\n",
    "                long_clipped = np.maximum(clipped_weights, 0)\n",
    "                short_clipped = np.abs(np.minimum(clipped_weights, 0))\n",
    "\n",
    "                has_long_clipped = np.sum(long_clipped) > 0\n",
    "                has_short_clipped = np.sum(short_clipped) > 0\n",
    "\n",
    "                if has_long_clipped and has_short_clipped:\n",
    "                    final_long = desired_long * long_clipped / np.sum(long_clipped)\n",
    "                    final_short = desired_short * short_clipped / np.sum(short_clipped)\n",
    "                elif has_long_clipped and not has_short_clipped:\n",
    "                    final_long = long_clipped / np.sum(long_clipped)\n",
    "                    final_short = np.zeros_like(short_clipped)\n",
    "                else:\n",
    "                    num_assets = len(raw_weights)\n",
    "                    final_long = np.ones(num_assets) / num_assets\n",
    "                    final_short = np.zeros(num_assets)\n",
    "\n",
    "                final_weights = final_long - final_short\n",
    "\n",
    "                rebalance_date = pred_data_with_history.loc[pred_env.current_step, 'Date']\n",
    "                # all_weights.append([rebalance_date] + final_weights.tolist())\n",
    "                all_weights_iterations.append([iteration + 1, rebalance_date] + final_weights.tolist())\n",
    "                # \n",
    "            obs, _, done, _, _ = pred_env.step(action)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        print(f\"Iteration {iteration + 1}, start index {start_idx} completed in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "columns = ['Iteration', 'Date'] + etf_list\n",
    "weights_df = pd.DataFrame(all_weights_iterations, columns=columns)\n",
    "weights_df.to_csv('ppo_allocations_multiple_iterations_DIA_ETF.csv', index=False)\n",
    "print(\"Saved all iterations' allocations to ppo_allocations_multiple_iterations_DIA_ETF.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d1a98b60121652",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Stage 2 PPO training with recommended enhancements\n",
    "# ==================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import gym\n",
    "from gym import spaces\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Utility functions and seeding\n",
    "# -------------------------------------------------------------------\n",
    "SEED = 42\n",
    "\n",
    "def set_global_seed(seed):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_global_seed(SEED)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Environment definition with softmax normalisation and Mean‑CVaR reward\n",
    "# -------------------------------------------------------------------\n",
    "class PortfolioEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Gym environment for portfolio allocation.\n",
    "    Observations are flattened windows of features; actions are unconstrained\n",
    "    real numbers that are converted to portfolio weights via softmax.\n",
    "    Reward is computed at each rebalance period as mean minus λ × CVaR.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, etf_list, reward_type='mean_cvar',\n",
    "                 risk_coefficient=1.0, rebalance_period=21,\n",
    "                 lookback_period=60):\n",
    "        super().__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.etf_list = etf_list\n",
    "        self.reward_type = reward_type\n",
    "        self.risk_coefficient = risk_coefficient\n",
    "        self.rebalance_period = rebalance_period\n",
    "        self.lookback_period = lookback_period\n",
    "\n",
    "        # Action space: one unbounded action per asset\n",
    "        self.action_space = spaces.Box(low=-10, high=10, shape=(len(etf_list),), dtype=np.float32)\n",
    "\n",
    "        # Observation space: flatten last lookback_period days of features\n",
    "        self.feature_cols = [c for c in data.columns\n",
    "                             if c not in ['Date'] and not c.startswith('Actual_Return')]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(len(self.feature_cols)*lookback_period,),\n",
    "                                            dtype=np.float32)\n",
    "\n",
    "        self.current_step = self.lookback_period\n",
    "        self.current_weights = np.array([1/len(etf_list)]*len(etf_list), dtype=float)\n",
    "        self.cumulative_wealth = 1.0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.current_step = self.lookback_period\n",
    "        self.current_weights = np.array([1/len(self.etf_list)]*len(self.etf_list),\n",
    "                                        dtype=float)\n",
    "        self.cumulative_wealth = 1.0\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"Return a flattened window of recent features.\"\"\"\n",
    "        window = self.data.iloc[\n",
    "            self.current_step - self.lookback_period : self.current_step\n",
    "        ]\n",
    "        return window[self.feature_cols].values.flatten().astype(np.float32)\n",
    "\n",
    "    def _action_to_weights(self, action):\n",
    "        \"\"\"\n",
    "        Convert raw action outputs into a valid long‑only weight vector via softmax.\n",
    "        This implements the 'continuous 10‑dimensional weights with softmax normalisation'\n",
    "        specification from your methodology (Step 4).\n",
    "        \"\"\"\n",
    "        # temperature scaling – adjust if you want more/less concentration\n",
    "        temperature = 1.0\n",
    "        scaled = action / temperature\n",
    "        exp_vals = np.exp(scaled - np.max(scaled))\n",
    "        return exp_vals / exp_vals.sum()\n",
    "\n",
    "    def calculate_reward(self, portfolio_return, asset_returns):\n",
    "        \"\"\"Compute reward according to the chosen risk measure.\"\"\"\n",
    "        if self.reward_type == 'mean_cvar':\n",
    "            alpha = 0.05\n",
    "            var = np.percentile(asset_returns, 100*alpha)\n",
    "            cvar = np.mean(asset_returns[asset_returns <= var])\n",
    "            return portfolio_return - self.risk_coefficient * cvar\n",
    "        elif self.reward_type == 'mean_var':\n",
    "            return portfolio_return - self.risk_coefficient * np.var(asset_returns)\n",
    "        elif self.reward_type == 'log_wealth':\n",
    "            return np.log(self.cumulative_wealth)\n",
    "        elif self.reward_type == 'cumulative_return':\n",
    "            return self.cumulative_wealth - 1.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reward_type {self.reward_type}\")\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Update portfolio and compute reward.\"\"\"\n",
    "        next_step = self.current_step + 1\n",
    "\n",
    "        # rebalance portfolio at rebalance dates\n",
    "        if self.current_step % self.rebalance_period == 0:\n",
    "            self.current_weights = self._action_to_weights(action)\n",
    "        else:\n",
    "            # drift weights using actual returns\n",
    "            daily_rets = np.array([\n",
    "                self.data.loc[self.current_step, f'Actual_Return_{t}']\n",
    "                for t in self.etf_list\n",
    "            ])\n",
    "            self.current_weights *= (1 + daily_rets)\n",
    "            self.current_weights /= self.current_weights.sum()\n",
    "\n",
    "        # compute reward on the next day\n",
    "        if next_step >= len(self.data):\n",
    "            done = True\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            asset_returns = np.array([\n",
    "                self.data.loc[next_step, f'Actual_Return_{t}']\n",
    "                for t in self.etf_list\n",
    "            ])\n",
    "            portfolio_ret = float(np.dot(self.current_weights, asset_returns))\n",
    "            self.cumulative_wealth *= (1 + portfolio_ret)\n",
    "            reward = self.calculate_reward(portfolio_ret, asset_returns)\n",
    "            done = (next_step >= len(self.data) - 1)\n",
    "\n",
    "        self.current_step += 1\n",
    "        return self._get_obs(), reward, done, False, {}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Data preparation (Step 1)\n",
    "# -------------------------------------------------------------------\n",
    "# Load your Stage 2 RL observations (predicted returns, SHAP, etc.)\n",
    "stage2_file = 'stage2_rl_observations_optimized_10ETFs.csv'\n",
    "price_file = 'stock_prices_10ETFs.csv'\n",
    "\n",
    "stage2 = pd.read_csv(stage2_file, parse_dates=['Date'])\n",
    "prices = pd.read_csv(price_file)\n",
    "prices['Date'] = pd.to_datetime(prices['Date'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "# Align data on Date\n",
    "prices.rename(columns={c: f'Price_{c}' for c in prices.columns if c != 'Date'},\n",
    "              inplace=True)\n",
    "data_merged = pd.merge(stage2, prices, on='Date', how='inner')\n",
    "\n",
    "# Compute technical indicators (volatility, momentum, moving averages)\n",
    "# as outlined in the methodology (20‑day volatility, 5/10/20‑day momentum,\n",
    "# 5‑ and 20‑day moving averages and crossover).\n",
    "\n",
    "\n",
    "def add_features(df, etfs):\n",
    "    df2 = df.copy()\n",
    "    for etf in etfs:\n",
    "        price_col = f'Price_{etf}'\n",
    "        returns = df2[price_col].pct_change()\n",
    "        df2[f'Volatility_{etf}'] = returns.rolling(20).std()\n",
    "        df2[f'Momentum_5d_{etf}'] = returns.rolling(5).sum()\n",
    "        df2[f'Momentum_10d_{etf}'] = returns.rolling(10).sum()\n",
    "        df2[f'Momentum_20d_{etf}'] = returns.rolling(20).sum()\n",
    "        df2[f'MA_5d_{etf}'] = df2[price_col].rolling(5).mean()\n",
    "        df2[f'MA_20d_{etf}'] = df2[price_col].rolling(20).mean()\n",
    "        df2[f'MA_Crossover_{etf}'] = df2[f'MA_5d_{etf}'] - df2[f'MA_20d_{etf}']\n",
    "    return df2.dropna()\n",
    "\n",
    "data_with_features = add_features(data_merged, ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'])\n",
    "\n",
    "# Optionally, filter out predicted returns or SHAP metrics; here we include both\n",
    "# because they are key inputs in Step 4’s observation space.\n",
    "def filter_features(df, include_predicted_returns=True, include_shap_metrics=True):\n",
    "    df2 = df.copy()\n",
    "    if not include_predicted_returns:\n",
    "        cols = [c for c in df2.columns if 'Predicted_Return' in c]\n",
    "        df2.drop(columns=cols, inplace=True)\n",
    "    if not include_shap_metrics:\n",
    "        cols = [c for c in df2.columns if 'SHAP' in c]\n",
    "        df2.drop(columns=cols, inplace=True)\n",
    "    return df2\n",
    "\n",
    "data_with_features = filter_features(data_with_features, True, True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rolling window splits (Stage 2 Initial Training, Validation, Test)\n",
    "# -------------------------------------------------------------------\n",
    "# Use 10 years for training, 2 years for validation, 3 years for test\n",
    "train_days = 252*10\n",
    "val_days   = 252*2\n",
    "test_days  = 252*3\n",
    "\n",
    "lookback  = 60         # 60‑day lookback (recommended)\n",
    "rebalance = 21         # monthly rebalance (21 trading days)\n",
    "\n",
    "# In a real implementation you would loop over many start dates; here we take the first one\n",
    "start_idx = 0\n",
    "train_data = data_with_features.iloc[start_idx:start_idx+train_days].reset_index(drop=True)\n",
    "val_data   = data_with_features.iloc[start_idx+train_days:\n",
    "                                     start_idx+train_days+val_days].reset_index(drop=True)\n",
    "test_data  = data_with_features.iloc[start_idx+train_days+val_days:\n",
    "                                     start_idx+train_days+val_days+test_days].reset_index(drop=True)\n",
    "\n",
    "# Standardise features\n",
    "feature_cols = [c for c in train_data.columns if c not in ['Date']\n",
    "                and not c.startswith('Actual_Return')]\n",
    "scaler = StandardScaler().fit(train_data[feature_cols])\n",
    "\n",
    "def scale(df):\n",
    "    x = scaler.transform(df[feature_cols])\n",
    "    df_scaled = pd.DataFrame(x, columns=feature_cols, index=df.index)\n",
    "    for col in df.columns:\n",
    "        if col not in feature_cols:\n",
    "            df_scaled[col] = df[col]\n",
    "    return df_scaled[df.columns]\n",
    "\n",
    "train_scaled = scale(train_data)\n",
    "val_scaled   = scale(val_data)\n",
    "test_scaled  = scale(test_data)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PPO Training with improved hyper‑parameters (Step 5)\n",
    "# -------------------------------------------------------------------\n",
    "def linear_schedule(initial_value, final_value):\n",
    "    def schedule(progress_remaining):\n",
    "        return final_value + progress_remaining * (initial_value - final_value)\n",
    "    return schedule\n",
    "\n",
    "# Use a vectorised environment with 10 parallel instances for faster training\n",
    "n_envs = 10\n",
    "def make_env():\n",
    "    return PortfolioEnv(train_scaled, \n",
    "                        ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'],\n",
    "                        reward_type='mean_cvar',\n",
    "                        risk_coefficient=1.0,\n",
    "                        rebalance_period=rebalance,\n",
    "                        lookback_period=lookback)\n",
    "\n",
    "vec_env = SubprocVecEnv([make_env for _ in range(n_envs)], start_method='spawn')\n",
    "\n",
    "# PPO hyper‑parameters inspired by recent research:contentReference[oaicite:0]{index=0}\n",
    "# n_steps collects 3 months of daily data per environment: 252 * 3 ≈ 756\n",
    "n_steps = 252 * 3\n",
    "ppo_model = PPO(\n",
    "    policy='MlpPolicy',\n",
    "    env=vec_env,\n",
    "    learning_rate=linear_schedule(3e-4, 1e-5),\n",
    "    n_steps=n_steps,\n",
    "    batch_size=1260,           # 252 * 5\n",
    "    n_epochs=16,\n",
    "    gamma=0.9,                 # lower discount to focus on near‑term returns\n",
    "    gae_lambda=0.9,\n",
    "    clip_range=0.25,\n",
    "    policy_kwargs=dict(\n",
    "        net_arch=[64, 64],\n",
    "        activation_fn=torch.nn.Tanh,\n",
    "        log_std_init=-1.0\n",
    "    ),\n",
    "    ent_coef=0.01,\n",
    "    seed=SEED,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train for 7.5 million timesteps (≈600 episodes × 10 envs × 252×5 steps)\n",
    "total_timesteps = int(7.5e6)\n",
    "ppo_model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "# Optionally save the model\n",
    "ppo_model.save('ppo_stage2_best_model.zip')\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Validation and early stopping (Step 6)\n",
    "# -------------------------------------------------------------------\n",
    "# After training, evaluate on the validation set without updating parameters\n",
    "val_env = PortfolioEnv(val_scaled,\n",
    "                       ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'],\n",
    "                       reward_type='mean_cvar',\n",
    "                       risk_coefficient=1.0,\n",
    "                       rebalance_period=rebalance,\n",
    "                       lookback_period=lookback)\n",
    "obs, _ = val_env.reset(seed=SEED)\n",
    "done = False\n",
    "val_reward = 0.0\n",
    "while not done:\n",
    "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, _ = val_env.step(action)\n",
    "    val_reward += reward\n",
    "print(f\"Total validation reward: {val_reward:.4f}\")\n",
    "\n",
    "# If necessary, you can adjust hyperparameters and re‑train based on validation performance.\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Out‑of‑sample testing (2022–2024) and performance metrics (Step 6)\n",
    "# -------------------------------------------------------------------\n",
    "test_env = PortfolioEnv(test_scaled,\n",
    "                        ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'],\n",
    "                        reward_type='mean_cvar',\n",
    "                        risk_coefficient=1.0,\n",
    "                        rebalance_period=rebalance,\n",
    "                        lookback_period=lookback)\n",
    "\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "rebalance_dates = []\n",
    "weights_history = []\n",
    "while not done:\n",
    "    # produce an action every step; env will apply it only on rebalance dates\n",
    "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "    obs, _, done, _, _ = test_env.step(action)\n",
    "    # record weights at rebalance points\n",
    "    if test_env.current_step % rebalance == 0:\n",
    "        date = test_scaled.loc[test_env.current_step-1, 'Date']\n",
    "        weights_history.append([date] + test_env.current_weights.tolist())\n",
    "\n",
    "# Save monthly weights to CSV\n",
    "weights_df = pd.DataFrame(weights_history, columns=['Date'] + ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'])\n",
    "weights_df.to_csv('ppo_stage2_weights.csv', index=False)\n",
    "\n",
    "# Compute drifted daily returns and compare to equal weights\n",
    "# (similar to your existing evaluation code)\n",
    "def compute_returns(weights, price_df):\n",
    "    # Explicitly define price columns by removing \"Price_\" prefix\n",
    "    price_df.columns = [c.replace('Price_', '') for c in price_df.columns]\n",
    "\n",
    "    common = [c for c in weights.columns if c in price_df.columns]\n",
    "    if len(common) == 0:\n",
    "        raise ValueError(\"No common ETFs found between weights and prices DataFrames.\")\n",
    "\n",
    "    price_df = price_df[common]\n",
    "    daily_returns = price_df.pct_change().dropna()\n",
    "    weights = weights.set_index('Date')\n",
    "    start = weights.index.min()\n",
    "    end = weights.index.max() + timedelta(days=rebalance)\n",
    "    daily_returns = daily_returns.loc[start:end]\n",
    "\n",
    "    eq_weight = np.array([1/len(common)]*len(common))\n",
    "    drifted = pd.DataFrame(index=daily_returns.index, columns=common)\n",
    "    eq_drift = pd.DataFrame(index=daily_returns.index, columns=common)\n",
    "    cur_w = weights.iloc[0].values\n",
    "    cur_eq = eq_weight\n",
    "\n",
    "    returns_df = pd.DataFrame(index=daily_returns.index, columns=['RL', 'Equal'])\n",
    "\n",
    "    for d in daily_returns.index:\n",
    "        rets = daily_returns.loc[d]  # <-- Define this here explicitly every loop iteration\n",
    "\n",
    "        if d in weights.index:\n",
    "            cur_w = weights.loc[d].values\n",
    "            cur_eq = eq_weight\n",
    "        else:\n",
    "            cur_w = (cur_w * (1 + rets.values))\n",
    "            cur_w /= cur_w.sum()\n",
    "            cur_eq = (cur_eq * (1 + rets.values))\n",
    "            cur_eq /= cur_eq.sum()\n",
    "\n",
    "        drifted.loc[d] = cur_w\n",
    "        eq_drift.loc[d] = cur_eq\n",
    "\n",
    "        shifted_rl = drifted.shift(1).loc[d]\n",
    "        shifted_eq = eq_drift.shift(1).loc[d]\n",
    "\n",
    "        if d == daily_returns.index[0]:\n",
    "            returns_df.loc[d, 'RL'] = np.dot(cur_w, rets)\n",
    "            returns_df.loc[d, 'Equal'] = np.dot(cur_eq, rets)\n",
    "        else:\n",
    "            returns_df.loc[d, 'RL'] = np.dot(shifted_rl, rets)\n",
    "            returns_df.loc[d, 'Equal'] = np.dot(shifted_eq, rets)\n",
    "\n",
    "    return returns_df.dropna()\n",
    "\n",
    "# Compute test returns\n",
    "test_returns = compute_returns(weights_df, prices.set_index('Date'))\n",
    "cum_rl    = (1 + test_returns['RL']).prod() - 1\n",
    "cum_equal = (1 + test_returns['Equal']).prod() - 1\n",
    "print(f\"Out‑of‑sample cumulative return (RL):    {cum_rl:.4%}\")\n",
    "print(f\"Out‑of‑sample cumulative return (Equal): {cum_equal:.4%}\")\n",
    "\n",
    "# You can also compute annualised return, volatility, Sharpe ratio and max drawdown\n",
    "def performance_metrics(returns, freq=252):\n",
    "    ann_return = (1 + returns).prod()**(freq/len(returns)) - 1\n",
    "    ann_vol    = returns.std() * np.sqrt(freq)\n",
    "    sharpe     = ann_return / ann_vol if ann_vol != 0 else np.nan\n",
    "    cum_pnl    = (1+returns).cumprod()\n",
    "    max_dd     = (cum_pnl / cum_pnl.cummax() - 1).min()\n",
    "    return ann_return, ann_vol, sharpe, max_dd\n",
    "\n",
    "rl_ann, rl_vol, rl_sharpe, rl_dd = performance_metrics(test_returns['RL'])\n",
    "eq_ann, eq_vol, eq_sharpe, eq_dd = performance_metrics(test_returns['Equal'])\n",
    "print(f\"RL annualised return:    {rl_ann:.4%}, Sharpe: {rl_sharpe:.3f}, Max Drawdown: {rl_dd:.4%}\")\n",
    "print(f\"Equal annualised return: {eq_ann:.4%}, Sharpe: {eq_sharpe:.3f}, Max Drawdown: {eq_dd:.4%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6947d247eaecd896",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Validation and early stopping (Step 6)\n",
    "# -------------------------------------------------------------------\n",
    "# After training, evaluate on the validation set without updating parameters\n",
    "val_env = PortfolioEnv(val_scaled,\n",
    "                       ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'],\n",
    "                       reward_type='mean_cvar',\n",
    "                       risk_coefficient=1.0,\n",
    "                       rebalance_period=rebalance,\n",
    "                       lookback_period=lookback)\n",
    "obs, _ = val_env.reset(seed=SEED)\n",
    "done = False\n",
    "val_reward = 0.0\n",
    "while not done:\n",
    "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, _ = val_env.step(action)\n",
    "    val_reward += reward\n",
    "print(f\"Total validation reward: {val_reward:.4f}\")\n",
    "\n",
    "# If necessary, you can adjust hyperparameters and re‑train based on validation performance.\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Out‑of‑sample testing (2022–2024) and performance metrics (Step 6)\n",
    "# -------------------------------------------------------------------\n",
    "test_env = PortfolioEnv(test_scaled,\n",
    "                        ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'],\n",
    "                        reward_type='mean_cvar',\n",
    "                        risk_coefficient=1.0,\n",
    "                        rebalance_period=rebalance,\n",
    "                        lookback_period=lookback)\n",
    "\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "rebalance_dates = []\n",
    "weights_history = []\n",
    "while not done:\n",
    "    # produce an action every step; env will apply it only on rebalance dates\n",
    "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "    obs, _, done, _, _ = test_env.step(action)\n",
    "    # record weights at rebalance points\n",
    "    if test_env.current_step % rebalance == 0:\n",
    "        date = test_scaled.loc[test_env.current_step-1, 'Date']\n",
    "        weights_history.append([date] + test_env.current_weights.tolist())\n",
    "\n",
    "# Save monthly weights to CSV\n",
    "weights_df = pd.DataFrame(weights_history, columns=['Date'] + ['XLB','XLE','XLF','XLI','XLK','XLP','XLY','XLV','XLU'])\n",
    "weights_df.to_csv('ppo_stage2_weights.csv', index=False)\n",
    "\n",
    "# Compute drifted daily returns and compare to equal weights\n",
    "# (similar to your existing evaluation code)\n",
    "def compute_returns(weights, price_df):\n",
    "    # Explicitly define price columns by removing \"Price_\" prefix\n",
    "    price_df.columns = [c.replace('Price_', '') for c in price_df.columns]\n",
    "\n",
    "    common = [c for c in weights.columns if c in price_df.columns]\n",
    "    if len(common) == 0:\n",
    "        raise ValueError(\"No common ETFs found between weights and prices DataFrames.\")\n",
    "\n",
    "    price_df = price_df[common]\n",
    "    daily_returns = price_df.pct_change().dropna()\n",
    "    weights = weights.set_index('Date')\n",
    "    start = weights.index.min()\n",
    "    end = weights.index.max() + timedelta(days=rebalance)\n",
    "    daily_returns = daily_returns.loc[start:end]\n",
    "\n",
    "    eq_weight = np.array([1/len(common)]*len(common))\n",
    "    drifted = pd.DataFrame(index=daily_returns.index, columns=common)\n",
    "    eq_drift = pd.DataFrame(index=daily_returns.index, columns=common)\n",
    "    cur_w = weights.iloc[0].values\n",
    "    cur_eq = eq_weight\n",
    "\n",
    "    returns_df = pd.DataFrame(index=daily_returns.index, columns=['RL', 'Equal'])\n",
    "\n",
    "    for d in daily_returns.index:\n",
    "        rets = daily_returns.loc[d]  # <-- Define this here explicitly every loop iteration\n",
    "\n",
    "        if d in weights.index:\n",
    "            cur_w = weights.loc[d].values\n",
    "            cur_eq = eq_weight\n",
    "        else:\n",
    "            cur_w = (cur_w * (1 + rets.values))\n",
    "            cur_w /= cur_w.sum()\n",
    "            cur_eq = (cur_eq * (1 + rets.values))\n",
    "            cur_eq /= cur_eq.sum()\n",
    "\n",
    "        drifted.loc[d] = cur_w\n",
    "        eq_drift.loc[d] = cur_eq\n",
    "\n",
    "        shifted_rl = drifted.shift(1).loc[d]\n",
    "        shifted_eq = eq_drift.shift(1).loc[d]\n",
    "\n",
    "        if d == daily_returns.index[0]:\n",
    "            returns_df.loc[d, 'RL'] = np.dot(cur_w, rets)\n",
    "            returns_df.loc[d, 'Equal'] = np.dot(cur_eq, rets)\n",
    "        else:\n",
    "            returns_df.loc[d, 'RL'] = np.dot(shifted_rl, rets)\n",
    "            returns_df.loc[d, 'Equal'] = np.dot(shifted_eq, rets)\n",
    "\n",
    "    return returns_df.dropna()\n",
    "\n",
    "# Compute test returns\n",
    "test_returns = compute_returns(weights_df, prices.set_index('Date'))\n",
    "cum_rl    = (1 + test_returns['RL']).prod() - 1\n",
    "cum_equal = (1 + test_returns['Equal']).prod() - 1\n",
    "print(f\"Out‑of‑sample cumulative return (RL):    {cum_rl:.4%}\")\n",
    "print(f\"Out‑of‑sample cumulative return (Equal): {cum_equal:.4%}\")\n",
    "\n",
    "# You can also compute annualised return, volatility, Sharpe ratio and max drawdown\n",
    "def performance_metrics(returns, freq=252):\n",
    "    ann_return = (1 + returns).prod()**(freq/len(returns)) - 1\n",
    "    ann_vol    = returns.std() * np.sqrt(freq)\n",
    "    sharpe     = ann_return / ann_vol if ann_vol != 0 else np.nan\n",
    "    cum_pnl    = (1+returns).cumprod()\n",
    "    max_dd     = (cum_pnl / cum_pnl.cummax() - 1).min()\n",
    "    return ann_return, ann_vol, sharpe, max_dd\n",
    "\n",
    "rl_ann, rl_vol, rl_sharpe, rl_dd = performance_metrics(test_returns['RL'])\n",
    "eq_ann, eq_vol, eq_sharpe, eq_dd = performance_metrics(test_returns['Equal'])\n",
    "print(f\"RL annualised return:    {rl_ann:.4%}, Sharpe: {rl_sharpe:.3f}, Max Drawdown: {rl_dd:.4%}\")\n",
    "print(f\"Equal annualised return: {eq_ann:.4%}, Sharpe: {eq_sharpe:.3f}, Max Drawdown: {eq_dd:.4%}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3462ab258866c09e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data explicitly\n",
    "port_wts = pd.read_csv('ppo_allocations_multiple_iterations_DIA_ETF.csv', parse_dates=['Date'], index_col='Date')\n",
    "daily_returns = pd.read_csv('daily_returns_10ETFs.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "common_tickers = [col for col in port_wts.columns if col in daily_returns.columns]\n",
    "daily_returns = daily_returns[common_tickers]\n",
    "\n",
    "# Explicitly filter daily returns to the date range covered by portfolio weights\n",
    "start_date, end_date = port_wts.index.min(), port_wts.index.max() + pd.Timedelta(days=21)\n",
    "daily_returns = daily_returns.loc[start_date:end_date]\n",
    "\n",
    "# Initialize drifted weights with the first available rebalance weights\n",
    "initial_weights = port_wts.loc[start_date].values\n",
    "\n",
    "equal_weight = np.array([1.0 / len(common_tickers)] * len(common_tickers))\n",
    "\n",
    "# Create drifted weights DataFrame explicitly initialized\n",
    "drifted_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "equal_weights = pd.DataFrame(index=daily_returns.index, columns=common_tickers)\n",
    "\n",
    "current_weights = initial_weights\n",
    "current_equal_weights = equal_weight\n",
    "\n",
    "# Initialize returns DataFrame explicitly\n",
    "returns_df = pd.DataFrame(index=daily_returns.index, columns=['Optimal_Portfolio_Return', 'Equal_Weight_Return'])\n",
    "\n",
    "for current_date in daily_returns.index:\n",
    "    if current_date in port_wts.index:\n",
    "        # Explicit rebalance date: assign new weights\n",
    "        current_weights = port_wts.loc[current_date].values\n",
    "        current_equal_weights = equal_weight\n",
    "    else:\n",
    "        # Explicitly drift weights using previous day's return\n",
    "        prev_day_return = daily_returns.loc[current_date]\n",
    "\n",
    "        drifted_wts_numerator = current_weights * (1 + prev_day_return.values)\n",
    "        current_weights = drifted_wts_numerator / np.sum(drifted_wts_numerator)\n",
    "\n",
    "        equal_drifted_numerator = current_equal_weights * (1 + prev_day_return.values)\n",
    "        current_equal_weights = equal_drifted_numerator / np.sum(equal_drifted_numerator)\n",
    "\n",
    "    drifted_weights.loc[current_date] = current_weights\n",
    "    equal_weights.loc[current_date] = current_equal_weights\n",
    "    shifted_drifted_weights = drifted_weights.shift(1)\n",
    "    shifted_equal_weights = equal_weights.shift(1)\n",
    "    if current_date == daily_returns.index[0]:\n",
    "        # On the first day, use initial weights directly\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "    else:\n",
    "        # Explicitly use previous day's weights\n",
    "        returns_df.loc[current_date, 'Optimal_Portfolio_Return'] = np.dot(\n",
    "            shifted_drifted_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "        returns_df.loc[current_date, 'Equal_Weight_Return'] = np.dot(\n",
    "            shifted_equal_weights.loc[current_date], daily_returns.loc[current_date])\n",
    "\n",
    "# Check explicitly\n",
    "print(\"Drifted weights (head):\\n\", drifted_weights.head())\n",
    "print(\"\\nPortfolio returns (head):\\n\", returns_df.head())\n",
    "\n",
    "# Save explicitly\n",
    "drifted_weights.to_csv('drifted_weights_corrected.csv')\n",
    "equal_weights.to_csv('equal_weights.csv')\n",
    "returns_df.to_csv('portfolio_returns_combined.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e17792fa6118e4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
